{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib as 2D backend.\n",
      "___MEG QC___:  list_of_subs ['Ab140232', 'Al150424', 'Cb140229', 'Cc160310', 'Jl150443', 'Lb160367', 'Mb160304', 'Mk150295', 'Mm150194', 'Mp110340', 'Mp150285', 'Rt160359', 'Sl160372', 'emptyroom']\n",
      "___MEG QC___:  TOTAL subs 14\n",
      "___MEG QC___:  EMPTY room? Ab140232 emptyroom\n",
      "___MEG QC___:  Dataset:  /Volumes/M2_DATA/MEG_QC_stuff/data/openneuro/ds003922\n",
      "___MEG QC___:  Take SID:  Al150424\n",
      "___MEG QC___:  list_of_fifs ['/Volumes/M2_DATA/MEG_QC_stuff/data/openneuro/ds003922/sub-Al150424/ses-01/meg/sub-Al150424_ses-01_acq-crosstalk_meg.fif', '/Volumes/M2_DATA/MEG_QC_stuff/data/openneuro/ds003922/sub-Al150424/ses-01/meg/sub-Al150424_ses-01_task-mcd_run-02_meg.fif', '/Volumes/M2_DATA/MEG_QC_stuff/data/openneuro/ds003922/sub-Al150424/ses-01/meg/sub-Al150424_ses-01_task-mcd_run-03_meg.fif', '/Volumes/M2_DATA/MEG_QC_stuff/data/openneuro/ds003922/sub-Al150424/ses-01/meg/sub-Al150424_ses-01_task-mcd_run-04_meg.fif', '/Volumes/M2_DATA/MEG_QC_stuff/data/openneuro/ds003922/sub-Al150424/ses-01/meg/sub-Al150424_ses-01_task-mcd_run-05_meg.fif', '/Volumes/M2_DATA/MEG_QC_stuff/data/openneuro/ds003922/sub-Al150424/ses-01/meg/sub-Al150424_ses-01_task-mcd_run-06_meg.fif', '/Volumes/M2_DATA/MEG_QC_stuff/data/openneuro/ds003922/sub-Al150424/ses-01/meg/sub-Al150424_ses-01_task-mcd_run-07_meg.fif', '/Volumes/M2_DATA/MEG_QC_stuff/data/openneuro/ds003922/sub-Al150424/ses-01/meg/sub-Al150424_ses-01_task-mcd_run-08_meg.fif', '/Volumes/M2_DATA/MEG_QC_stuff/data/openneuro/ds003922/sub-Al150424/ses-01/meg/sub-Al150424_ses-01_task-mcd_run-09_meg.fif', '/Volumes/M2_DATA/MEG_QC_stuff/data/openneuro/ds003922/sub-Al150424/ses-01/meg/sub-Al150424_ses-01_task-mcd_run-10_meg.fif', '/Volumes/M2_DATA/MEG_QC_stuff/data/openneuro/ds003922/sub-Al150424/ses-01/meg/sub-Al150424_ses-01_task-mcd_run-11_meg.fif', '/Volumes/M2_DATA/MEG_QC_stuff/data/openneuro/ds003922/sub-Al150424/ses-01/meg/sub-Al150424_ses-01_task-rest_run-01_meg.fif']\n",
      "___MEG QC___:  TOTAL fifs:  12\n",
      "___MEG QC___:  Take fif:  /Volumes/M2_DATA/MEG_QC_stuff/data/openneuro/ds003922/sub-Al150424/ses-01/meg/sub-Al150424_ses-01_task-mcd_run-03_meg.fif\n",
      "___MEG QC___:  Starting initial processing...\n",
      "___MEG QC___:  Reading data from file: /Volumes/M2_DATA/MEG_QC_stuff/data/openneuro/ds003922/sub-Al150424/ses-01/meg/sub-Al150424_ses-01_task-mcd_run-03_meg.fif\n",
      "Opening raw data file /Volumes/M2_DATA/MEG_QC_stuff/data/openneuro/ds003922/sub-Al150424/ses-01/meg/sub-Al150424_ses-01_task-mcd_run-03_meg.fif...\n",
      "    Read a total of 13 projection items:\n",
      "        grad_ssp_upright.fif : PCA-v1 (1 x 306)  idle\n",
      "        grad_ssp_upright.fif : PCA-v2 (1 x 306)  idle\n",
      "        grad_ssp_upright.fif : PCA-v3 (1 x 306)  idle\n",
      "        grad_ssp_upright.fif : PCA-v4 (1 x 306)  idle\n",
      "        grad_ssp_upright.fif : PCA-v5 (1 x 306)  idle\n",
      "        mag_ssp_upright.fif : PCA-v1 (1 x 306)  idle\n",
      "        mag_ssp_upright.fif : PCA-v2 (1 x 306)  idle\n",
      "        mag_ssp_upright.fif : PCA-v3 (1 x 306)  idle\n",
      "        mag_ssp_upright.fif : PCA-v4 (1 x 306)  idle\n",
      "        mag_ssp_upright.fif : PCA-v5 (1 x 306)  idle\n",
      "        mag_ssp_upright.fif : PCA-v6 (1 x 306)  idle\n",
      "        mag_ssp_upright.fif : PCA-v7 (1 x 306)  idle\n",
      "        mag_ssp_upright.fif : PCA-v8 (1 x 306)  idle\n",
      "Opening raw data file /Volumes/M2_DATA/MEG_QC_stuff/data/openneuro/ds003922/sub-Al150424/ses-01/meg/sub-Al150424_ses-01_task-mcd_run-03_meg.fif...\n",
      "    Read a total of 13 projection items:\n",
      "        grad_ssp_upright.fif : PCA-v1 (1 x 306)  idle\n",
      "        grad_ssp_upright.fif : PCA-v2 (1 x 306)  idle\n",
      "        grad_ssp_upright.fif : PCA-v3 (1 x 306)  idle\n",
      "        grad_ssp_upright.fif : PCA-v4 (1 x 306)  idle\n",
      "        grad_ssp_upright.fif : PCA-v5 (1 x 306)  idle\n",
      "        mag_ssp_upright.fif : PCA-v1 (1 x 306)  idle\n",
      "        mag_ssp_upright.fif : PCA-v2 (1 x 306)  idle\n",
      "        mag_ssp_upright.fif : PCA-v3 (1 x 306)  idle\n",
      "        mag_ssp_upright.fif : PCA-v4 (1 x 306)  idle\n",
      "        mag_ssp_upright.fif : PCA-v5 (1 x 306)  idle\n",
      "        mag_ssp_upright.fif : PCA-v6 (1 x 306)  idle\n",
      "        mag_ssp_upright.fif : PCA-v7 (1 x 306)  idle\n",
      "        mag_ssp_upright.fif : PCA-v8 (1 x 306)  idle\n",
      "    Range : 66000 ... 376999 =     66.000 ...   376.999 secs\n",
      "Ready.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Volumes/MAIN DATA/Users/evgeniiagapontseva/Local/MEG-QC-code/meg_qc/source/initial_meg_qc.py:636: RuntimeWarning: This file contains raw Internal Active Shielding data. It may be distorted. Elekta recommends it be run through MaxFilter to produce reliable results. Consider closing the file and running MaxFilter on the data.\n",
      "  raw = mne.io.read_raw_fif(data_file, allow_maxshield=True, on_split_missing='ignore')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"table table-hover table-striped table-sm table-responsive small\">\n",
       "    <tr>\n",
       "        <th>Measurement date</th>\n",
       "        \n",
       "        <td>December 06, 2016  15:35:17 GMT</td>\n",
       "        \n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Experimenter</th>\n",
       "        \n",
       "        <td>Common</td>\n",
       "        \n",
       "    </tr>\n",
       "        <th>Participant</th>\n",
       "        \n",
       "            \n",
       "        \n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Digitized points</th>\n",
       "        \n",
       "        <td>81 points</td>\n",
       "        \n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Good channels</th>\n",
       "        <td>204 Gradiometers, 102 Magnetometers, 19 Stimulus, 2 EOG, 1 ECG, 14 misc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Bad channels</th>\n",
       "        <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>EOG channels</th>\n",
       "        <td>EOG062, EOG063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>ECG channels</th>\n",
       "        <td>ECG064</td>\n",
       "    \n",
       "    <tr>\n",
       "        <th>Sampling frequency</th>\n",
       "        <td>1000.00 Hz</td>\n",
       "    </tr>\n",
       "    \n",
       "    \n",
       "    <tr>\n",
       "        <th>Highpass</th>\n",
       "        <td>0.10 Hz</td>\n",
       "    </tr>\n",
       "    \n",
       "    \n",
       "    <tr>\n",
       "        <th>Lowpass</th>\n",
       "        <td>330.00 Hz</td>\n",
       "    </tr>\n",
       "    \n",
       "    \n",
       "    <tr>\n",
       "        <th>Projections</th>\n",
       "        <td>grad_ssp_upright.fif : PCA-v1 : off<br/>grad_ssp_upright.fif : PCA-v2 : off<br/>grad_ssp_upright.fif : PCA-v3 : off<br/>grad_ssp_upright.fif : PCA-v4 : off<br/>grad_ssp_upright.fif : PCA-v5 : off<br/>mag_ssp_upright.fif : PCA-v1 : off<br/>mag_ssp_upright.fif : PCA-v2 : off<br/>mag_ssp_upright.fif : PCA-v3 : off<br/>mag_ssp_upright.fif : PCA-v4 : off<br/>mag_ssp_upright.fif : PCA-v5 : off<br/>mag_ssp_upright.fif : PCA-v6 : off<br/>mag_ssp_upright.fif : PCA-v7 : off<br/>mag_ssp_upright.fif : PCA-v8 : off</td>\n",
       "    </tr>\n",
       "    \n",
       "    \n",
       "    <tr>\n",
       "        <th>Filenames</th>\n",
       "        <td>sub-Al150424_ses-01_task-mcd_run-03_meg.fif</td>\n",
       "    </tr>\n",
       "    \n",
       "    <tr>\n",
       "        <th>Duration</th>\n",
       "        <td>00:05:11 (HH:MM:SS)</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Raw | sub-Al150424_ses-01_task-mcd_run-03_meg.fif, 342 x 311000 (311.0 s), ~5.4 MB, data not loaded>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading 0 ... 30000  =      0.000 ...    30.000 secs...\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up low-pass filter at 1.4e+02 Hz\n",
      "\n",
      "IIR filter parameters\n",
      "---------------------\n",
      "Butterworth lowpass zero-phase (two-pass forward and reverse) non-causal filter:\n",
      "- Filter order 8 (effective, after forward-backward)\n",
      "- Cutoff at 140.00 Hz: -6.02 dB\n",
      "\n",
      "___MEG QC___:  Data filtered from 0.0 to 140.0 Hz.\n",
      "Trigger channel has a non-zero initial value of 43 (consider using initial_event=True to detect this event)\n",
      "43 events found\n",
      "Event IDs: [ 1  2 41 43 45 47]\n",
      "Trigger channel has a non-zero initial value of 43 (consider using initial_event=True to detect this event)\n",
      "43 events found\n",
      "Event IDs: [ 1  2 41 43 45 47]\n",
      "___MEG QC___:  Data resampled to 1000 Hz. \n",
      "___MEG QC___:  Stimulus channels detected: ['STI001', 'STI002', 'STI003', 'STI004', 'STI005', 'STI006', 'STI007', 'STI008', 'STI009', 'STI010', 'STI011', 'STI012', 'STI013', 'STI014', 'STI015', 'STI016', 'STI101', 'STI201', 'STI301']\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "Trigger channel has a non-zero initial value of 5 (consider using initial_event=True to detect this event)\n",
      "Removing orphaned offset at the beginning of the file.\n",
      "7 events found\n",
      "Event IDs: [5]\n",
      "Trigger channel has a non-zero initial value of 5 (consider using initial_event=True to detect this event)\n",
      "Removing orphaned offset at the beginning of the file.\n",
      "___MEG QC___:  Could not find events using stimulus channels:  ['STI001', 'STI002', 'STI003', 'STI004', 'STI005', 'STI006', 'STI007', 'STI008', 'STI009', 'STI010', 'STI011', 'STI012', 'STI013', 'STI014', 'STI015', 'STI016', 'STI101', 'STI201', 'STI301'] . Setting stimulus channels to None to alom mne to detect events autamtically\n",
      "Trigger channel has a non-zero initial value of 43 (consider using initial_event=True to detect this event)\n",
      "15 events found\n",
      "Event IDs: [41 42 43 44 45 46]\n",
      "Not setting metadata\n",
      "15 matching events found\n",
      "No baseline correction applied\n",
      "Created an SSP operator (subspace dimension = 8)\n",
      "13 projection items activated\n",
      "Using data from preloaded Raw for 15 events and 1201 original time points ...\n",
      "1 bad epochs dropped\n",
      "Not setting metadata\n",
      "15 matching events found\n",
      "No baseline correction applied\n",
      "Created an SSP operator (subspace dimension = 5)\n",
      "13 projection items activated\n",
      "Using data from preloaded Raw for 15 events and 1201 original time points ...\n",
      "1 bad epochs dropped\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "___MEG QC___:  Finished initial processing. --- Execution 2.8497719764709473 seconds ---\n",
      "___MEG QC___:  Starting Peak-to-Peak manual...\n",
      "___MEG QC___:  5.852375177695782e-12  threshold for NOISY. \n",
      "___MEG QC___:  1.1553142265645478e-12  threshold for FLAT. \n",
      "___MEG QC___:  Finished Peak-to-Peak manual. --- Execution 6.105906963348389 seconds ---\n",
      "___MEG QC___:  Starting ECG...\n",
      "___MEG QC___: Peaks have similar amplitudes, amplitude std:  0.056086407458266485\n",
      "___MEG QC___: There are more than 2 bursts in the data, number:  18\n",
      "___MEG QC___: ECG064 satisfied conditions for a good channel:  (True, True, False)\n",
      "___MEG QC___: Overall bad ECG channel: ECG064\n",
      "___MEG QC___:  ECG channel data is too noisy, cardio artifacts were reconstructed. ECG channel was dropped from the analysis. Consider checking the quality of ECG channel on your recording device. \n",
      "Reconstructing ECG signal from Magnetometers\n",
      "Setting up band-pass filter from 5 - 35 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a two-pass forward and reverse, zero-phase, non-causal bandpass filter:\n",
      "- Windowed frequency-domain design (firwin2) method\n",
      "- Hann window\n",
      "- Lower passband edge: 5.00\n",
      "- Lower transition bandwidth: 0.50 Hz (-12 dB cutoff frequency: 4.75 Hz)\n",
      "- Upper passband edge: 35.00 Hz\n",
      "- Upper transition bandwidth: 0.50 Hz (-12 dB cutoff frequency: 35.25 Hz)\n",
      "- Filter length: 10000 samples (10.000 s)\n",
      "\n",
      "Number of ECG events detected : 26 (average pulse 51 / min.)\n",
      "___MEG QC___:  Mean wave is good enough to use for artifact detection\n",
      "Reconstructing ECG signal from Magnetometers\n",
      "Setting up band-pass filter from 8 - 16 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a two-pass forward and reverse, zero-phase, non-causal bandpass filter:\n",
      "- Windowed frequency-domain design (firwin2) method\n",
      "- Hann window\n",
      "- Lower passband edge: 8.00\n",
      "- Lower transition bandwidth: 0.50 Hz (-12 dB cutoff frequency: 7.75 Hz)\n",
      "- Upper passband edge: 16.00 Hz\n",
      "- Upper transition bandwidth: 0.50 Hz (-12 dB cutoff frequency: 16.25 Hz)\n",
      "- Filter length: 10000 samples (10.000 s)\n",
      "\n",
      "Number of ECG events detected : 28 (average pulse 55 / min.)\n",
      "Not setting metadata\n",
      "28 matching events found\n",
      "No baseline correction applied\n",
      "Created an SSP operator (subspace dimension = 8)\n",
      "Using data from preloaded Raw for 28 events and 161 original time points ...\n",
      "0 bad epochs dropped\n",
      "Not setting metadata\n",
      "28 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "combining channels using \"mean\"\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "Created an SSP operator (subspace dimension = 8)\n",
      "13 projection items activated\n",
      "SSP projectors applied...\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "___MEG QC___:  max_n_peaks_allowed_for_ch: 13\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "t0_time_channels:  0.051000000000000004\n",
      "t0_time_mean:  [-0.071 -0.047  0.03 ]\n",
      "all_corr_values [0.40764214044991803, 0.2262236126240988, 0.2184182011464253, 0.1825433134337847, 0.1803783694969018, 0.16160383386495228, 0.14987539431674182, 0.14179819398114243, 0.13856712226071224, 0.13467314065156463, 0.13223359225940332, 0.1219276748897829, 0.11449794866798836, 0.11293891942679261, 0.11252306912735242, 0.10814661140079167, 0.10489161635415897, 0.10487884965125611, 0.1035251401144615, 0.10266952065727414, 0.09999097632207732, 0.0969310020737348, 0.09529847073572076, 0.0947370035657818, 0.09415590151980656, 0.09374638836461612, 0.09327700931751579, 0.09208156963650968, 0.09167431661325912, 0.09114464102379674, 0.08991930321183676, 0.08922619606331528, 0.08911105225166406, 0.08886784542673148, 0.08772046305313781, 0.08657102118510158, 0.08526588660720481, 0.08399728942271308, 0.08373767751921601, 0.08145444368975277, 0.07974958052130796, 0.07847966094942305, 0.07787594197783872, 0.07765851812294655, 0.07675558057057276, 0.0746667086476692, 0.07454450531541196, 0.07330977843279267, 0.07103088131396276, 0.0690782621625005, 0.06474256545166095, 0.06414453456706098, 0.06403757923110441, 0.06342636282285748, 0.06253052951181137, 0.06056889717857639, 0.059665819163289224, 0.059027125917579956, 0.05893090502438116, 0.05785165581228496, 0.05726537958812099, 0.05683934734104387, 0.05580627187435392, 0.055459668256883296, 0.05285621885899505, 0.05276380568978335, 0.052182339241679795, 0.05196773986615258, 0.05154008504114246, 0.05082371565151251, 0.04721708433451088, 0.044019749355834185, 0.043625041828341864, 0.04323419339700721, 0.04317959778443398, 0.041683509429907, 0.03871373645153007, 0.03845343292569503, 0.0374594750570704, 0.036764320474964085, 0.03406959286911985, 0.03358648946346999, 0.03237587050965471, 0.03147218027191398, 0.031154893380555746, 0.026735176444332914, 0.02412132004389344, 0.023037630453631268, 0.0228898927780243, 0.022844111604692817, 0.018042830060301062, 0.01787425989258022, 0.017870274155453073, 0.017208843156273163, 0.01677543548035604, 0.013737119736484336, 0.009368656078239517, 0.00907401370920031, 0.008537714118449688, 0.007884290129092681, 0.0030061852493729604, 0.0015598305937790822]\n",
      "all_corr_values [0.33437091506445205, 0.30915641258700766, 0.2518328778090869, 0.20428734807656354, 0.19353821358647902, 0.17763640544662934, 0.1630580866556002, 0.1567970551226422, 0.15518367306380465, 0.15449578258152424, 0.14468495880020305, 0.14380331438829833, 0.1385211909066799, 0.1380220837143019, 0.13579514258507533, 0.1324991199047437, 0.13217793680209766, 0.12731544836061462, 0.12483223136243606, 0.12154777397552419, 0.12095792781507028, 0.11843920578396261, 0.11778227583332405, 0.1170771197493099, 0.11007594102713168, 0.1098920991598389, 0.1079018038258551, 0.10408885929538278, 0.10379596365662527, 0.09870150525372295, 0.09716498731703498, 0.09701074858407381, 0.09429876670259317, 0.09317050720341026, 0.09247298251084339, 0.08977589871232396, 0.0887396070406099, 0.0880051074827454, 0.08726773401943091, 0.08694910689590028, 0.08512500313288217, 0.08421792849491266, 0.08198747032228865, 0.08196573259549342, 0.08190808368692375, 0.08151784703664901, 0.08140300595400578, 0.08113213341401544, 0.08033101380146576, 0.07965175360434608, 0.07914712366994735, 0.07897469696436113, 0.07542722809608102, 0.07470089395495298, 0.07321533063979645, 0.07197355264351273, 0.07168641074882823, 0.07157552369441202, 0.06768485012340666, 0.06700518198019546, 0.06695338509893585, 0.0667269181815291, 0.0621733612843266, 0.060977466595389426, 0.05775866565566663, 0.056715232104688346, 0.056377263428323436, 0.055525496262167906, 0.055306173581721844, 0.05434248642537777, 0.053450213780706954, 0.0525766712139225, 0.05206524074426497, 0.051917002729287946, 0.050669316168425974, 0.049684812876490236, 0.04779302091195218, 0.04763370726110867, 0.04760009433626136, 0.04573507337079694, 0.04522137150663637, 0.04363564590136885, 0.043613456566456356, 0.042196868034091235, 0.041164531588631065, 0.039232613466575195, 0.039222520404112775, 0.03873341776265246, 0.03818215658743187, 0.03777484203204362, 0.03747791177149572, 0.03526647533541034, 0.02943642806822168, 0.02818111422203201, 0.02573164743492527, 0.02443542496803123, 0.021472644609777557, 0.01815801903001673, 0.01447840665948178, 0.012195317152616568, 0.0066806481919719, 0.00011804975264668321]\n",
      "all_corr_values [0.21934369175270163, 0.19849799841360627, 0.17385693774969316, 0.17208721190216514, 0.15994057326451214, 0.15799710699566255, 0.15433163648258802, 0.1535350505911623, 0.1453564336385968, 0.1410296490668437, 0.1357722919497616, 0.12447363285881818, 0.12334985837209782, 0.12304862901533097, 0.12182572124968058, 0.1214748319369597, 0.12110864072750711, 0.11665607449058057, 0.11120013104851145, 0.11064313865121207, 0.11003812713874501, 0.10951764092355457, 0.10943985445472594, 0.10943633764302227, 0.10908992179417087, 0.1090891595826998, 0.10859060968068986, 0.10606548029404239, 0.10603058611989008, 0.10429960665234675, 0.10130485851341828, 0.10072289847601607, 0.09769539714544936, 0.0974175202014054, 0.09696835791567485, 0.09573447237878319, 0.09529010744306457, 0.09507576070346935, 0.09479577251908951, 0.09369937681618155, 0.09237059378456199, 0.09230749258950306, 0.09055063846880382, 0.08913845691129217, 0.08597965841072859, 0.0857874747881271, 0.08522814442021401, 0.0847873535774877, 0.08331831985725163, 0.08311103844898143, 0.08302059494117286, 0.08121793080182273, 0.08115130500204257, 0.08090607473257407, 0.08031140275278122, 0.08017241213949856, 0.08012977024181334, 0.08001550185217352, 0.07948461227016598, 0.07774999571128793, 0.07771929223499792, 0.076567113815025, 0.0725088311076331, 0.07240414772839632, 0.07130090761158484, 0.06714701463280023, 0.06695234133211947, 0.06599409366461625, 0.06590727228985653, 0.06586524167547164, 0.06040195344499728, 0.057634205322079766, 0.053748651046018586, 0.053661034880240606, 0.05311201933419128, 0.05208660706600152, 0.050875403610700344, 0.05051582862208291, 0.04991701244723088, 0.04519868670969336, 0.044800138516198185, 0.042012148043062386, 0.04031972162628443, 0.039947392009679374, 0.0370792426715444, 0.035373760009233306, 0.03418491232728273, 0.02856948480869815, 0.0282677859421793, 0.02751633052678059, 0.026302545340134684, 0.02326470405316212, 0.02236934642537137, 0.02147073715769417, 0.02001296711495237, 0.019662656568749833, 0.018789777741858193, 0.016077945560947913, 0.008459563212846632, 0.002671943913399198, 0.0014591259330451588, 0.0007402622961849097]\n",
      "least 0.06590727228985653\n",
      "middle 0.09696835791567485\n",
      "most 0.21934369175270163\n",
      "___MEG QC___:  Finished ECG. --- Execution 2.8974881172180176 seconds ---\n",
      "___MEG QC___:  Starting EOG...\n",
      "___MEG QC___: EOG channel names: ['EOG062', 'EOG063']\n",
      "Using EOG channels: EOG062, EOG063\n",
      "EOG channel index for this subject is: [322 323]\n",
      "Filtering the data to remove DC offset to help distinguish blinks from saccades\n",
      "Setting up band-pass filter from 1 - 10 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a two-pass forward and reverse, zero-phase, non-causal bandpass filter:\n",
      "- Windowed frequency-domain design (firwin2) method\n",
      "- Hann window\n",
      "- Lower passband edge: 1.00\n",
      "- Lower transition bandwidth: 0.50 Hz (-12 dB cutoff frequency: 0.75 Hz)\n",
      "- Upper passband edge: 10.00 Hz\n",
      "- Upper transition bandwidth: 0.50 Hz (-12 dB cutoff frequency: 10.25 Hz)\n",
      "- Filter length: 10000 samples (10.000 s)\n",
      "\n",
      "Now detecting blinks and generating corresponding events\n",
      "Found 11 significant peaks\n",
      "Number of EOG events detected: 11\n",
      "___MEG_QC___: Blinks will be detected based on channel:  EOG062\n",
      "___MEG QC___:  Mean wave is good enough to use for artifact detection\n",
      "Using EOG channels: EOG062, EOG063\n",
      "EOG channel index for this subject is: [322 323]\n",
      "Filtering the data to remove DC offset to help distinguish blinks from saccades\n",
      "Setting up band-pass filter from 1 - 10 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a two-pass forward and reverse, zero-phase, non-causal bandpass filter:\n",
      "- Windowed frequency-domain design (firwin2) method\n",
      "- Hann window\n",
      "- Lower passband edge: 1.00\n",
      "- Lower transition bandwidth: 0.50 Hz (-12 dB cutoff frequency: 0.75 Hz)\n",
      "- Upper passband edge: 10.00 Hz\n",
      "- Upper transition bandwidth: 0.50 Hz (-12 dB cutoff frequency: 10.25 Hz)\n",
      "- Filter length: 10000 samples (10.000 s)\n",
      "\n",
      "Now detecting blinks and generating corresponding events\n",
      "Found 11 significant peaks\n",
      "Number of EOG events detected: 11\n",
      "Not setting metadata\n",
      "11 matching events found\n",
      "No baseline correction applied\n",
      "Created an SSP operator (subspace dimension = 8)\n",
      "Using data from preloaded Raw for 11 events and 601 original time points ...\n",
      "0 bad epochs dropped\n",
      "Not setting metadata\n",
      "11 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "combining channels using \"mean\"\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "Created an SSP operator (subspace dimension = 8)\n",
      "13 projection items activated\n",
      "SSP projectors applied...\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "___MEG QC___:  max_n_peaks_allowed_for_ch: 30\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "least 0.04394125189404298\n",
      "middle 0.09956846301459585\n",
      "most 0.2892374171089007\n",
      "___MEG QC___:  Finished EOG. --- Execution 2.004940986633301 seconds ---\n",
      "Embedding : jquery-3.6.0.min.js\n",
      "Embedding : bootstrap.bundle.min.js\n",
      "Embedding : bootstrap.min.css\n",
      "Embedding : bootstrap-table/bootstrap-table.min.js\n",
      "Embedding : bootstrap-table/bootstrap-table.min.css\n",
      "Embedding : bootstrap-table/bootstrap-table-copy-rows.min.js\n",
      "Embedding : bootstrap-table/bootstrap-table-export.min.js\n",
      "Embedding : bootstrap-table/tableExport.min.js\n",
      "Embedding : bootstrap-icons/bootstrap-icons.mne.min.css\n",
      "Embedding : highlightjs/highlight.min.js\n",
      "Embedding : highlightjs/atom-one-dark-reasonable.min.css\n",
      "Saving report to : /Volumes/M2_DATA/MEG_QC_stuff/data/openneuro/ds003922/derivatives/Meg_QC/sub-Al150424/sub-Al150424_ses-01_acq-crosstalk_desc-REPORTmne_meg.html\n"
     ]
    }
   ],
   "source": [
    "# Import from meg_qc, relative to the path of this file\n",
    "\n",
    "# add meg_qc module to the path\n",
    "\n",
    "from meg_qc.meg_qc_pipeline import make_derivative_meg_qc\n",
    "\n",
    "config_file_path = 'meg_qc/settings.ini' \n",
    "internal_config_file_path='meg_qc/settings_internal.ini' # internal settings in in\n",
    "raw, raw_cropped_filtered_resampled, QC_derivs, QC_simple, df_head_pos, head_pos, scores_muscle_all1, scores_muscle_all2, scores_muscle_all3, raw1, raw2, raw3, avg_ecg, avg_eog = make_derivative_meg_qc(config_file_path, internal_config_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "raw = mne.io.read_raw_fif('/Volumes/M2_DATA/MEG_QC_stuff/data/openneuro/ds003922/sub-Al150424/ses-01/meg/sub-Al150424_ses-01_task-mcd_run-03_meg.fif', allow_maxshield=True)\n",
    "stim=['STI001', 'STI002', 'STI003', 'STI004', 'STI005', 'STI006', 'STI007', 'STI008', 'STI009', 'STI010', 'STI011', 'STI012', 'STI013', 'STI014', 'STI015', 'STI016', 'STI101', 'STI201', 'STI301']\n",
    "\n",
    "mne.find_events(raw, min_duration=0.2, stim_channel=stim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def find_t0_channels(artif_per_ch):\n",
    "\n",
    "    #run peak detection on all channels and find the 5 channels with the highest peaks:\n",
    "    \n",
    "    first_crests = []\n",
    "    first_crests_magnitudes = []\n",
    "\n",
    "    for artif_per_ch.artif_data in artif_per_ch:\n",
    "        peaks_pos_loc = find_peaks(artif_per_ch.artif_data)\n",
    "        peaks_neg_loc = find_peaks(-artif_per_ch.artif_data)\n",
    "        peaks_pos_magn = artif_per_ch.artif_data[peaks_pos_loc]\n",
    "        peaks_neg_magn = artif_per_ch.artif_data[peaks_neg_loc]\n",
    "        #find the highest of all peak_pos:\n",
    "        max_peak_pos_loc = peaks_pos_loc[np.argmax(peaks_pos_magn)]\n",
    "        min_peak_neg_loc = peaks_neg_loc[np.argmin(peaks_neg_magn)]\n",
    "\n",
    "        #put these 2 together and sort by which comes first:\n",
    "        crests = np.sort(np.concatenate((max_peak_pos_loc, min_peak_neg_loc)))\n",
    "\n",
    "        first_crests.append(crests[0])\n",
    "        first_crests_magnitudes.append(artif_per_ch.artif_data[crests[0]])\n",
    "\n",
    "    #find the 5 channels with the highest first_crests_magnitudes:\n",
    "    first_crests_magnitudes = np.array(first_crests_magnitudes)\n",
    "    first_crests = np.array(first_crests)\n",
    "    first_crests_sorted = first_crests[np.argsort(first_crests_magnitudes)]\n",
    "    first_crests_sorted = first_crests_sorted[-5:]\n",
    "\n",
    "    #find the average location of the first crest over the 5 channels:\n",
    "    t0_channels = int(np.mean(first_crests_sorted))\n",
    "\n",
    "    return t0_channels\n",
    "\n",
    "def find_t0_mean(mean_rwave):\n",
    "    \n",
    "    #run peak detection on the mean_rwave and find the first peak:\n",
    "    peaks_pos_loc = find_peaks(mean_rwave)\n",
    "    peaks_neg_loc = find_peaks(-mean_rwave)\n",
    "    peaks_pos_magn = mean_rwave[peaks_pos_loc]\n",
    "    peaks_neg_magn = mean_rwave[peaks_neg_loc]\n",
    "    #find the highest of all peak_pos:\n",
    "    max_peak_pos_loc = peaks_pos_loc[np.argmax(peaks_pos_magn)]\n",
    "    min_peak_neg_loc = peaks_neg_loc[np.argmin(peaks_neg_magn)]\n",
    "\n",
    "    #put these 2 together and sort by which comes first:\n",
    "    crests = np.sort(np.concatenate((max_peak_pos_loc, min_peak_neg_loc)))\n",
    "\n",
    "    t0_mean = crests[0]\n",
    "\n",
    "    return t0_mean\n",
    "\n",
    "\n",
    "def find_t0_shift(t0_channels, t0_mean):\n",
    "    t0_shift = t0_mean - t0_channels\n",
    "    return t0_shift\n",
    "\n",
    "\n",
    "def shift_mean_wave(mean_rwave, t0_shift):\n",
    "    mean_rwave_shifted = np.roll(mean_rwave, t0_shift)\n",
    "    return mean_rwave_shifted\n",
    "\n",
    "#Now plot the mean_rwave_shifted and the mean_rwave on the same plot to see if they are aligned\n",
    "# Plot each of the channels on another plot\n",
    "\n",
    "def plot_mean_rwave_shifted(mean_rwave_shifted, mean_rwave):\n",
    "    #plot using plotly\n",
    "\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Scatter(x=np.arange(len(mean_rwave_shifted)), y=mean_rwave_shifted, mode='lines', name='mean_rwave_shifted'))\n",
    "    fig.add_trace(go.Scatter(x=np.arange(len(mean_rwave)), y=mean_rwave, mode='lines', name='mean_rwave'))\n",
    "    fig.show()\n",
    "\n",
    "def plot_channels(artif_per_ch):\n",
    "    #plot using plotly\n",
    "\n",
    "    fig = go.Figure()\n",
    "    for artif_per_ch.artif_data in artif_per_ch:\n",
    "        fig.add_trace(go.Scatter(x=np.arange(len(artif_per_ch.artif_data)), y=artif_per_ch.artif_data, mode='lines', name='artif_per_ch.artif_data'))\n",
    "    fig.show()\n",
    "\n",
    "def align_mean_rwave(mean_rwave, artif_per_ch):\n",
    "\n",
    "    #Get 5 highest channels.\n",
    "    #get highest positive peak and highest negative peak\n",
    "    # put them in list sorted by which peak comes first\n",
    "\n",
    "    #calculate average location of the 1st peak over 5 channels and set it as t0\n",
    "\n",
    "    #do the same for the mean wave. set it s first peak as t0\n",
    "\n",
    "    #calculate time shift between the two t0s\n",
    "\n",
    "    #shift the mean wave by the time shift\n",
    "\n",
    "    t0_channels = find_t0_channels(artif_per_ch)\n",
    "    t0_mean = find_t0_mean(mean_rwave)\n",
    "    t0_shift = find_t0_shift(t0_channels, t0_mean)\n",
    "    mean_rwave_shifted = shift_mean_wave(mean_rwave, t0_shift)\n",
    "    plot_mean_rwave_shifted(mean_rwave_shifted, mean_rwave)\n",
    "    plot_channels(artif_per_ch)\n",
    "\n",
    "    return mean_rwave_shifted\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Aligned Wave Shapes:\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "# Generate two aligned wave shapes\n",
    "time = np.linspace(0, 1, 100)\n",
    "wave1 = np.sin(2 * np.pi * 2 * time)\n",
    "wave2 = np.sin(2 * np.pi * 2 * time)\n",
    "\n",
    "# Calculate correlation\n",
    "correlation = np.correlate(wave1, wave2, mode='same')\n",
    "corr1 = pearsonr(wave1, wave2)\n",
    "print(corr1)\n",
    "\n",
    "# Plot the wave shapes and correlation\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(time, wave1)\n",
    "plt.title('Wave 1')\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(time, wave2)\n",
    "plt.title('Wave 2')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#Misaligned Wave Shapes:\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Generate two misaligned wave shapes\n",
    "time = np.linspace(0, 1, 100)\n",
    "wave1 = np.sin(2 * np.pi * 2 * time)\n",
    "wave2 = np.sin(2 * np.pi * 2 * (time + 0.15))  # Shifted by 0.2 seconds\n",
    "\n",
    "# Calculate correlation\n",
    "correlation = np.correlate(wave1, wave2, mode='same')\n",
    "corr2 = pearsonr(wave1, wave2)\n",
    "print(corr2)\n",
    "\n",
    "# Plot the wave shapes and correlation\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(time, wave1)\n",
    "plt.title('Wave 1')\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(time, wave2)\n",
    "plt.title('Wave 2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create wave shapes\n",
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "\n",
    "# Define the number of points in each array\n",
    "num_points = 100\n",
    "\n",
    "# Create an array of time values\n",
    "t = np.linspace(0, 2*np.pi, num_points)\n",
    "\n",
    "# Define the amplitudes for the R-wave shapes\n",
    "amplitudes = [1.0, 1.5, 2.0, 2.5, 3.0, 3.5]\n",
    "\n",
    "# Define the maximum time shift in seconds\n",
    "max_shift = 0.4\n",
    "\n",
    "# Create five arrays with R-wave shapes, shifted in time\n",
    "waves = []\n",
    "for i, amplitude in enumerate(amplitudes):\n",
    "    # Generate a random time shift within the maximum shift range\n",
    "    time_shift = np.random.uniform(-max_shift, max_shift)\n",
    "    \n",
    "    # Shift the time values\n",
    "    shifted_t = t + time_shift\n",
    "    \n",
    "    # Create the R-wave shape with the shifted time values\n",
    "    wave = np.exp(-shifted_t) * np.sin(4*shifted_t) * amplitude\n",
    "    #waves.append(wave)\n",
    "    waves.append(wave[::-1])\n",
    "\n",
    "\n",
    "fig = go.Figure()\n",
    "for i, wave in enumerate(waves):\n",
    "    fig.add_trace(go.Scatter(x=time, y=wave, name=f'Wave {i+1}'))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Assuming you have two arrays: array1 and array2\n",
    "array1 = waves[0]\n",
    "array2 = waves[5]\n",
    "\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "from scipy.signal import find_peaks\n",
    "\n",
    "# Assuming you have two arrays: array1 and array2\n",
    "\n",
    "# Find peaks in both arrays\n",
    "peaks1, _ = find_peaks(array1)\n",
    "peaks2, _ = find_peaks(array2)\n",
    "\n",
    "# Calculate the time shift based on the peak positions\n",
    "time_shift = peaks1[0] - peaks2[0]\n",
    "\n",
    "# Shift array2 to align with array1\n",
    "aligned_array2 = np.roll(array2, time_shift)\n",
    "\n",
    "# Create the figure\n",
    "fig = go.Figure()\n",
    "\n",
    "# Add the array1 trace\n",
    "fig.add_trace(go.Scatter(x=np.arange(len(array1)), y=array1, name='Array 1'))\n",
    "\n",
    "# Add the array2 trace\n",
    "fig.add_trace(go.Scatter(x=np.arange(len(array2)), y=array2, name='Array 2'))\n",
    "\n",
    "# Add the aligned_array2 trace\n",
    "fig.add_trace(go.Scatter(x=np.arange(len(aligned_array2)), y=aligned_array2, name='Aligned Array 2'))\n",
    "\n",
    "# Set the layout\n",
    "fig.update_layout(title='Aligned Arrays using Peak Detection',\n",
    "                  xaxis_title='Time',\n",
    "                  yaxis_title='Amplitude')\n",
    "\n",
    "# Show the figure\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "from scipy.signal import find_peaks\n",
    "\n",
    "array1 = waves[0]\n",
    "array2 = -waves[5]\n",
    "\n",
    "# Create the figure\n",
    "fig = go.Figure()\n",
    "\n",
    "# Add the array1 trace\n",
    "fig.add_trace(go.Scatter(x=np.arange(len(array1)), y=array1, name='Array 1'))\n",
    "\n",
    "# Add the array2 trace\n",
    "fig.add_trace(go.Scatter(x=np.arange(len(array2)), y=array2, name='Array 2'))\n",
    "\n",
    "# Set the layout\n",
    "fig.update_layout(title='Aligned Arrays using Peak Detection',\n",
    "                  xaxis_title='Time',\n",
    "                  yaxis_title='Amplitude')\n",
    "\n",
    "# Show the figure\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Assuming you have two arrays: array1 and array2\n",
    "\n",
    "# Find peaks in array1\n",
    "peaks1, _ = find_peaks(array1)\n",
    "\n",
    "# Initialize variables for best alignment\n",
    "best_time_shift = 0\n",
    "best_correlation = -np.inf\n",
    "best_aligned_array2 = None\n",
    "\n",
    "# Try aligning array2 in both orientations\n",
    "for flip in [False, True]:\n",
    "    # Flip array2 if needed\n",
    "    #aligned_array2 = np.flip(array2) if flip else array2\n",
    "    aligned_array2 = -array2 if flip else array2\n",
    "\n",
    "    # Find peaks in aligned_array2\n",
    "    peaks2, _ = find_peaks(aligned_array2)\n",
    "\n",
    "    # Calculate the time shift based on the peak positions\n",
    "    time_shift = peaks1[0] - peaks2[0]\n",
    "\n",
    "    # Shift aligned_array2 to align with array1\n",
    "    aligned_array2 = np.roll(aligned_array2, time_shift)\n",
    "\n",
    "    # Calculate the correlation between array1 and aligned_array2\n",
    "    correlation = np.corrcoef(array1, aligned_array2)[0, 1]\n",
    "\n",
    "    # Update the best alignment if the correlation is higher\n",
    "    if correlation > best_correlation:\n",
    "        best_correlation = correlation\n",
    "        best_time_shift = time_shift\n",
    "        best_aligned_array2 = aligned_array2\n",
    "\n",
    "# Create the figure\n",
    "fig = go.Figure()\n",
    "\n",
    "# Add the array1 trace\n",
    "fig.add_trace(go.Scatter(x=np.arange(len(array1)), y=array1, name='Array 1'))\n",
    "\n",
    "# Add the array2 trace\n",
    "fig.add_trace(go.Scatter(x=np.arange(len(array2)), y=array2, name='Array 2'))\n",
    "\n",
    "# Add the best_aligned_array2 trace\n",
    "fig.add_trace(go.Scatter(x=np.arange(len(best_aligned_array2)), y=best_aligned_array2, name='Aligned Array 2'))\n",
    "\n",
    "# Set the layout\n",
    "fig.update_layout(title='Aligned Arrays with Flipped Second Array',\n",
    "                  xaxis_title='Time',\n",
    "                  yaxis_title='Amplitude')\n",
    "\n",
    "# Show the figure\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.signal import find_peaks\n",
    "\n",
    "avg_ecg_epoch_data_nonflipped_limited_to_event = np.array(waves)\n",
    "\n",
    "max_values=np.max(np.abs(avg_ecg_epoch_data_nonflipped_limited_to_event), axis=1)\n",
    "print(max_values)\n",
    "max_values_ind=np.argsort(max_values)[::-1] \n",
    "print(max_values_ind)\n",
    "max_values_ind=max_values_ind[:5]\n",
    "\n",
    "chosen_5 = (avg_ecg_epoch_data_nonflipped_limited_to_event[max_values_ind])\n",
    "\n",
    "thresh_lvl_peakfinder = 5\n",
    "\n",
    "\n",
    "#get the highest peak for every channel:\n",
    "max_amplitude1 = []\n",
    "index_of_max_amplitude1=[]\n",
    "for ch_data in avg_ecg_epoch_data_nonflipped_limited_to_event:\n",
    "\n",
    "    thresh_mean=(max(ch_data) - min(ch_data)) / thresh_lvl_peakfinder\n",
    "    peak_locs_pos, _ = find_peaks(ch_data, prominence=thresh_mean)\n",
    "    peak_locs_neg, _ = find_peaks(-ch_data, prominence=thresh_mean)\n",
    "\n",
    "    all_peaks = np.concatenate((peak_locs_pos, peak_locs_neg))\n",
    "    print('all peaks', all_peaks)\n",
    "\n",
    "    #Find the peak with the maximal amplitude:\n",
    "\n",
    "    max_amplitude_peak = np.argmax(np.abs(ch_data[all_peaks]))\n",
    "\n",
    "    #now find the index of this point in the channel data:\n",
    "    index_of_max_amplitude1.append(all_peaks[max_amplitude_peak])\n",
    "\n",
    "    print('Index1', index_of_max_amplitude1)\n",
    "\n",
    "    #now find the magnitude of the data in this point:\n",
    "\n",
    "    max_amplitude1.append(ch_data[index_of_max_amplitude1[-1]])\n",
    "\n",
    "    \n",
    "\n",
    "# find 5 channels which have the highest peaks and get the locations of these peaks:\n",
    "highest_channels_sorted = np.argsort(max_amplitude1)[::-1] \n",
    "print(highest_channels_sorted)\n",
    "max_ind_of_chosen_5=highest_channels_sorted[:5]\n",
    "\n",
    "print(max_ind_of_chosen_5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_of_max_amplitude2=[]\n",
    "for ch_data in max_ind_of_chosen_5:\n",
    "\n",
    "    thresh_mean=(max(ch_data) - min(ch_data)) / thresh_lvl_peakfinder\n",
    "    peak_locs_pos, _ = find_peaks(ch_data, prominence=thresh_mean)\n",
    "    peak_locs_neg, _ = find_peaks(-ch_data, prominence=thresh_mean)\n",
    "\n",
    "    all_peaks = np.concatenate((peak_locs_pos, peak_locs_neg))\n",
    "    print('all peaks', all_peaks)\n",
    "\n",
    "    #Find the peak with the maximal amplitude:\n",
    "\n",
    "    max_amplitude_peak = np.argmax(np.abs(ch_data[all_peaks]))\n",
    "\n",
    "\n",
    "    #6. Output the index of the point with the maximal amplitude:\n",
    "\n",
    "    index_of_max_amplitude1.append(all_peaks[max_amplitude_peak])\n",
    "    print('Index1', index_of_max_amplitude1)\n",
    "\n",
    "    if len(all_peaks)>1:\n",
    "        #7. Now find the second largest peak:\n",
    "        all_peaks_without_max = np.delete(all_peaks, max_amplitude_peak)\n",
    "\n",
    "        print('no max', all_peaks_without_max)\n",
    "\n",
    "        max_amplitude_peak = np.argmax(np.abs(ch_data[all_peaks_without_max]))\n",
    "\n",
    "\n",
    "        #6. Output the index of the point with the maximal amplitude:\n",
    "\n",
    "        index_of_max_amplitude2.append(all_peaks_without_max[max_amplitude_peak])\n",
    "        print('Index2', index_of_max_amplitude2)\n",
    "        \n",
    "    else:\n",
    "        index_of_max_amplitude2.append(np.nan)\n",
    "\n",
    "mean_index_of_max_amplitude1 = np.nanmean(index_of_max_amplitude1)\n",
    "\n",
    "# If in more than a half of cases there was no second biggest peak found, skip it and assign t) as first peak:\n",
    "non_zero_count = np.count_nonzero(index_of_max_amplitude2)\n",
    "percentage = (non_zero_count/len(index_of_max_amplitude2)) * 100\n",
    "\n",
    "if percentage < 50:\n",
    "    t0_peak = int(mean_index_of_max_amplitude1)\n",
    "else:\n",
    "    mean_index_of_max_amplitude2 = np.nanmean(index_of_max_amplitude2)\n",
    "    #Now out of them set the first peak (according to time) as t0.\n",
    "    t0_peak = int(np.nanmin([mean_index_of_max_amplitude1, mean_index_of_max_amplitude2]))\n",
    "\n",
    "\n",
    "print('mean_ind1', mean_index_of_max_amplitude1)\n",
    "print('mean_ind2', mean_index_of_max_amplitude2)\n",
    "\n",
    "\n",
    "print(t0_peak)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "arr = np.array([5, 2, 9, 1, 7, 3])\n",
    "\n",
    "# Get the indices that would sort the array in ascending order\n",
    "sorted_indices = np.argsort(arr)\n",
    "\n",
    "# Index of the largest value\n",
    "largest_index = sorted_indices[-1]\n",
    "\n",
    "# Index of the second largest value\n",
    "second_largest_index = sorted_indices[-2]\n",
    "\n",
    "print(\"Index of the largest value:\", largest_index)\n",
    "print(\"Index of the second largest value:\", second_largest_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "from IPython.display import display\n",
    "\n",
    "# Load the MEG data\n",
    "raw=mne.io.read_raw_fif('/Volumes/M2_DATA/MEG_QC_stuff/data/openneuro/ds004107/sub-mind002/ses-01/meg/sub-mind002_ses-01_task-auditory_meg.fif', preload=True)\n",
    "\n",
    "display(raw)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the EOG channel names\n",
    "eog_channels = ['EOG 061', 'EOG 062']\n",
    "\n",
    "# extract the data of 2 EOG channels\n",
    "eog_data = raw.copy().pick_channels(eog_channels).get_data()\n",
    "\n",
    "print(eog_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Plot the data with plotly:\n",
    "\n",
    "import plotly.graph_objs as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Create a figure with two subplots\n",
    "fig = make_subplots(rows=2, cols=1)\n",
    "\n",
    "x_values = raw.times\n",
    "\n",
    "# Add a trace for the first subplot\n",
    "fig.add_trace(go.Scatter(x=x_values, y=eog_data[0], mode='lines', name='EOG 1'), row=1, col=1)\n",
    "\n",
    "# Add a trace for the second subplot\n",
    "fig.add_trace(go.Scatter(x=x_values, y=eog_data[1], mode='lines', name='EOG 2'), row=2, col=1)\n",
    "\n",
    "# Update the layout\n",
    "fig.update_layout(title='EOG Data', xaxis_title='Time (s)', yaxis_title='Amplitude')\n",
    "\n",
    "# Show the figure\n",
    "fig.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# create two arrays\n",
    "array1 = np.array([1, 2, 3, 4, 5])\n",
    "array2 = np.array([6, 7, 8, 9, 10])\n",
    "\n",
    "# stack the arrays horizontally\n",
    "stacked = np.stack((array1, array2), axis=0)\n",
    "\n",
    "display(stacked)\n",
    "\n",
    "# calculate the covariance matrix\n",
    "covariance_matrix = np.cov(stacked)\n",
    "\n",
    "print(covariance_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "import numpy as np\n",
    "from scipy.signal import find_peaks\n",
    "\n",
    "# Load the MEG data\n",
    "raw = mne.io.read_raw_fif('/Volumes/M2_DATA/MEG_QC_stuff/data/openneuro/ds003703/sub-a68d5xp5/meg/sub-a68d5xp5_task-listeningToSpeech_run-01_meg.fif')\n",
    "#raw=mne.io.read_raw_fif('/Volumes/M2_DATA/MEG_QC_stuff/data/openneuro/ds004107/sub-mind002/ses-01/meg/sub-mind002_ses-01_task-auditory_meg.fif', preload=True)\n",
    "\n",
    "# Select the EOG channels\n",
    "eog_channels = mne.pick_types(raw.info, meg=False, eeg=False, stim=False, eog=True)\n",
    "\n",
    "# Get the names of the EOG channels\n",
    "eog_channel_names = [raw.ch_names[ch] for ch in eog_channels]\n",
    "\n",
    "print('EOG channel names:', eog_channel_names)\n",
    "\n",
    "eog_events = mne.preprocessing.find_eog_events(raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "picks_ECG = mne.pick_types(raw.info, ecg=True)\n",
    "ecg_ch_name = [raw.info['chs'][name]['ch_name'] for name in picks_ECG]\n",
    "\n",
    "arr=raw.get_data(picks=ecg_ch_name)[0] \n",
    "height = np.mean(arr) + 1 * np.std(arr)\n",
    "fs=raw.info['sfreq']\n",
    "peaks, _ = find_peaks(arr, height=height, distance=round(0.5 * fs)) #assume there are no peaks within 0.5 seconds from each other.\n",
    "ecg_events = peaks/fs\n",
    "\n",
    "# Define the time window of interest\n",
    "time_window = [0.2, 0.2]  # in seconds\n",
    "tmin=-0.2\n",
    "tmax=0.2\n",
    "\n",
    "# Convert time window to samples\n",
    "sfreq = 1000  # sampling frequency of your data\n",
    "time_window_samples = np.round(np.array(time_window) * sfreq).astype(int)\n",
    "print('samples', time_window_samples)\n",
    "\n",
    "# Initialize an empty array to store the extracted epochs\n",
    "epochs = np.zeros((len(peaks), int((tmax-tmin)*sfreq)))\n",
    "\n",
    "print('HERE')\n",
    "print(arr)\n",
    "print(epochs)\n",
    "\n",
    "# Loop through each ECG event and extract the corresponding epoch\n",
    "for i, event in enumerate(peaks):\n",
    "    start = event - time_window_samples[0]\n",
    "    start = np.round(event + tmin*sfreq).astype(int)\n",
    "    end = event + time_window_samples[1]\n",
    "    end= np.round(event + tmax*sfreq).astype(int)\n",
    "    epochs[i, :] = arr[start:end]\n",
    "\n",
    "#average all epochs:\n",
    "avg_ecg=np.mean(epochs, axis=0)\n",
    "\n",
    "#print average ecg with plotly:\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "fig = go.Figure()\n",
    "#create time vector based on time window and sampling frequency:\n",
    "times= np.arange(tmin, tmax, 1/sfreq)\n",
    "fig.add_trace(go.Scatter(x=times, y=avg_ecg, mode='lines', name='ECG'))\n",
    "fig.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Detect the R-wave peaks in the filtered ECG channel data\n",
    "r_peaks, ch_ecg, pulse, ecg_data_rec = mne.preprocessing.find_ecg_events(raw, return_ecg=True)\n",
    "print(ecg_data_rec)\n",
    "\n",
    "#plot the ECG data with plotly:\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "times=[t for t in range(len(ecg_data_rec[0]))]\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=times, y=ecg_data_rec[0], mode='lines', name='ECG'))\n",
    "fig.update_layout(title='ECG data', xaxis_title='Time (s)', yaxis_title='ECG (mV)')\n",
    "fig.show()\n",
    "\n",
    "# Calculate the time difference between each R-wave peak and the first R-wave peak\n",
    "r_wave_epochs = (r_peaks - r_peaks[0]) / raw.info['sfreq']\n",
    "print('r_wave_epochs', r_wave_epochs)\n",
    "\n",
    "# Calculate the average R-wave epoch\n",
    "avg_r_wave_epoch = np.mean(r_wave_epochs)\n",
    "print('avg_r_wave_epoch', avg_r_wave_epoch)\n",
    "\n",
    "if ecg_ch_name:\n",
    "    # Extract the ECG channel data\n",
    "    ecg_data, times = raw.get_data(ecg_ch_name, return_times=True)\n",
    "    ecg_data2=ecg_data_rec\n",
    "else:\n",
    "    ecg_data=ecg_data_rec\n",
    "\n",
    "\n",
    "\n",
    "# Use the average R-wave epoch to extract a segment of data from the ECG channel\n",
    "avg_r_wave_data = ecg_data[:, int(avg_r_wave_epoch * raw.info['sfreq']) : int((avg_r_wave_epoch + 0.2) * raw.info['sfreq'])]\n",
    "avg_r_wave_data2 = ecg_data2[:, int(avg_r_wave_epoch * raw.info['sfreq']) : int((avg_r_wave_epoch + 0.2) * raw.info['sfreq'])]\n",
    "\n",
    "#plot the average R-wave epoch with plotly:\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "times=[t/raw.info['sfreq'] for t in range(len(avg_r_wave_data[0]))]\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=times, y=avg_r_wave_data[0], mode='lines', name='ECG'))\n",
    "fig.add_trace(go.Scatter(x=times, y=avg_r_wave_data2[0], mode='lines', name='ECG2'))\n",
    "fig.update_layout(title='Average R-wave epoch', xaxis_title='Time (s)', yaxis_title='ECG (mV)')\n",
    "fig.show()\n",
    "\n",
    "raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print([t/raw.info['sfreq'] for t in range(len(avg_r_wave_data[0]))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecg_data\n",
    "avg_r_wave_epoch * raw.info['sfreq']\n",
    "r_peaks[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_r_wave_data = ecg_data[:, int(avg_r_wave_epoch * raw.info['sfreq']) : int((avg_r_wave_epoch + 0.2) * raw.info['sfreq'])]\n",
    "avg_r_wave_data2 = ecg_data2[:, int(avg_r_wave_epoch * raw.info['sfreq']) : int((avg_r_wave_epoch + 0.2) * raw.info['sfreq'])]\n",
    "\n",
    "#plot the average R-wave epoch with plotly:\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "times=[t/raw.info['sfreq'] for t in range(len(avg_r_wave_data[0]))]\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=times, y=avg_r_wave_data[0], mode='lines', name='ECG'))\n",
    "fig.add_trace(go.Scatter(x=times, y=avg_r_wave_data2[0], mode='lines', name='ECG2'))\n",
    "fig.update_layout(title='Average R-wave epoch', xaxis_title='Time (s)', yaxis_title='ECG (mV)')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "# Generate two waves\n",
    "wave1 = np.array([1, 2, 3, 4, 5])\n",
    "wave2 = np.array([2, 4, 6, 8, 10])\n",
    "\n",
    "# Calculate the Pearson correlation coefficient and p-value\n",
    "corr_coef, p_value = pearsonr(wave1, wave2)\n",
    "\n",
    "# Print the results\n",
    "print(\"Pearson correlation coefficient:\", corr_coef)\n",
    "print(\"p-value:\", p_value)\n",
    "\n",
    "\n",
    "#plot both waves with plotly:\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(y=wave1, mode='lines', name='wave1'))\n",
    "fig.add_trace(go.Scatter(y=wave2, mode='lines', name='wave2'))\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "lobe_colors = {\n",
    "        'Left Frontal': '#1f77b4',\n",
    "        'Right Frontal': '#ff7f0e',\n",
    "        'Left Temporal': '#2ca02c',\n",
    "        'Right Temporal': '#9467bd',\n",
    "        'Left Parietal': '#e377c2',\n",
    "        'Right Parietal': '#d62728',\n",
    "        'Left Occipital': '#bcbd22',\n",
    "        'Right Occipital': '#17becf'}\n",
    "\n",
    "print(random.choice(list(lobe_colors.values())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage import gaussian_filter\n",
    "import numpy as np\n",
    "\n",
    "# Generate some noisy wave data\n",
    "x = np.linspace(0, 2*np.pi, 100)\n",
    "y = np.sin(x) + np.random.normal(0, 0.5, 100)\n",
    "\n",
    "# Apply Gaussian smoothing with a sigma of 2\n",
    "y_smooth = gaussian_filter(y, sigma=4)\n",
    "\n",
    "# Plot the original and smoothed waves\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(x, y, label='Noisy wave')\n",
    "plt.plot(x, y_smooth, label='Smoothed wave')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objs as go\n",
    "import pandas as pd\n",
    "\n",
    "# create sample data\n",
    "df = pd.DataFrame({'values': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]}, index=['A']*10)\n",
    "df = df.T\n",
    "print(df)\n",
    "\n",
    "# create box plot trace\n",
    "box_trace = go.Box(x=df.iloc[0], orientation='h')\n",
    "#box_trace = go.Box(x=df['values'], y=df.index, orientation='h', name='')\n",
    "\n",
    "fig = go.Figure(data=box_trace)\n",
    "\n",
    "for col in df.columns:\n",
    "    fig.add_trace(go.Scatter(x=df[col], name=col))\n",
    "\n",
    "# for v in df['values']:\n",
    "#     #fig.add_trace(go.Scatter(x=df['values'], y=df.index, mode='markers', marker=dict(size=5, color='yellow'), name='Scatter Plot', hovertext=df.index))\n",
    "#     fig.add_trace(go.Scatter(x=[v], y=['A'], mode='markers', marker=dict(size=5, color='yellow'), name='Scatter Plot', hovertext=df.index))\n",
    "\n",
    "# plot figure\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objs as go\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "# Add box plot trace\n",
    "fig.add_trace(go.Box(x=[1, 2, 3, 4, 5]))\n",
    "\n",
    "# Add horizontal line at y=0\n",
    "fig.update_layout(\n",
    "    shapes=[\n",
    "        dict(\n",
    "            type='line',\n",
    "            yref='y',\n",
    "            y0=0,\n",
    "            y1=0,\n",
    "            xref='paper',\n",
    "            x0=0,\n",
    "            x1=1\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Create example dataset\n",
    "np.random.seed(123)\n",
    "std_val = pd.DataFrame({'Group': ['A', 'A', 'B', 'B', 'C', 'C'],\n",
    "                     'Value': np.random.normal(size=6)})\n",
    "\n",
    "# Create box plot with custom marker colors\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Box(x=std_val['Group'], y=std_val['Value'], name='Value',\n",
    "                     marker=dict(color='red')))\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(title='Box plot with custom marker colors',\n",
    "                  xaxis_title='Group', yaxis_title='Value')\n",
    "\n",
    "# Show the plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objs as go\n",
    "\n",
    "# create a box plot with custom marker color\n",
    "trace = go.Box(\n",
    "    y=[1, 2, 3, 4, 5],\n",
    "    marker=dict(\n",
    "        color='blue'\n",
    "    )\n",
    ")\n",
    "\n",
    "# create a figure and add the box plot trace\n",
    "fig = go.Figure(data=[trace])\n",
    "\n",
    "# show the figure\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This here is to save all the average ECG/EOG data into a pickle file, so I can test difefrent wave detection algorythms on them without running the pipeline again\n",
    "\n",
    "import pickle \n",
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# open a file in write binary mode\n",
    "with open(\"avg_ecg.pkl\", \"wb\") as f:\n",
    "    # dump the list of objects into the file\n",
    "    pickle.dump(avg_ecg, f)\n",
    "\n",
    "with open(\"avg_eog.pkl\", \"wb\") as f:\n",
    "    # dump the list of objects into the file\n",
    "    pickle.dump(avg_eog, f)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This here is to open the pickle files from above and plot the data\n",
    "\n",
    "import pickle \n",
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "\n",
    "# open the file in read binary mode\n",
    "with open(\"avg_ecg0.pkl\", \"rb\") as f:\n",
    "    # load the list of objects from the file\n",
    "    eog_list = pickle.load(f)\n",
    "\n",
    "print(eog_list[0])\n",
    "\n",
    "sfreq=1000\n",
    "t = np.round(np.arange(-0.4, 0.4+1/sfreq, 1/sfreq), 3) #yes, you need to round\n",
    "fig0=go.Figure()\n",
    "for x in range(0, len(eog_list)):\n",
    "    fig_temp=eog_list[x].plot_epoch_and_peak(t, 'Channels affected by ECG artifact: ', 'mag', fig0)\n",
    "    for trace in fig_temp['data']:\n",
    "        fig0.add_trace(trace)\n",
    "\n",
    "fig0.update_layout(\n",
    "    yaxis = dict(\n",
    "            showexponent = 'all',\n",
    "            exponentformat = 'e')) \n",
    "fig0.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same for EOG\n",
    "\n",
    "import pickle \n",
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "from scipy.ndimage import gaussian_filter\n",
    "\n",
    "\n",
    "# open the file in read binary mode\n",
    "with open(\"avg_eog0.pkl\", \"rb\") as f:\n",
    "    # load the list of objects from the file\n",
    "    eog_list = pickle.load(f)\n",
    "\n",
    "sfreq=1000\n",
    "t = np.round(np.arange(-0.4, 0.4+1/sfreq, 1/sfreq), 3) #yes, you need to round\n",
    "fig0=go.Figure()\n",
    "for x in range(0, len(eog_list)):\n",
    "    fig_temp=eog_list[x].plot_epoch_and_peak(t, 'Channels affected by ECG artifact: ', 'mag')\n",
    "    for trace in fig_temp['data']:\n",
    "        fig0.add_trace(trace)\n",
    "\n",
    "fig0.update_layout(\n",
    "    yaxis = dict(\n",
    "            showexponent = 'all',\n",
    "            exponentformat = 'e')) \n",
    "fig0.show()\n",
    "\n",
    "#Now apply the gaussia filter to each trace and plot result in the same figure:\n",
    "fig0_new=deepcopy(fig0)\n",
    "for trace in fig0_new['data']:\n",
    "    y=trace['y']\n",
    "    y_smooth = gaussian_filter(y, sigma=10)\n",
    "    trace['y']=y_smooth\n",
    "\n",
    "fig0_new.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "raw = mne.io.read_raw_fif('/Volumes/M2_DATA/MEG_QC_stuff/data/Jochem/LeerraumAarhus2017/sub-emptyroom/meg/sub-emptyroom_task-Aarhus_meg.fif', preload=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#show sensor posiions using mne:\n",
    "\n",
    "import mne\n",
    "\n",
    "raw = mne.io.read_raw_fif('/Volumes/M2_DATA/MEG_QC_stuff/data/Jochem/LeerraumAarhus2017/sub-emptyroom/meg/sub-emptyroom_task-Aarhus_meg.fif', preload=True)\n",
    "\n",
    "mne.viz.plot_sensors(raw.info, kind='topomap', ch_type='grad', show_names=True, ch_groups='position')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PLOT SENSORS IN 2D with plotly\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "import mne\n",
    "\n",
    "raw = mne.io.read_raw_fif('/Volumes/M2_DATA/MEG_QC_stuff/data/Jochem/LeerraumAarhus2017/sub-emptyroom/meg/sub-emptyroom_task-Aarhus_meg.fif', preload=True)\n",
    "\n",
    "\n",
    "mag_ch_names = raw.copy().pick_types(meg='mag').ch_names if 'mag' in raw else None\n",
    "grad_ch_names = raw.copy().pick_types(meg='grad').ch_names if 'grad' in raw else None\n",
    "channels_objs = {'mag': mag_ch_names, 'grad': grad_ch_names}\n",
    "\n",
    "# Get the sensor locations\n",
    "sensor_locs = raw.info['chs']\n",
    "#print(sensor_locs)\n",
    "#coords_mag=[loc['loc'][:2] for loc in sensor_locs]\n",
    "coords_mag=[loc['loc'] for loc in sensor_locs if loc['ch_name'] in mag_ch_names]\n",
    "#print(len(coords), coords)\n",
    "print(len(coords_mag), coords_mag)\n",
    "\n",
    "x = [r[0] for r in coords_mag]\n",
    "y = [r[1] for r in coords_mag]\n",
    "#x, y, z = [loc['loc'][:3] for loc in sensor_locs]\n",
    "names = [loc['ch_name'] for loc in sensor_locs if loc['ch_name'] in mag_ch_names]\n",
    "kinds= [loc['kind'] for loc in sensor_locs]\n",
    "print(kinds)\n",
    "\n",
    "# Create a scatter plot of the sensor locations\n",
    "fig = go.Figure(data=go.Scatter(x=x, y=y, mode='markers', text=names))\n",
    "\n",
    "fig.update_layout(\n",
    "    autosize=False,\n",
    "    width=1000,\n",
    "    height=1000)\n",
    "\n",
    "# Set the plot title and axis labels\n",
    "fig.update_layout(title='MEG Sensor Locations', xaxis_title='X', yaxis_title='Y')\n",
    "\n",
    "# Add a circle shape to the plot to show the position of the head\n",
    "fig.update_layout(\n",
    "    shapes=[\n",
    "        dict(\n",
    "            type='circle',\n",
    "            xref='x',\n",
    "            yref='y',\n",
    "            x0=-0.1,\n",
    "            y0=-0.1,\n",
    "            x1=0.1,\n",
    "            y1=0.12,\n",
    "            line=dict(color='red', width=2),\n",
    "            opacity=0.5\n",
    "        ),\n",
    "        dict(\n",
    "            type='line',\n",
    "            xref='x',\n",
    "            yref='y',\n",
    "            x0=[0, -0.02],\n",
    "            y0=[0.1, 0.08],\n",
    "            line=dict(color='black', width=2)\n",
    "        ),\n",
    "        dict(\n",
    "            type='line',\n",
    "            xref='x',\n",
    "            yref='y',\n",
    "            x0=[0, 0.02],\n",
    "            y0=[0.1, 0.08],\n",
    "            line=dict(color='black', width=2)\n",
    "        ),\n",
    "        dict(\n",
    "            type='line',\n",
    "            xref='x',\n",
    "            yref='y',\n",
    "            x0=[-0.02, 0.02],\n",
    "            y0=[0.08, 0.08],\n",
    "            line=dict(color='black', width=2))\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "# Show the plot \n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = mne.io.read_raw_fif('/Volumes/M2_DATA/MEG_QC_stuff/data/Jochem/LeerraumAarhus2017/sub-emptyroom/meg/sub-emptyroom_task-Aarhus_meg.fif', preload=True)\n",
    "\n",
    "#PLOT 3 D\n",
    "\n",
    "def switch_names_on_off(fig):\n",
    "    # Define the buttons\n",
    "    buttons = [\n",
    "    dict(label='Show channel names when hovering',\n",
    "         method='update',\n",
    "         args=[{'mode': 'markers'}]),\n",
    "    dict(label='Always show channel names',\n",
    "         method='update',\n",
    "         args=[{'mode': 'markers+text'}])\n",
    "    ]\n",
    "\n",
    "    # Add the buttons to the layout\n",
    "    fig.update_layout(updatemenus=[dict(type='buttons',\n",
    "                                        showactive=True,\n",
    "                                        buttons=buttons)])\n",
    "\n",
    "    return fig\n",
    "\n",
    "\n",
    "\n",
    "# Extract the sensor locations and names for magnetometers\n",
    "mag_locs = raw.copy().pick_types(meg='mag').info['chs']\n",
    "mag_pos = [ch['loc'][:3] for ch in mag_locs]\n",
    "mag_names = [ch['ch_name'] for ch in mag_locs]\n",
    "\n",
    "# Create the magnetometer plot with markers only\n",
    "\n",
    "mag_fig = go.Figure(data=[go.Scatter3d(x=[pos[0] for pos in mag_pos],\n",
    "                                       y=[pos[1] for pos in mag_pos],\n",
    "                                       z=[pos[2] for pos in mag_pos],\n",
    "                                       mode='markers',\n",
    "                                       marker=dict(size=5),\n",
    "                                       text=mag_names,\n",
    "                                       hovertemplate='%{text}')],\n",
    "                                       layout=go.Layout(width=1000, height=1000))\n",
    "\n",
    "mag_fig.update_layout(title='Magnetometers')\n",
    "\n",
    "mag_fig = switch_names_on_off(mag_fig)\n",
    "mag_fig.show()\n",
    "\n",
    "\n",
    "\n",
    "# Extract the sensor locations and names for gradiometers\n",
    "grad_locs = raw.copy().pick_types(meg='grad').info['chs']\n",
    "grad_pos = [ch['loc'][:3] for ch in grad_locs]\n",
    "grad_names = [ch['ch_name'] for ch in grad_locs]\n",
    "\n",
    "#since grads have 2 sensors located in the same spot - need to put their names together to make pretty plot labels:\n",
    "\n",
    "grad_pos_together = []\n",
    "grad_names_together = []\n",
    "\n",
    "for i in range(len(grad_pos)-1):\n",
    "    if all(x == y for x, y in zip(grad_pos[i], grad_pos[i+1])):\n",
    "        grad_pos_together += [grad_pos[i]]\n",
    "        grad_names_together += [grad_names[i]+', '+grad_names[i+1]]\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "\n",
    "# Add both sets of gradiometer positions to the plot:\n",
    "grad_fig = go.Figure(data=[go.Scatter3d(x=[pos[0] for pos in grad_pos_together],\n",
    "                                        y=[pos[1] for pos in grad_pos_together],\n",
    "                                        z=[pos[2] for pos in grad_pos_together],\n",
    "                                        mode='markers',\n",
    "                                        marker=dict(size=5),\n",
    "                                        text=grad_names_together,\n",
    "                                        hovertemplate='%{text}')],\n",
    "                                        layout=go.Layout(width=1000, height=1000))\n",
    "\n",
    "grad_fig.update_layout(title='Gradiometers')\n",
    "\n",
    "\n",
    "# Add the button to have names show up on hover or always:\n",
    "grad_fig = switch_names_on_off(grad_fig)\n",
    "\n",
    "# Show the plots\n",
    "\n",
    "grad_fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# MUSCLE ARIFACTS IN EMPTYROOM DATA:\n",
    "# Discussed with Andreas:\n",
    "# We can see very high muscle scores at the very beginning and end of the empty room recording\n",
    "# Are these real muscle artifacts or filtering errors?\n",
    "# Cut out 1st second of the data where they are visible.\n",
    "# make Fourier transform of the 1st second and see if there are high amplitudes visible for the muscle frequencies - nope \n",
    "# most likely this is filtering.\n",
    "# next, follow the MNE steps for muscle artifact detection: they use first filtering at 11--140 hz, then Hilbert\n",
    "# plotted raw data after the applied filter, and Hilbert - see cut artifacts in the beginning and end. (WJY arw we sure it  s not hilbert?)\n",
    "# then, tried to only filter - very noisy data. but most likely the filtering is the source. Because of the cut-off in the beginning and end.\n",
    "# Solutions: zero padding in the beginning and end before filtering, which will be cut off after. But may still create a jump while filtering and keep the artifact.\n",
    "# Better: add 2s of dummy data at the beginning and end of the recording, and then crop it out (the data added should be mirrored). This will not create a jump in the filtering.\n",
    "# Tried\n",
    "\n",
    "# Problem found! 2 problems: \n",
    "# 1st: The main artifact is actually introduced by filtering power lines. filtering the data at 150 Hz (harmonics) clearly creates this artifact.\n",
    "# Removed that and any other filtering over the range of muscle freqs, since we don't need them anyways. (over 140 Hz)\n",
    "# 2nd: Still some artifact is present in the beginning and end of the recording. For this attach mirrored data on both ends.\n",
    "# Then detect muscle, then cut the resulting scores away for the attached period.\n",
    "# There will be still some very minimal artifact at the beginning/end of this attachment - probably due to the attachment itself: the mirrored data is still not a normally shaped signal.\n",
    "# See example in cell above of how all 3 option look: oroginal, with attached data and with attached and cut away.\n",
    "\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "import mne\n",
    "\n",
    "raw = mne.io.read_raw_fif('/Volumes/M2_DATA/MEG_QC_stuff/data/Jochem/LeerraumAarhus2017/sub-emptyroom/meg/sub-emptyroom_task-Aarhus_meg.fif', preload=True)\n",
    "\n",
    "#%matplotlib qt\n",
    "raw_first = raw.copy().crop(tmin=0, tmax=1)\n",
    "#raw_first.plot()\n",
    "\n",
    "\n",
    "std_val=raw_first.get_data()\n",
    "\n",
    "window = np.hanning(std_val.shape[-1])*std_val\n",
    "\n",
    "window\n",
    "\n",
    "freqs = np.fft.rfftfreq(window.shape[-1], 1/raw.info['sfreq'])\n",
    "\n",
    "components = np.fft.fft(window, axis=-1)\n",
    "\n",
    "components.shape\n",
    "\n",
    "fig = go.Figure()\n",
    "for ch in range(15, 250):\n",
    "    fig.add_trace(go.Scatter(x=freqs, y = np.abs(components[ch, 0:500])))\n",
    "fig.add_trace(go.Scatter(x=freqs, y = np.abs(components[0, 0:500])))\n",
    "#from mne annotate_muscle_zscore:\n",
    "from scipy.stats import zscore\n",
    "from scipy.ndimage import label\n",
    "\n",
    "filter_freq=(110, 140)\n",
    "legend_category = 'mag'\n",
    "\n",
    "raw_copy = raw_first.copy()\n",
    "raw_copy.load_data()\n",
    "\n",
    "if legend_category is None:\n",
    "    raw_ch_type = raw_copy.get_channel_types()\n",
    "    if 'mag' in raw_ch_type:\n",
    "        legend_category = 'mag'\n",
    "    elif 'grad' in raw_ch_type:\n",
    "        legend_category = 'grad'\n",
    "    elif 'eeg' in raw_ch_type:\n",
    "        legend_category = 'eeg'\n",
    "    else:\n",
    "        raise ValueError('No M/EEG channel types found, please specify a'\n",
    "                            ' ch_type or provide M/EEG sensor data')\n",
    "\n",
    "if legend_category in ('mag', 'grad'):\n",
    "    raw_copy.pick_types(meg=legend_category, ref_meg=False)\n",
    "else:\n",
    "    legend_category = {'meg': False, legend_category: True}\n",
    "    raw_copy.pick_types(**legend_category)\n",
    "\n",
    "#raw_copy.filter(filter_freq[0], filter_freq[1], fir_design='firwin',\n",
    "#                pad=\"reflect_limited\")\n",
    "\n",
    "hilb_applied=raw_copy.apply_hilbert(envelope=True)\n",
    "hilb_applied.plot()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Load the list of values into a NumPy array\n",
    "values = np.array([1, 2, 1.8, 2.5, 3, 3.5, 4, 3.8, 5, 4, 2, 2.1, 1, 0, 2, 4, 6])\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from scipy.signal import butter, filtfilt, savgol_filter, find_peaks\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "\n",
    "# Generate a noisy wave shape\n",
    "t = np.linspace(0, 10, 1000)\n",
    "y = np.sin(t) + 0.5*np.random.randn(len(t))\n",
    "\n",
    "data = np.random.randn(1000) #no wave shape\n",
    "# Load the noisy wave data into a NumPy array\n",
    "wave_data = data\n",
    "\n",
    "# Create a Plotly figure\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=t, y=wave_data, mode='lines', name='Noisy Wave'))\n",
    "fig.update_layout(xaxis_title='Time', yaxis_title='Amplitude', title='Noisy Wave Shape')\n",
    "fig.show()\n",
    "\n",
    "# Apply a low-pass filter to remove high-frequency noise\n",
    "b, a = butter(5, 0.1, 'low')\n",
    "filtered_data = filtfilt(b, a, wave_data)\n",
    "\n",
    "# plot filtered data\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=t, y=filtered_data, mode='lines', name='Filtered Wave'))\n",
    "fig.update_layout(xaxis_title='Time', yaxis_title='Amplitude', title='Filtered Wave Shape')\n",
    "fig.show()\n",
    "\n",
    "# Apply a Savitzky-Golay filter to further reduce noise and extract the underlying wave shape\n",
    "#smoothed_data = savgol_filter(wave_data, window_length=int(len(wave_data)/4), polyorder=3)\n",
    "smoothed_data = savgol_filter(data, window_length=100, polyorder=3)\n",
    "\n",
    "# Identify the shape of the wave using peak detection or curve fitting\n",
    "# For example, you can use the `scipy.signal.find_peaks` function to detect peaks in the smoothed data\n",
    "#peaks, _ = find_peaks(smoothed_data, height=0.5*np.max(smoothed_data))\n",
    "peaks, _ = find_peaks(smoothed_data)\n",
    "\n",
    "# plot smoothed data\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=t, y=smoothed_data, mode='lines', name='Smoothed Wave'))\n",
    "fig.update_layout(xaxis_title='Time', yaxis_title='Amplitude', title='Smoothed Wave Shape')\n",
    "fig.add_trace(go.Scatter(x=t[peaks], y=smoothed_data[peaks], mode='markers', name='Peaks'))\n",
    "fig.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "from scipy.signal import find_peaks\n",
    "\n",
    "# Generate a noisy wave shape\n",
    "t = np.linspace(0, 10, 1000)\n",
    "y = np.sin(t) + 0.5*np.random.randn(len(t))\n",
    "\n",
    "# Find the peaks in the wave\n",
    "peaks, _ = find_peaks(y)\n",
    "\n",
    "# Count the number of peaks\n",
    "num_peaks = len(peaks)\n",
    "\n",
    "# Create a Plotly figure\n",
    "fig = go.Figure()\n",
    "\n",
    "# Add the noisy wave shape to the figure\n",
    "fig.add_trace(go.Scatter(x=t, y=y, mode='lines', name='Noisy Wave'))\n",
    "\n",
    "# Add the peaks to the figure\n",
    "fig.add_trace(go.Scatter(x=t[peaks], y=y[peaks], mode='markers', name='Peaks'))\n",
    "\n",
    "# Add axis labels and a title\n",
    "fig.update_layout(xaxis_title='Time', yaxis_title='Amplitude', title='Noisy Wave Shape')\n",
    "\n",
    "# Show the figure and print the number of peaks\n",
    "fig.show()\n",
    "print(f'The wave has {num_peaks} crest(s).')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "picks_EOG = mne.pick_types(raw.info, eog=True)\n",
    "eog_ch_name = [raw.info['chs'][name]['ch_name'] for name in picks_EOG]\n",
    "eog_ch_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_psd = [2.93686870e-12, 5.37336497e-13, 2.34749324e-13, 1.70403629e-13\n",
    ", 1.42868936e-13, 1.10614848e-13, 1.01586902e-13, 9.41699507e-14\n",
    ", 8.41904711e-14, 7.56254639e-14, 6.98933286e-14, 6.47116338e-14\n",
    ", 5.37107007e-14, 5.42174045e-14, 4.78692577e-14, 4.36476164e-14\n",
    ", 3.69272073e-14, 3.81479068e-14, 4.07614720e-14, 3.71683505e-14\n",
    ", 3.74843265e-14, 3.57210926e-14, 3.99173535e-14, 4.87143053e-14\n",
    ", 4.20066645e-14, 3.84896719e-14, 3.13482998e-14, 2.86289627e-14\n",
    ", 2.82586165e-14, 2.71780036e-14, 2.48692250e-14, 2.71251350e-14\n",
    ", 2.79561808e-14, 2.72047767e-14, 2.79637330e-14, 2.55955578e-14\n",
    ", 2.53291180e-14, 2.01500680e-14, 2.12080778e-14, 2.18529602e-14\n",
    ", 2.12775368e-14, 2.14334140e-14, 2.18751322e-14, 1.97884378e-14\n",
    ", 1.89952388e-14, 1.79404586e-14, 2.01555022e-14, 2.21105500e-14\n",
    ", 1.87897255e-14, 1.95585625e-14, 2.07067862e-14, 2.15786185e-14\n",
    ", 1.78539522e-14, 1.89461927e-14, 1.83714513e-14, 1.91272285e-14\n",
    ", 1.81790918e-14, 1.51935998e-14, 1.55331746e-14, 1.37627320e-14\n",
    ", 1.37333973e-14, 1.47261781e-14, 1.35323358e-14, 1.23234074e-14\n",
    ", 1.26296023e-14, 1.39794705e-14, 1.32391885e-14, 1.33172509e-14\n",
    ", 1.40752537e-14, 1.35291881e-14, 1.46771014e-14, 1.57039580e-14\n",
    ", 1.76870590e-14, 2.11409680e-14, 2.66470647e-14, 2.09066429e-14\n",
    ", 1.68226688e-14, 1.63034232e-14, 1.32317697e-14, 1.20372472e-14\n",
    ", 1.10395275e-14, 1.17336558e-14, 1.12817157e-14, 1.31068881e-14\n",
    ", 1.36940739e-14, 1.48016686e-14, 1.35999052e-14, 1.56644411e-14\n",
    ", 1.51726149e-14, 1.95274934e-14, 1.84669709e-14, 1.89443054e-14\n",
    ", 1.82544652e-14, 1.92617658e-14, 1.80902967e-14, 2.17239287e-14\n",
    ", 2.67917043e-14, 4.45194367e-14, 2.01857457e-12, 4.40594585e-12\n",
    ", 1.74602155e-12, 4.30562941e-14, 2.53461498e-14, 1.87278757e-14\n",
    ", 1.54232144e-14, 1.67924147e-14, 1.22749773e-14, 1.25017017e-14\n",
    ", 1.22475994e-14, 1.02921463e-14, 1.07700101e-14, 1.02658035e-14\n",
    ", 9.54949869e-15, 9.84280694e-15, 8.88745310e-15, 9.02206922e-15\n",
    ", 8.47210049e-15, 8.64491709e-15, 1.32254861e-14, 1.89573615e-14\n",
    ", 1.23079196e-14, 8.62994931e-15, 8.12535185e-15, 8.01035318e-15\n",
    ", 7.53220890e-15, 8.02056256e-15, 7.90231409e-15, 7.63270083e-15\n",
    ", 7.93212379e-15, 7.28368608e-15, 7.59772607e-15, 7.26136429e-15\n",
    ", 7.86504197e-15, 7.36256360e-15, 7.02847343e-15, 7.08620266e-15\n",
    ", 6.86068169e-15, 7.21792433e-15, 7.28674098e-15, 6.88181371e-15\n",
    ", 6.78751472e-15, 6.59002904e-15, 6.74850515e-15, 6.53743454e-15\n",
    ", 6.70834535e-15, 6.72520433e-15, 6.78371437e-15, 6.70420118e-15\n",
    ", 6.97442862e-15, 7.26767528e-15, 6.79388360e-15, 6.83101277e-15\n",
    ", 6.90684197e-15, 6.45716620e-15, 6.66190889e-15, 6.49304182e-15\n",
    ", 6.38068712e-15, 6.29160702e-15, 5.92354089e-15, 6.33890242e-15\n",
    ", 6.33787606e-15, 5.76688121e-15, 6.31821916e-15, 6.34536916e-15\n",
    ", 6.51250512e-15, 6.43164190e-15, 6.46530769e-15, 6.44724883e-15\n",
    ", 7.48305304e-15, 7.50925230e-15, 6.28419317e-15, 6.33908319e-15\n",
    ", 5.86954984e-15, 6.54561206e-15, 6.08872456e-15, 6.40874736e-15\n",
    ", 5.95870142e-15, 6.13488554e-15, 5.83721527e-15, 5.87793931e-15\n",
    ", 5.81207088e-15, 5.98748087e-15, 5.94551525e-15, 5.75415575e-15\n",
    ", 5.66968278e-15, 6.11006036e-15, 5.72066372e-15, 5.96629716e-15\n",
    ", 5.80372053e-15, 5.75583336e-15, 5.84628922e-15, 5.63642362e-15\n",
    ", 5.34942930e-15, 5.75920960e-15, 6.05337029e-15, 6.61372576e-15\n",
    ", 7.14210116e-15, 6.94968538e-15, 1.85742697e-14, 3.52090532e-14\n",
    ", 1.48785528e-14, 6.23577963e-15, 5.66229647e-15, 5.39212323e-15\n",
    ", 5.32890121e-15, 5.54967559e-15, 5.29485491e-15, 5.65665900e-15\n",
    ", 5.31337965e-15, 5.30139224e-15, 5.21434237e-15, 5.61739646e-15\n",
    ", 5.62673191e-15, 5.68441483e-15, 5.43332729e-15, 5.34563989e-15\n",
    ", 5.69510011e-15, 6.43038706e-15, 5.52069097e-15, 5.22891308e-15\n",
    ", 5.06513758e-15, 5.15715319e-15, 5.32484298e-15, 5.37071225e-15\n",
    ", 5.24099974e-15, 5.14413780e-15, 5.05322799e-15, 5.27277366e-15\n",
    ", 5.17209094e-15, 5.19895605e-15, 5.04662049e-15, 5.13492402e-15\n",
    ", 5.39573281e-15, 5.13639899e-15, 5.29696474e-15, 5.29749076e-15\n",
    ", 5.23187737e-15, 5.14179424e-15, 1.44011463e-14, 2.29753019e-14\n",
    ", 8.85041560e-15, 5.16398069e-15, 5.09075672e-15, 5.06681957e-15\n",
    ", 5.17284653e-15, 4.99688083e-15, 5.01988585e-15, 5.07952302e-15\n",
    ", 4.97188381e-15, 5.17733558e-15, 4.97124292e-15, 4.96910679e-15\n",
    ", 4.96283207e-15, 5.07193856e-15, 4.80712108e-15, 4.97630935e-15\n",
    ", 4.93727883e-15, 4.84091247e-15, 5.07370238e-15, 4.76459850e-15\n",
    ", 4.86678392e-15, 5.03907955e-15, 4.91645908e-15, 4.99691785e-15\n",
    ", 4.81326372e-15, 5.56398292e-15, 5.40286001e-15, 4.91762834e-15\n",
    ", 4.96042200e-15, 4.86125369e-15, 5.04306529e-15, 4.89229744e-15\n",
    ", 4.93924928e-15, 4.91889752e-15, 4.92336366e-15, 4.91476256e-15\n",
    ", 4.90731383e-15, 4.79751988e-15, 4.96181659e-15, 5.04353794e-15]\n",
    "\n",
    "#plot the data with ploty:\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "from scipy.signal import find_peaks\n",
    "\n",
    "freqs = [i/2 for i in range(0, 280)]\n",
    "prominence_lvl_pos = 50\n",
    "prominence_pos=(max(one_psd) - min(one_psd)) / prominence_lvl_pos\n",
    "noisy_freqs_indexes, _ = find_peaks(one_psd, prominence=prominence_pos)\n",
    "noisy_freqs_indexes = [int(i) for i in noisy_freqs_indexes]\n",
    "\n",
    "for i in range(0,2):\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Scatter(x=freqs, y=one_psd, name='psd'))\n",
    "    fig.update_layout(title=' PSD', xaxis_title='Frequency', yaxis_title='Amplitude',\n",
    "            yaxis = dict(\n",
    "            showexponent = 'all',\n",
    "            exponentformat = 'e'))\n",
    "\n",
    "    fig.add_trace(go.Scatter(x=[freqs[noisy_freqs_indexes[0]]], y=[one_psd[noisy_freqs_indexes[0]]], mode='markers', name='peaks'))\n",
    "\n",
    "    if i == 0:\n",
    "        fig.update_yaxes(type=\"log\")\n",
    "\n",
    "    fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_head_pos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bool('False')\n",
    "\n",
    "#convert \"false\" to boolean:\n",
    "import ast\n",
    "t = ast.literal_eval('False')\n",
    "t\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mne-qc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
