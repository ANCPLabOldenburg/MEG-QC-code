{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THE OLD VERSION: here frequency spectrum can be calculated over entire time or over concatenated epochs. \n",
    "# Jochen said no concatenated epochs needed, cos ot will introduce artifacts on the endges: jumps between epochs. \n",
    "# In this file both options avalible. In main Funks - only over whole time series.\n",
    "\n",
    "import os\n",
    "\n",
    "#import matplotlib\n",
    "#matplotlib.use('MACOSX')\n",
    "#for some reason if I run these 2 lines - it doesnt plot at all any more.\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import mne\n",
    "import matplotlib.pyplot as plt\n",
    "from copy import deepcopy\n",
    "from mne.time_frequency import tfr_morlet, psd_multitaper, psd_welch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load data\n",
    "\n",
    "#! use relative paths!\n",
    "\n",
    "kath_raw_file = os.path.join('Katharinas_Data','sub_HT05ND16', '210811', 'mikado-1.fif')                               \n",
    "raw = mne.io.read_raw_fif(kath_raw_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_folders_meg(sid='1'):\n",
    "#Create folders (if they dont exist yet)\n",
    "\n",
    "#sid is subject Id, must be a string.\n",
    "#Folders are created in BIDS-compliant directory order: \n",
    "#Working directory - Subject - derivtaives - megQC - csvs and figures\n",
    "\n",
    "    #This is the list of folders and subfolders to be created. Loop checks if directory already exists, if not - create.\n",
    "    #Make sure to add subfolders on the list here AFTER the parent folder.\n",
    "\n",
    "    #DO WE NEED TO CREATE IT ACTUALLY NOT IN CURRENT DIRECTORY, BUT GO ONE STEP UP FROM CURRENT DIRECTORY AND THEN CREAT DERIVATIVES?\n",
    "\n",
    "    path_list = [f'./derivatives', \n",
    "    f'./derivatives/sub-{sid}',\n",
    "    f'./derivatives/sub-{sid}/megqc',\n",
    "    f'./derivatives/sub-{sid}/megqc/csv files',\n",
    "    f'./derivatives/sub-{sid}/megqc/figures']\n",
    "\n",
    "    print(path_list)\n",
    "\n",
    "    for path in path_list:\n",
    "        if os.path.isdir(path)==False: #if directory doesnt exist yet - create\n",
    "            os.mkdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_folders_meg(sid='1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#crop the data to calculate faster\n",
    "\n",
    "raw_cropped = raw.copy()\n",
    "raw_cropped.crop(0, 300) #(first 5 min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filter the data\n",
    "\n",
    "def filtering_data(data=None,l_freq=None, h_freq=None, method='iir'):\n",
    "    # Filtering the data. Recommended: 1-100Hz bandpass or 0.5-100 Hz - better for frequency spectrum\n",
    "\n",
    "    # method='iir' - I m using here the Butterworth filter similar to filtfilt in matlab, like we  \n",
    "    # did in the course with eeg data. such filter creates no time shift, since it filters forward and backward.\n",
    "    # But we might use a different filter as well. I dont know if this one is the best possible option.\n",
    "\n",
    "    #Data has to be loaded into mememory before filetering:\n",
    "    data.load_data(verbose=True)\n",
    "    raw_bandpass = data.copy()\n",
    "    raw_bandpass.filter(l_freq=l_freq, h_freq=h_freq, picks='meg', method=method, iir_params=None)\n",
    "\n",
    "    return(raw_bandpass)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply filtgering\n",
    "\n",
    "filtered_d=filtering_data(data=raw_cropped,l_freq=0.5, h_freq=100, method='iir')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def Epoch_meg(data=None, stim_channel='STI101', event_dur=1.2, mags_grads_separate=True, epoch_tmin=-0.2, epoch_tmax=1):\n",
    "\n",
    "       #2 OPTIONS TO RETURN DATA FRAME OF EPOCHS: MAGS+GRADS IN ONE DF OR SEPARATE. CAN MAKE ONLY SEPARATE OPTION AND \n",
    "       # REWRITE CODE SO THAT WE USE DFS SEPARATE. IF WE NEVER NEED MAGS AND GRADS TOGETEHR. CHECK THAT!\n",
    "\n",
    "       #mags_grads_separate: 0 - everything in one object and data frame, 1 - mags and grads separate.\n",
    "\n",
    "\n",
    "       picks_grad = mne.pick_types(data.info, meg='grad', eeg=False, eog=False, stim=False)\n",
    "       picks_magn = mne.pick_types(data.info, meg='mag', eeg=False, eog=False, stim=False)\n",
    "\n",
    "       events = mne.find_events(data, stim_channel=stim_channel, min_duration=event_dur)\n",
    "       n_events=len(events)\n",
    "\n",
    "       if mags_grads_separate==True:\n",
    "              epochs_mags = mne.Epochs(data, events, picks=picks_magn, tmin=epoch_tmin, tmax=epoch_tmax, preload=True, baseline = None)\n",
    "              epochs_grads = mne.Epochs(data, events, picks=picks_grad, tmin=epoch_tmin, tmax=epoch_tmax, preload=True, baseline = None)\n",
    "\n",
    "              #Present epochs as data frame - separately for mags and grads\n",
    "              df_epochs_mags = epochs_mags.to_data_frame(time_format=None, scalings=dict(mag=1, grad=1))\n",
    "              df_epochs_grads = epochs_grads.to_data_frame(time_format=None, scalings=dict(mag=1, grad=1))\n",
    "\n",
    "              return(n_events, df_epochs_mags, df_epochs_grads, epochs_mags, epochs_grads)\n",
    "              #Returns: \n",
    "              # number of events(=number of epochs), \n",
    "              # data frame containing data for all epochs: mags and grads separately\n",
    "              # epochs as mne data structure (not used anywhere, we may use it for something in the future)\n",
    "\n",
    "       elif mags_grads_separate==False:\n",
    "              #Find events and epochs:\n",
    "\n",
    "              epochs = mne.Epochs(data, events, tmin=epoch_tmin, tmax=epoch_tmax, preload=True, baseline = None) #, event_id=event_dict, reject=reject_criteria)\n",
    "\n",
    "              #Present epochs as data frame:\n",
    "              df_epochs_all = epochs.to_data_frame(time_format=None, scalings=dict(mag=1, grad=1))\n",
    "\n",
    "              return(n_events, df_epochs_all, epochs)\n",
    "\n",
    "              #Returns: \n",
    "              # number of events(=number of epochs), \n",
    "              # data frame containing data for all epochs and all channels together, \n",
    "              # epochs as mne data structure (not used anywhere, we may use it for something in the future)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply epoching:\n",
    "#Left it as a function. But the plan is to amke it an oblogatory step. So that teh user doesnt have to input \n",
    "# different epoch parameters in difefrent fucbtions and all calculation goes for the same epochs (RMSE, freq. spectrum):\n",
    "\n",
    "#epochs for mags and grads separately\n",
    "n_events, df_epochs_mags, df_epochs_grads, epochs_mags, epochs_grads=Epoch_meg(data=filtered_d, stim_channel='STI101', event_dur=1.2, mags_grads_separate=1, epoch_tmin=-0.2, epoch_tmax=1)\n",
    "\n",
    "#epochs for them together in one object:\n",
    "n_events, df_epochs_all, epochs=Epoch_meg(data=filtered_d, stim_channel='STI101', event_dur=1.2, mags_grads_separate=0, epoch_tmin=-0.2, epoch_tmax=1)\n",
    "\n",
    "#df_epochs_mags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% RMSE - general function to use in other functions\n",
    "#STD CALCULATION IS MUCH LESS COdE BUT TAKES LONGER THAN RMSE\n",
    "\n",
    "def RMSE(data_mags=None, data_grads=None):\n",
    "\n",
    "    # https://stackoverflow.com/questions/17197492/is-there-a-library-function-for-root-mean-square-error-rmse-in-python\n",
    "\n",
    "    from sklearn.metrics import mean_squared_error\n",
    "\n",
    "    #Magnitometers:\n",
    "    y_actual_mags=data_mags #refrence to data_mags\n",
    "    y_predicted_mags=data_mags.mean(axis=1)\n",
    "\n",
    "    rmse_mags = np.zeros(len(y_predicted_mags)) #RMSE of all magnetometers\n",
    "\n",
    "    for i in range(len(y_predicted_mags)):\n",
    "        y_predicted_vec_mags=np.ones(len(y_actual_mags[0]))*y_predicted_mags[i]\n",
    "        rmse_mags[i] = mean_squared_error(y_actual_mags[i, :], y_predicted_vec_mags, squared=False)\n",
    "\n",
    "\n",
    "    #Gradiometers:\n",
    "    y_actual_grads=data_grads #refrence to data_grads\n",
    "    y_predicted_grads=data_grads.mean(axis=1)\n",
    "\n",
    "    rmse_grads = np.zeros(len(y_predicted_grads)) #RMSE of all gradiometers\n",
    "\n",
    "    for i in range(len(y_predicted_grads)):\n",
    "        y_predicted_vec_grads=np.ones(len(y_actual_grads[0]))*y_predicted_grads[i]\n",
    "        rmse_grads[i] = mean_squared_error(y_actual_grads[i, :], y_predicted_vec_grads, squared=False)\n",
    "\n",
    "    return(rmse_mags, rmse_grads)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Root mean squared error calculation (or STD - same result) over all data:\n",
    "\n",
    "def RMSE_meg_all(data=None, std_lvl=1, plotflag=True, sid='1'): #, min_duration_event=1, epoch_tmin=-0.2, epoch_tmax=1):\n",
    "    #give path to directory and then it should auto find the data file when bids compliant.\n",
    "    ##maybe distinguish between negative and positive std_lvl\n",
    "\n",
    "    #plotflag - plot or no plot\n",
    "    #sid - subject Id. Has to be a string , like '1'\n",
    "\n",
    "    #Separate mags and grads:\n",
    "    mags = [(chs['ch_name'], i) for i, chs in enumerate(data.info['chs']) if str(chs['unit']).endswith('UNIT_T)')]\n",
    "    grads = [(chs['ch_name'], i) for i, chs in enumerate(data.info['chs']) if str(chs['unit']).endswith('UNIT_T_M)')]\n",
    "  \n",
    "\n",
    "    # Separate data for mags and grads in 2 arrays.\n",
    "    selected_mags = [item[1] for item in mags]\n",
    "    selected_grads = [item[1] for item in grads]\n",
    "    data_mags, times = data[selected_mags, :]  \n",
    "    data_grads, times = data[selected_grads, :]  \n",
    "\n",
    "    # %% Calculate STD or RMSE of each channel\n",
    "\n",
    "    #Calculate RMSE for each channel (separated mags and grads) - for the entire time duration:\n",
    "    std_mags, std_grads = RMSE(data_mags=data_mags, data_grads=data_grads)\n",
    "\n",
    "    #STD (if wanna use insted of RMSE. it will exactly replace the RMSE function above):\n",
    "    #std_mags=np.std(data_mags, axis=1) #calculate std of all magnetometers (along second dimantion)\n",
    "    #std_grads=np.std(data_grads, axis=1) #calculate std of all gradiometers (along second dimantion)\n",
    "\n",
    "\n",
    "    # Check if channel data is within 1 std over all channels.\n",
    "    # COMMENT: can use -3 to 3 (or other number) std istead of -1/+1 std, but this can adjusted later. \n",
    "    # 1 std is too narrow, gives way too many bad channels.\n",
    "\n",
    "    std_std_mags=np.std(std_mags)\n",
    "    std_std_grads=np.std(std_grads)\n",
    "\n",
    "    mean_std_mags=np.mean(std_mags)\n",
    "    mean_std_grads=np.mean(std_grads)\n",
    "\n",
    "    ch_large_std_mags= np.where(std_mags > mean_std_mags+std_lvl*std_std_mags) # | std_mags < mean_std_magn-std_std_mags)\n",
    "    ch_large_std_grads= np.where(std_grads > mean_std_grads+std_lvl*std_std_grads) # | std_grads < mean_std_grad-std_std_grads)\n",
    "\n",
    "    ch_small_std_mags= np.where(std_mags < mean_std_mags-std_lvl*std_std_mags)\n",
    "    ch_small_std_grads= np.where(std_grads < mean_std_grads-std_lvl*std_std_grads)\n",
    "\n",
    "\n",
    "    magn_channel_big_std=np.array(mags)[ch_large_std_mags[0]]\n",
    "    grad_channel_big_std=np.array(grads)[ch_large_std_grads[0]]\n",
    "\n",
    "    magn_channel_small_std=np.array(mags)[ch_small_std_mags[0]]\n",
    "    grad_channel_small_std=np.array(grads)[ch_small_std_grads[0]]\n",
    "\n",
    "    print('Magnetometers with high STD: ', magn_channel_big_std)\n",
    "    print('Gradiometers with high STD: ',grad_channel_big_std)\n",
    "\n",
    "    print('Magnetometers with low STD: ', magn_channel_small_std)\n",
    "    print('Gradiometers with low STD: ',grad_channel_small_std)\n",
    "\n",
    "\n",
    "    if plotflag==True:\n",
    "        \n",
    "        from matplotlib import pyplot as plt\n",
    "        #%matplotlib qt\n",
    "        #%matplotlib inline\n",
    "\n",
    "        fig, (ax1, ax2) = plt.subplots(2)\n",
    "        fig.suptitle('STDs')\n",
    "        ax1.plot(list(range(1, len(std_mags)+1)), std_mags)\n",
    "        ax1.plot(list(range(1, len(std_mags)+1)), [mean_std_mags]*len(std_mags))\n",
    "        ax1.plot(list(range(1, len(std_mags)+1)), [mean_std_mags-std_lvl*std_std_mags]*len(std_mags))\n",
    "        ax1.plot(list(range(1, len(std_mags)+1)), [mean_std_mags+std_lvl*std_std_mags]*len(std_mags))\n",
    "        ax1.set(xlabel='Magnetometer', ylabel='STD')\n",
    "\n",
    "        ax2.plot(list(range(1, len(std_grads)+1)), std_grads)\n",
    "        ax2.plot(list(range(1, len(std_grads)+1)), [mean_std_grads]*len(std_grads))\n",
    "        ax2.plot(list(range(1, len(std_grads)+1)), [mean_std_grads-std_lvl*std_std_grads]*len(std_grads))\n",
    "        ax2.plot(list(range(1, len(std_grads)+1)), [mean_std_grads+std_lvl*std_std_grads]*len(std_grads))\n",
    "        ax2.set(xlabel='Gradiometer', ylabel='STD')\n",
    "\n",
    "        plt.savefig('./derivatives/sub-'+sid+'/megqc/figures/RMSE_all_channels.png')\n",
    "\n",
    "\n",
    "    #Return the channel names with STD over the set STD level and under the set negative STD level.\n",
    "    return(magn_channel_big_std, grad_channel_big_std, magn_channel_small_std, grad_channel_small_std)\n",
    "\n",
    "\n",
    "    #CAN ADD OPTIONAL PLOTTING OF SOME CHANNELS WITH HIGH/LOW STD. DO WE NEED THAT?\n",
    "    #WHAT DO WE WANT TO GIVE AS OUTPUT HERE? NEED PLOTS, NEED LIST OF CHANNELS?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Try:\n",
    "\n",
    "magn_channel_big_std, grad_channel_big_std, magn_channel_small_std, grad_channel_small_std=RMSE_meg_all(data=filtered_d, std_lvl=1, plotflag=True, sid='1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STD over epochs. \n",
    "def RMSE_meg_epoch(data=None, std_lvl=1, n_events=n_events, df_epochs_all=df_epochs_all, sid='1'):\n",
    "\n",
    "#def RMSE_meg_epoch(data=None, std_lvl=1, stim_channel='STI101',  min_duration_event=1.2, epoch_tmin=-0.2, epoch_tmax=1):\n",
    "    #stim_channel name is users input. but we can also let mne find it itself if 'None' is set? mne seems to have such function.\n",
    "\n",
    "    # 1) Loop over the epochs of each channel and check for every separate magn and grad and calculate std\n",
    "    import pandas as pd\n",
    "    eps=list(range(0,n_events)) #list of epoch numbers\n",
    "\n",
    "    #Separate mags and grads:\n",
    "    mags = [(chs['ch_name'], i) for i, chs in enumerate(data.info['chs']) if str(chs['unit']).endswith('UNIT_T)')]\n",
    "    grads = [(chs['ch_name'], i) for i, chs in enumerate(data.info['chs']) if str(chs['unit']).endswith('UNIT_T_M)')]\n",
    "    \n",
    "    mags_names = [mag[0] for mag in mags]\n",
    "    grads_names = [grad[0] for grad in grads]\n",
    "\n",
    "    combined_names = {\"mags\": mags_names, \"grads\": grads_names}\n",
    "\n",
    "    dict_mags = {}\n",
    "    dict_grads = {}\n",
    "\n",
    "    for ep in eps: #loop over each epoch\n",
    "        rows_for_ep = [row for row in df_epochs_all.iloc if row.epoch == ep]\n",
    "\n",
    "        std_epoch = {\"mags\": [], \"grads\": []}\n",
    "\n",
    "        for key_of_list in combined_names: #loop over mags, then grads\n",
    "\n",
    "            for ch_name in combined_names[key_of_list]: #loop over channel names\n",
    "                \n",
    "                data_ch_epoch = [row_m[ch_name] for row_m in rows_for_ep]\n",
    "\n",
    "                std_ch_ep = np.std(data_ch_epoch)   #HERE CAN ALSO REPLACE STD WITH RMSE CALCULATION FOR SPEED!\n",
    "\n",
    "                std_epoch[key_of_list].append(std_ch_ep)\n",
    "\n",
    "        dict_mags[ep] = std_epoch[\"mags\"]\n",
    "        dict_grads[ep] = std_epoch[\"grads\"]\n",
    "\n",
    "    df_std_mags = pd.DataFrame(dict_mags, index=mags_names)\n",
    "    df_std_grads = pd.DataFrame(dict_grads, index=grads_names)\n",
    "\n",
    "    # 2) Check (which epochs for which channel) are over 1STD (or 2, 3, ets STDs) for (this epoch for all channels)\n",
    "\n",
    "    #Find what is 1 std over all channels per 1 epoch:\n",
    "    std_std_mags_per_epoch=[]\n",
    "    std_std_grads_per_epoch=[]\n",
    "    mean_std_mags_per_epoch=[]\n",
    "    mean_std_grads_per_epoch=[]\n",
    "\n",
    "    for ep in eps: #goes over each epoch\n",
    "        std_std_mags_per_epoch.append(np.std(df_std_mags.iloc[:, ep])) #std of stds of all channels of every single epoch\n",
    "        std_std_grads_per_epoch.append(np.std(df_std_grads.iloc[:, ep]))\n",
    "\n",
    "        mean_std_mags_per_epoch.append(np.mean(df_std_mags.iloc[:, ep])) #mean of stds of all channels of every single epoch\n",
    "        mean_std_grads_per_epoch.append(np.mean(df_std_grads.iloc[:, ep]))\n",
    "\n",
    "\n",
    "    df_ch_ep_large_std_mags=df_std_mags.copy()\n",
    "    df_ch_ep_large_std_grads=df_std_grads.copy()\n",
    "\n",
    "    df_ch_ep_small_std_mags=df_std_mags.copy()\n",
    "    df_ch_ep_small_std_grads=df_std_grads.copy()\n",
    "\n",
    "    #Now see which channles in epoch are over 1 std or under -1 std:\n",
    "    for ep in eps: #goes over each epoch   \n",
    "        df_ch_ep_large_std_mags.iloc[:,ep] = df_ch_ep_large_std_mags.iloc[:,ep] > mean_std_mags_per_epoch[ep]+std_lvl*std_std_mags_per_epoch[ep] #magnetometers\n",
    "        df_ch_ep_large_std_grads.iloc[:,ep] = df_ch_ep_large_std_grads.iloc[:,ep] > mean_std_grads_per_epoch[ep]+std_lvl*std_std_grads_per_epoch[ep] #gradiometers\n",
    "\n",
    "        df_ch_ep_small_std_mags.iloc[:,ep] = df_ch_ep_small_std_mags.iloc[:,ep] < mean_std_mags_per_epoch[ep]-std_lvl*std_std_mags_per_epoch[ep] #magnetometers\n",
    "        df_ch_ep_small_std_grads.iloc[:,ep] = df_ch_ep_small_std_grads.iloc[:,ep] < mean_std_grads_per_epoch[ep]-std_lvl*std_std_grads_per_epoch[ep] #gradiometers\n",
    "\n",
    "\n",
    "    # Create csv files  for the user:\n",
    "\n",
    "    df_std_mags.to_csv('./derivatives/sub-'+sid+'/megqc/csv files/std_mags_per_epoch.csv')\n",
    "    \n",
    "    df_std_grads.to_csv('./derivatives/sub-'+sid+'/megqc/csv files/std_grads_per_epoch.csv')\n",
    "\n",
    "    df_ch_ep_large_std_mags.to_csv('./derivatives/sub-'+sid+'/megqc/csv files/Large_std_mags_per_epoch.csv')\n",
    "\n",
    "    df_ch_ep_large_std_grads.to_csv('./derivatives/sub-'+sid+'/megqc/csv files/Large_std_grads_per_epoch.csv')\n",
    "\n",
    "    df_ch_ep_small_std_mags.to_csv('./derivatives/sub-'+sid+'/megqc/csv files/Small_std_mags_per_epoch.csv')\n",
    "\n",
    "    df_ch_ep_small_std_grads.to_csv('./derivatives/sub-'+sid+'/megqc/csv files/Small_std_grads_per_epoch.csv')\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#try (will output csv files):\n",
    "RMSE_meg_epoch(data=filtered_d, std_lvl=1, sid='1') #stim_channel='STI101', std_lvl=1, min_duration_event=1.2, epoch_tmin=-0.2, epoch_tmax=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate frequency spectrum:\n",
    "\n",
    "def Freq_Spectrum_meg(data=None, epoched=True, df_epochs_mags=df_epochs_mags, df_epochs_grads=df_epochs_grads, plotflag=True, sid='1', freq_min=1, \n",
    "    freq_max=200, n_fft=1000, n_per_seg=1000, freq_tmin=None, freq_tmax=None):\n",
    "\n",
    "    #Separate mags and grads:\n",
    "    mags = [(chs['ch_name'], i) for i, chs in enumerate(data.info['chs']) if str(chs['unit']).endswith('UNIT_T)')]\n",
    "    grads = [(chs['ch_name'], i) for i, chs in enumerate(data.info['chs']) if str(chs['unit']).endswith('UNIT_T_M)')]\n",
    "\n",
    "    if epoched==False: #if epoched True - epoch the data, otherwise use the whole data.\n",
    "        ##again use a boolean :)\n",
    "\n",
    "        # Frequency spectrum using Welch method OVER ALL TIME. USING MNE:\n",
    "\n",
    "        picks_grad = mne.pick_types(data.info, meg='grad', eeg=False, eog=False, stim=False)\n",
    "        picks_magn = mne.pick_types(data.info, meg='mag', eeg=False, eog=False, stim=False)\n",
    "\n",
    "        psds_mags, freqs_mags = psd_welch(data, fmin=freq_min, fmax=freq_max, n_jobs=-1, picks=picks_magn, n_fft=n_fft, n_per_seg=n_per_seg, tmin=freq_tmin, tmax=freq_tmax)\n",
    "        psds_grads, freqs_grads = psd_welch(data, fmin=freq_min, fmax=freq_max, n_jobs=-1, picks=picks_grad, n_fft=n_fft, n_per_seg=n_per_seg, tmin=freq_tmin, tmax=freq_tmax)\n",
    "        #CALCULATES NOW OVER ALL TIME. SET TIME HERE IF WANT IT FASTER OR PARTICULAR PERIOD. RESULT CAN LOOK VERY DIFFERNT.\n",
    "\n",
    "        # n_per_seg - Length of each Welch segment (windowed with a Hamming window). Defaults to None, which sets n_per_seg equal to n_fft.\n",
    "        # n_fft - The length of FFT used, must be >= n_per_seg (default: 256). The segments will be zero-padded if n_fft > n_per_seg. If n_per_seg \n",
    "        # is None, n_fft must be <= number of time points in the data.\n",
    "        # These influence the bandwidth.\n",
    "\n",
    "        #Plot the result over all time:\n",
    "\n",
    "        freqs_mat_mags=np.tile(freqs_mags, [np.shape(psds_mags)[0],1])\n",
    "        freqs_mat_grads=np.tile(freqs_grads, [np.shape(psds_grads)[0],1])\n",
    "\n",
    "        \n",
    "        if plotflag==True:\n",
    "            from matplotlib import pyplot as plt\n",
    "\n",
    "            %matplotlib qt\n",
    "            #%matplotlib inline\n",
    "\n",
    "            #Magnetometers:\n",
    "            plt.figure()\n",
    "            plt.plot(freqs_mat_mags.T, np.sqrt(psds_mags.T))\n",
    "            plt.yscale='log'\n",
    "            plt.xlabel('Frequency (Hz)')\n",
    "            plt.ylabel('Power spectral density (T / Hz)')  #check the units!\n",
    "            plt.title(\"Welch's periodogram for all magnetometers\")\n",
    "            plt.savefig('./derivatives/sub-'+sid+'/megqc/figures/PSD_over_all_data_mags.png')\n",
    "            #plt.show()\n",
    "            \n",
    "            #Freq spectrum peaks we see (visible on shorter interval, not so much when Welch is done over all time:\n",
    "            #50, 100, 150 - powerline EU\n",
    "            #6 noise of shielding chambers \n",
    "            #44 meg noise\n",
    "            #17 - was it the train station near by?\n",
    "            #10 Secret :)\n",
    "            #1hz - highpass filter.\n",
    "            #flat spectrum is white noise process. Has same energy in every frequency (starts around 50Hz or even below)\n",
    "\n",
    "            #Gradiometers:\n",
    "            plt.figure()\n",
    "            plt.plot(freqs_mat_grads.T, np.sqrt(psds_grads.T))\n",
    "            plt.yscale='log'\n",
    "            plt.xlabel('Frequency (Hz)')\n",
    "            plt.ylabel('Power spectral density (T/m)²/Hz)')  #check the units!\n",
    "            plt.title(\"Welch's periodogram for all gradiometers\")\n",
    "            plt.savefig('./derivatives/sub'+sid+'/megqc/figures/PSD_over_all_data_grads.png')\n",
    "            #plt.show()\n",
    "\n",
    "            #Need to find frequencies.. and filter out? \n",
    "            #Powerline\n",
    "            #Eye moves \n",
    "            #Blinks\n",
    "            #Cardio: try to autocreate it. Maybe it s small enough to not care?\n",
    "            #Muscle movements \n",
    "\n",
    "    elif epoched==True:\n",
    "\n",
    "        # Frequency spectrum using Welch method ONLY OVER ALL EPOCHS. USING SCIPY:\n",
    "        #Cant use MNE here, because the data for all channels after epoching is in a data frame.\n",
    "        #But MNE only accepts raw, epoch or evoked object as input into Welch function.\n",
    "        #However if I use epochs - it calculates psds for each separate epoch and gives: epoch*channel*psds.\n",
    "        # While I want to all epochs together 1 value: channels * psds. (Like we had is statisticsl lerning course).\n",
    "\n",
    "        from scipy import signal\n",
    "\n",
    "        # Welch. Define window length:\n",
    "        sf=raw.info['sfreq']\n",
    "        win = 1 * sf  #frequency step will be 1 Hz\n",
    "\n",
    "        # Loop over the epochs data frame. Every iteration = 1 channel. all epochs will be merged together. \n",
    "        # This way we only take the valueble data of all epochs and throw away in-between data. \n",
    "        # however it doesnt calculate separate freq spectrim per individual epoch\n",
    "\n",
    "\n",
    "        psds_mags_cut_all = []\n",
    "        for m in mags:\n",
    "            ch_ep_data = df_epochs_mags[m[0]] #take all epochs of 1 channel\n",
    "\n",
    "            freqs_mags_cut, psd_mags_cut = signal.welch(ch_ep_data, sf, nperseg=win) #estimate freq and psds for this channel\n",
    "            #since we cant limit the range of needed frequencies inside the function - cut needed freq after it s done:  1-200Hz\n",
    "            freqs_mags_cut_ind = np.where(np.logical_and(freqs_mags_cut>=1, freqs_mags_cut<=200)) \n",
    "            psd_mags_cut=psd_mags_cut[freqs_mags_cut_ind]\n",
    "\n",
    "            #put all psds under each other. so it s a table: 102 mags*200psds.\n",
    "            psds_mags_cut_all.append(psd_mags_cut)\n",
    "            \n",
    "        psds_mags_cut_all = np.asarray(psds_mags_cut_all)\n",
    "        freqs_mags_cut=freqs_mags_cut[freqs_mags_cut_ind]\n",
    "\n",
    "\n",
    "        psds_grads_cut_all = []\n",
    "        for g in grads:\n",
    "            ch_ep_data = df_epochs_grads[g[0]] #take all epochs of 1 channel\n",
    "\n",
    "            freqs_grads_cut, psd_grads_cut = signal.welch(ch_ep_data, sf, nperseg=win) #estimate freq and psds for this channel\n",
    "            #since we cant limit the range of needed frequencies inside the function - cut needed freq after it s done:  1-200Hz\n",
    "            freqs_grads_cut_ind = np.where(np.logical_and(freqs_grads_cut>=1, freqs_grads_cut<=200)) \n",
    "            psd_grads_cut=psd_grads_cut[freqs_grads_cut_ind]\n",
    "\n",
    "            #put all psds under each other. so it s a table: 102 mags*200psds.\n",
    "            psds_grads_cut_all.append(psd_grads_cut)\n",
    "            \n",
    "        psds_grads_cut_all = np.asarray(psds_grads_cut_all)\n",
    "        freqs_grads_cut=freqs_grads_cut[freqs_grads_cut_ind]\n",
    "\n",
    "        #Plot freq. spectrum of epoched data:\n",
    "        freqs_mat_mags_cut=np.tile(freqs_mags_cut, [np.shape(psds_mags_cut_all)[0],1])\n",
    "        freqs_mat_grads_cut=np.tile(freqs_grads_cut, [np.shape(psds_grads_cut_all)[0],1])\n",
    "\n",
    "        if plotflag == True:\n",
    "            from matplotlib import pyplot as plt\n",
    "\n",
    "            %matplotlib qt\n",
    "            #%matplotlib inline\n",
    "\n",
    "            #Magnetometers:\n",
    "            plt.figure()\n",
    "            plt.plot(freqs_mat_mags_cut.T, np.sqrt(psds_mags_cut_all.T))\n",
    "            plt.yscale='log'\n",
    "            plt.xlabel('Frequency (Hz)')\n",
    "            plt.ylabel('Power spectral density (T / Hz)')  #check the units!\n",
    "            plt.title(\"Welch's periodogram for all magnetometers. Only epoched data\")\n",
    "            plt.savefig('./derivatives/sub-'+sid+'/megqc/figures/PSD_over_epoched_data_mags.png')\n",
    "            #plt.show()\n",
    "\n",
    "            #Gradiometers:\n",
    "            plt.figure()\n",
    "            plt.plot(freqs_mat_grads_cut.T, np.sqrt(psds_grads_cut_all.T))\n",
    "            plt.yscale='log'\n",
    "            plt.xlabel('Frequency (Hz)')\n",
    "            plt.ylabel('Power spectral density (T/m)²/Hz)')  #check the units!\n",
    "            plt.title(\"Welch's periodogram for all gradiometers. Only epoched data\")\n",
    "            plt.savefig('./derivatives/sub-'+sid+'/megqc/figures/PSD_over_epoched_data_grads.png')\n",
    "            #plt.show()\n",
    "\n",
    "        #Assign the new names for all the mags/grads psds calculated on EPOCHED CONCATENATED data to return them in the end of function:\n",
    "        freqs_mags=freqs_mags_cut\n",
    "        freqs_grads=freqs_grads_cut\n",
    "        psds_mags=psds_mags_cut_all\n",
    "        psds_grads=psds_grads_cut_all\n",
    "\n",
    "\n",
    "    return(mags, grads, freqs_mags, freqs_grads, psds_mags, psds_grads) \n",
    "    #mags, grads are channels (name, index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#try:\n",
    "mags, grads, freqs_mags, freqs_grads, psds_mags, psds_grads = Freq_Spectrum_meg(data=filtered_d, epoched=True, plotflag=True, sid='1', freq_min=1, freq_max=200, \n",
    "    n_fft=1000, n_per_seg=1000, freq_tmin=None, freq_tmax=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def Power_of_freq_meg(mags=mags, grads=grads, freqs_mags=freqs_mags, freqs_grads=freqs_grads, psds_mags=psds_mags, psds_grads=psds_grads, mean_power_per_band=True, plotflag=True, sid='1'):\n",
    "\n",
    "    # Power of frequencies calculation for all mags + grads channels separately, \n",
    "    # saving power + power/freq value in data frames.\n",
    "\n",
    "    from scipy.integrate import simps\n",
    "    import pandas as pd\n",
    "\n",
    "    # adopted from: https://raphaelvallat.com/bandpower.html\n",
    "    \n",
    "    # Calculate the band power:\n",
    "    wave_bands=[[0.5, 4], [4, 8], [8, 12], [12, 30], [30, 100]]\n",
    "    #delta (0.5–4 Hz), theta (4–8 Hz), alpha (8–12 Hz), beta (12–30 Hz), and gamma (30–100 Hz) bands\n",
    "\n",
    "    mags_names = [mag[0] for mag in mags]\n",
    "    grads_names = [grad[0] for grad in grads]\n",
    "\n",
    "    dict_mags_power = {}\n",
    "    dict_grads_power = {}\n",
    "\n",
    "    dict_mags_power_freq = {}\n",
    "    dict_grads_power_freq = {}\n",
    "\n",
    "    dict_mags_rel_power = {}\n",
    "    dict_grads_rel_power = {}\n",
    "\n",
    "    for w in enumerate(wave_bands): #loop over bands\n",
    "\n",
    "        low, high = w[1] # Define delta lower and upper limits\n",
    "        power_per_band = {\"mags\": [], \"grads\": []}\n",
    "        power_per_freq_per_band = {\"mags\": [], \"grads\": []}\n",
    "        rel_power_per_band = {\"mags\": [], \"grads\": []}\n",
    "\n",
    "    #loop over mags, then grads\n",
    "\n",
    "        idx_delta_m = np.logical_and(freqs_mags >= low, freqs_mags <= high)\n",
    "        for m in enumerate(psds_mags): \n",
    "        #loop over mags channels. psd_ch_m is psd of partigular channel\n",
    "\n",
    "            #ch_name_m=mags_names[m[0]]\n",
    "            psd_ch_m=np.array(m[1])\n",
    "\n",
    "            #Area under the curve:\n",
    "            # Frequency resolution\n",
    "            freq_res = freqs_mags[1] - freqs_mags[0]  # = 1 / 4 = 0.25\n",
    "\n",
    "            # Compute the absolute power by approximating the area under the curve\n",
    "            band_power_m = simps(psd_ch_m[idx_delta_m], dx=freq_res)\n",
    "\n",
    "            #devide the power by the  number of frequencies in the band\n",
    "            power_compare_m=band_power_m/sum(idx_delta_m) \n",
    "\n",
    "            #calculate the relative power: % of this band in the total bands power for this channel:\n",
    "            total_power_m = simps(psd_ch_m, dx=freq_res)\n",
    "            band_rel_power_m = band_power_m / total_power_m\n",
    "\n",
    "            power_per_band['mags'].append(band_power_m)\n",
    "            rel_power_per_band['mags'].append(band_rel_power_m)\n",
    "            power_per_freq_per_band['mags'].append(power_compare_m)\n",
    "\n",
    "        #print('mags done')\n",
    "\n",
    "        idx_delta_g = np.logical_and(freqs_grads >= low, freqs_grads <= high)\n",
    "        for g in enumerate(psds_grads): \n",
    "        #loop over grads channels and their names\n",
    "\n",
    "            #ch_name_g=grads_names[g[0]]\n",
    "            psd_ch_g=np.array(g[1])\n",
    "\n",
    "            #Area under the curve:\n",
    "            # Frequency resolution\n",
    "            freq_res = freqs_grads[1] - freqs_grads[0]  \n",
    "\n",
    "            # Compute the absolute power by approximating the area under the curve\n",
    "            band_power_g = simps(psd_ch_g[idx_delta_g], dx=freq_res)\n",
    "\n",
    "            #devide the power by the  number of frequencies in the band\n",
    "            power_compare_g=band_power_g/sum(idx_delta_g) \n",
    "\n",
    "            #calculate the relative power: % of this band in the total bands power for this channel:\n",
    "            total_power_g = simps(psd_ch_g, dx=freq_res)\n",
    "            band_rel_power_g = band_power_g / total_power_g\n",
    "\n",
    "            power_per_band['grads'].append(band_power_g)\n",
    "            rel_power_per_band['grads'].append(band_rel_power_g)\n",
    "            power_per_freq_per_band['grads'].append(power_compare_g)\n",
    "\n",
    "\n",
    "            \n",
    "        dict_mags_power[w[0]] = power_per_band[\"mags\"]\n",
    "        dict_grads_power[w[0]] = power_per_band[\"grads\"]\n",
    "\n",
    "        dict_mags_power_freq[w[0]] = power_per_freq_per_band[\"mags\"]\n",
    "        dict_grads_power_freq[w[0]] = power_per_freq_per_band[\"grads\"]\n",
    "\n",
    "        dict_mags_rel_power[w[0]] = rel_power_per_band[\"mags\"]\n",
    "        dict_grads_rel_power[w[0]] = rel_power_per_band[\"grads\"]\n",
    "\n",
    "\n",
    "    # Save power and delta_compare to data frame:\n",
    "    df_power_mags = pd.DataFrame(dict_mags_power, index=mags_names)\n",
    "    df_power_grads = pd.DataFrame(dict_grads_power, index=grads_names)\n",
    "\n",
    "    df_power_freq_mags = pd.DataFrame(dict_mags_power_freq, index=mags_names)\n",
    "    df_power_freq_grads = pd.DataFrame(dict_grads_power_freq, index=grads_names)\n",
    "\n",
    "    df_rel_power_mags = pd.DataFrame(dict_mags_rel_power, index=mags_names)\n",
    "    df_rel_power_grads = pd.DataFrame(dict_grads_rel_power, index=grads_names)\n",
    "\n",
    "    # Rename columns and extract to csv:\n",
    "\n",
    "    renamed_df_power_mags = df_power_mags.rename(columns={0: \"delta (0.5-4 Hz)\", 1: \"theta (4-8 Hz)\", 2: \"alpha (8-12 Hz)\", 3: \"beta (12-30 Hz)\", 4: \"gamma (30-100 Hz)\"})\n",
    "    renamed_df_power_grads = df_power_grads.rename(columns={0: \"delta (0.5-4 Hz)\", 1: \"theta (4-8 Hz)\", 2: \"alpha (8-12 Hz)\", 3: \"beta (12-30 Hz)\", 4: \"gamma (30-100 Hz)\"})\n",
    "\n",
    "    renamed_df_power_freq_mags = df_power_freq_mags.rename(columns={0: \"delta (0.5-4 Hz)\", 1: \"theta (4-8 Hz)\", 2: \"alpha (8-12 Hz)\", 3: \"beta (12-30 Hz)\", 4: \"gamma (30-100 Hz)\"})\n",
    "    renamed_df_power_freq_grads = df_power_freq_grads.rename(columns={0: \"delta (0.5-4 Hz)\", 1: \"theta (4-8 Hz)\", 2: \"alpha (8-12 Hz)\", 3: \"beta (12-30 Hz)\", 4: \"gamma (30-100 Hz)\"})\n",
    "\n",
    "    renamed_df_rel_power_mags = df_rel_power_mags.rename(columns={0: \"delta (0.5-4 Hz)\", 1: \"theta (4-8 Hz)\", 2: \"alpha (8-12 Hz)\", 3: \"beta (12-30 Hz)\", 4: \"gamma (30-100 Hz)\"})\n",
    "    renamed_df_rel_power_grads = df_rel_power_grads.rename(columns={0: \"delta (0.5-4 Hz)\", 1: \"theta (4-8 Hz)\", 2: \"alpha (8-12 Hz)\", 3: \"beta (12-30 Hz)\", 4: \"gamma (30-100 Hz)\"})\n",
    "\n",
    "\n",
    "    # Create csv file  for the user:\n",
    "   \n",
    "    renamed_df_power_mags.to_csv('./derivatives/sub-'+sid+'/megqc/csv files/abs_power_mags.csv')\n",
    "\n",
    "    renamed_df_power_grads.to_csv('./derivatives/sub-'+sid+'/megqc/csv files/abs_power_grads.csv')\n",
    "\n",
    "    renamed_df_power_freq_mags.to_csv('./derivatives/sub-'+sid+'/megqc/csv files/power_per_freq_mags.csv')\n",
    "\n",
    "    renamed_df_power_freq_grads.to_csv('./derivatives/sub-'+sid+'/megqc/csv files/power_per_freq_grads.csv')\n",
    "\n",
    "    renamed_df_rel_power_mags.to_csv('./derivatives/sub-'+sid+'/megqc/csv files/relative_power_mags.csv')\n",
    "\n",
    "    renamed_df_rel_power_grads.to_csv('./derivatives/sub-'+sid+'/megqc/csv files/relative_power_grads.csv')\n",
    "\n",
    "\n",
    "    if mean_power_per_band==True: #if user wants to see average power per band over all channels - calculate and plot here:\n",
    "\n",
    "        #Calculate power per band over all mags and all grads\n",
    "\n",
    "        import statistics \n",
    "\n",
    "        power_dfs=[df_power_mags, df_rel_power_mags, df_power_grads, df_rel_power_grads, df_power_freq_mags, df_power_freq_grads]\n",
    "        #keep them in this order!  important for this cell calculations\n",
    "\n",
    "        bands_names=['delta', 'theta', 'alpha', 'beta', 'gamma']\n",
    "        band_title=['Magnetometers. Average absolute power per band:', 'Magnetometers. Average relative power per band:',\n",
    "        'Gradiometers. Average absolute power per band:', 'Gradiometers. Average relative power per band:', \n",
    "        'Magnetometers. Average power/freq per band:', 'Gradiometers. Average power/freq per band:']\n",
    "\n",
    "        mean_abs_m=[]\n",
    "        mean_abs_g=[]\n",
    "        mean_relative_m=[]\n",
    "        mean_relative_g=[]\n",
    "        mean_power_nfreq_m=[]\n",
    "        mean_power_nfreq_g=[]\n",
    "\n",
    "        for d in enumerate(power_dfs):\n",
    "            print(band_title[d[0]])\n",
    "\n",
    "            for w in enumerate(bands_names): #loop over bands\n",
    "                mean_power_per_band = statistics.mean(d[1].loc[:,w[0]])\n",
    "                \n",
    "                if d[0]==0: #df_power_mags:\n",
    "                    mean_abs_m.append(mean_power_per_band) \n",
    "                elif d[0]==1: #df_rel_power_mags:\n",
    "                    mean_relative_m.append(mean_power_per_band) \n",
    "                elif d[0]==2: #df_power_grads:\n",
    "                    mean_abs_g.append(mean_power_per_band)\n",
    "                elif d[0]==3: #df_rel_power_grads:\n",
    "                    mean_relative_g.append(mean_power_per_band) \n",
    "                elif d[0]==4: #df_power_freq_mags:\n",
    "                    mean_power_nfreq_m.append(mean_power_per_band)\n",
    "                elif d[0]==5: #df_power_freq_grads:\n",
    "                    mean_power_nfreq_g.append(mean_power_per_band)\n",
    "                print(w[1], mean_power_per_band)\n",
    "\n",
    "\n",
    "        if plotflag==True:\n",
    "\n",
    "            #Visual: band power over all mags and grads as a pie chart:\n",
    "            #The mean relative percentages dont sum up into 100%, so added the 'unknown' part.\n",
    "\n",
    "            bands_names_un=['delta', 'theta', 'alpha', 'beta', 'gamma', 'unknown']\n",
    "\n",
    "            mean_relative_m_un=[v * 100 for v in mean_relative_m]  #in percentage\n",
    "            mean_relative_m_un.append(100-(sum(mean_relative_m))*100)\n",
    "            mean_relative_g_un=[v * 100 for v in mean_relative_g] #in percentage\n",
    "            mean_relative_g_un.append(100-(sum(mean_relative_g))*100)\n",
    "\n",
    "            fig1, axs = plt.subplots(1,2)\n",
    "            fig1.suptitle('Relative power of each band')\n",
    "            axs[0].pie(mean_relative_m_un, labels=bands_names_un, autopct='%1.1f%%') #autopct for percentage values\n",
    "            axs[0].axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n",
    "            axs[0].set_title('Magnetometers')\n",
    "            axs[1].pie(mean_relative_g_un, labels=bands_names_un, autopct='%1.1f%%')\n",
    "            axs[1].axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n",
    "            axs[1].set_title('Gradiometers')\n",
    "            plt.savefig('./derivatives/sub-'+sid+'/megqc/figures/Relative_power_per_band_over_all_channels.png')\n",
    "            plt.show()\n",
    "\n",
    "    # DECIDE WHAT TO OUTPUT HERE!\n",
    "    #ask Jochem about reference values for relative power values!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#try:\n",
    "\n",
    "Power_of_freq_meg(mags=mags, grads=grads, freqs_mags=freqs_mags, freqs_grads=freqs_grads, psds_mags=psds_mags, psds_grads=psds_grads, mean_power_per_band=True, plotflag=True, sid='1')\n",
    "#will output dataframes"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d401ab1bf6dd7bb97662b0feb1321a641d60d04842bfa92b47f7871360972b5d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('mne_new')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13 | packaged by conda-forge | (main, May 27 2022, 17:00:52) \n[Clang 13.0.1 ]"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
