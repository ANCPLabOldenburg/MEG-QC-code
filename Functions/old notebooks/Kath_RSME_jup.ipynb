{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Imports:\n",
    "import matplotlib\n",
    "matplotlib.use('MACOSX')\n",
    "\n",
    "from math import sqrt\n",
    "import os\n",
    "import numpy as np\n",
    "import mne\n",
    "#import matplotlib #doesnt it import through mne already?\n",
    "from copy import deepcopy\n",
    "\n",
    "#Open data:\n",
    "#sample_data_folder = mne.datasets.sample.data_path()\n",
    "#kath_raw_file2 = \"/Users/jenya/Documents/Oldenburg and university/Job Uni Rieger lab/Katharinas_Data/sub_HT05ND16/210811/mikado-1.fif\"\n",
    "#kath_raw_file = os.path.join('Katharinas_Data','sub_HT05ND16', '210811', 'mikado-1.fif')\n",
    "kath_raw_file='/Users/jenya/Local Storage/Job Uni Rieger lab/MEG QC code/data/sub_HT05ND16/210811/mikado-1.fif'\n",
    "\n",
    "#print(kath_raw_file2)                                   \n",
    "raw = mne.io.read_raw_fif(kath_raw_file)\n",
    "#raw = mne.io.read_raw_fif('/Users/jenya/Local Storage/Job Uni Rieger lab/MEG QC code/data/ds004276/sub-001/meg/sub-001_task-words_meg.fif')\n",
    "\n",
    "#raw.crop(0, 60).load_data()  # just use a fraction of data for speed here\n",
    "\n",
    "#Print info about the data:\n",
    "print(raw)\n",
    "print(raw.info)\n",
    "raw\n",
    "\n",
    "#crop the data to calculate faster\n",
    "\n",
    "raw_cropped = raw.copy()\n",
    "raw_cropped.crop(0, 300) #(first 5 min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% How to look up info and other usefull things. \n",
    "# CAN SKIP THIS WHOLE CELL, DOESNT AFFECT FURTHER STUFF\n",
    "\n",
    "#name of particular channel:\n",
    "raw.info['chs'][14]['ch_name']\n",
    "#See all channel names:\n",
    "print(raw.info['ch_names'])\n",
    "# see all avalinle info keys\n",
    "raw.info.keys()\n",
    "\n",
    "#See unit of channel number 15: (cos indexing from 0)\n",
    "raw.info['chs'][14]['unit']\n",
    "\n",
    "# Plot 5 sec of the first 30 channels.\n",
    "raw.plot(block=True, duration=5, n_channels=30)\n",
    "# HOW TO PLOT PARTICULAR RANGE OF CHANNELS?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mag_ch_names = raw.copy().pick_types(meg='mag').ch_names if 'mag' in raw else None\n",
    "grad_ch_names = raw.copy().pick_types(meg='grad').ch_names if 'grad' in raw else None\n",
    "\n",
    "channels = {'mags': mag_ch_names, 'grads': grad_ch_names}\n",
    "\n",
    "#Separate mags and grads:\n",
    "mags = [(chs['ch_name'], i) for i, chs in enumerate(raw.info['chs']) if str(chs['unit']).endswith('UNIT_T)')]\n",
    "grads = [(chs['ch_name'], i) for i, chs in enumerate(raw.info['chs']) if str(chs['unit']).endswith('UNIT_T_M)')]\n",
    "\n",
    "selected_channels = [ch[1] for ch in mags]\n",
    "data_channels, _ = raw[selected_channels, :]  \n",
    "\n",
    "\n",
    "data_channels2=raw.get_data(picks = channels['mags'])\n",
    "print(data_channels == data_channels2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering the data: 1-100Hz bandpass, because otherwise calculated stds are too high.\n",
    "# But actually after filtering they are still high\n",
    "# Upper level: No useful brain info comes over 100Hz\n",
    "# Lower level: maybe better from 0.5 because delta frequency is 0.5-4Hz? \n",
    "# (needed for frequency spectrum) and we cut it now. \n",
    "# But we do 1-100Hz for now.\n",
    "# Question: does this filtering change the magnitude of stds? from 9 to 12-13?\n",
    "\n",
    "# I m using here the Butterworth filter similar to filtfilt in matlab, like we  \n",
    "# did in the course with eeg data. such filter creates no time shift, since it filters forward and backward.\n",
    "# But we might use a different filter as well. I dont know if this one is the best possible option.\n",
    "\n",
    "#raw.crop(0, 60)\n",
    "\n",
    "raw_cropped.load_data(verbose=True)\n",
    "raw_bandpass = raw_cropped.copy()\n",
    "raw_bandpass.filter(l_freq=1, h_freq=100, picks='meg', method='iir', iir_params=None, verbose=True)\n",
    "\n",
    "# \"if method=”iir”, 4th order Butterworth will be used\" BUT it used filter order 16 here. and why is that???\n",
    "\n",
    "#Plot first 60 seconds of the filtered data:\n",
    "#(remove_dc=False) is copied from tutiril. I dont get what it means? No explanation in documentation.\n",
    "fig = raw_bandpass.plot(duration=60, proj=False, n_channels=len(raw.ch_names), remove_dc=False, verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#look at the new filtered raw:\n",
    "\n",
    "raw_bandpass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Find magnetometers and gradiometers:\n",
    "# unit t - magenetometer. unit M_T - gradiometer. (in this set name will end with 1 for magnet, \n",
    "# with 2and3 for grad.)\n",
    "\n",
    "mags = []\n",
    "grads=[]\n",
    "\n",
    "for i, chs in enumerate(raw_bandpass.info['chs']):\n",
    "\n",
    "    if str(chs['unit']).endswith('UNIT_T)'):\n",
    "        mags.append((chs['ch_name'], i))\n",
    "    elif str(chs['unit']).endswith('UNIT_T_M)'):\n",
    "        grads.append((chs['ch_name'], i))\n",
    "\n",
    "print('Magnetometers: ', mags)\n",
    "print('Gradiometers: ', grads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%other way (shorter):\n",
    "mags = [(chs['ch_name'], i) for i, chs in enumerate(raw_bandpass.info['chs']) if str(chs['unit']).endswith('UNIT_T)')]\n",
    "print('Magnetometers: ', mags)\n",
    "\n",
    "grads = [(chs['ch_name'], i) for i, chs in enumerate(raw_bandpass.info['chs']) if str(chs['unit']).endswith('UNIT_T_M)')]\n",
    "print('Gradiometers: ', grads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Found one more way using mne itself (check if shows the same as mine!)\n",
    "picks_grad = mne.pick_types(raw_bandpass.info, meg='grad', eeg=False, eog=True, stim=False)\n",
    "picks_mag = mne.pick_types(raw_bandpass.info, meg='mag', eeg=False, eog=True, stim=False)\n",
    "\n",
    "#Yes, shows the same as my code. Gives indexes of mags and grads (starting from 0), but no channel names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate data for mags and grads in 2 arrays.\n",
    "selected_mags = [item[1] for item in mags]\n",
    "selected_grads = [item[1] for item in grads]\n",
    "data_mags, times = raw_bandpass[selected_mags, :]  \n",
    "data_grads, times = raw_bandpass[selected_grads, :]  \n",
    "\n",
    "#may be useful later: get_data command \n",
    "# https://mne.tools/stable/generated/mne.io.Raw.html#mne.io.Raw.get_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Calculate STD or RMSE of each channel\n",
    "\n",
    "#Time how long it takes to calculate STD or RMSE:\n",
    "import time\n",
    "t0_std = time.time()\n",
    "\n",
    "#STD:\n",
    "std_mags=np.std(data_mags, axis=1) #calculate std of all magnetometers (along second dimantion)\n",
    "std_grads=np.std(data_grads, axis=1) #calculate std of all gradiometers (along second dimantion)\n",
    "\n",
    "t1_std = time.time()\n",
    "total_time_std = t1_std-t0_std\n",
    "\n",
    "mean_std_magn=np.mean(std_mags) #average std magnetometers\n",
    "mean_std_grad=np.mean(std_grads) #average std gradiometers\n",
    "\n",
    "print('Mean std of magnetometers data: ', mean_std_magn) #average std\n",
    "print('Max std of magnetometers data: ',max(std_mags)) #highest std\n",
    "print('Min std of magnetometers data: ',min(std_mags)) #lowest std.\n",
    "print('Mean std of gradiometers data: ', mean_std_grad) #average std\n",
    "print('Max std of gradiometers data: ',max(std_grads)) #highest std\n",
    "print('Min std of gradiometers data: ',min(std_grads)) #lowest std."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% RMSE:\n",
    "# https://stackoverflow.com/questions/17197492/is-there-a-library-function-for-root-mean-square-error-rmse-in-python\n",
    "\n",
    "t0_rmse = time.time()\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "#Magnitometers:\n",
    "y_actual_mags=data_mags\n",
    "y_predicted_mags=data_mags.mean(axis=1)\n",
    "#yeah i know i dont need to rename it, just easier for me this way to deal with RMSE concept\n",
    "\n",
    "rmse_mags = np.zeros(len(y_predicted_mags)) #RMSE of all magnetometers\n",
    "\n",
    "for i in range(len(y_predicted_mags)):\n",
    "    #print(i)\n",
    "    #print(y_actual[i, :])\n",
    "    #print(y_predicted[i])\n",
    "    y_predicted_vec_mags=np.ones(len(y_actual_mags[0]))*y_predicted_mags[i]\n",
    "    rmse_mags[i] = mean_squared_error(y_actual_mags[i, :], y_predicted_vec_mags, squared=False)\n",
    "\n",
    "#Gradiometers:\n",
    "y_actual_grads=data_grads\n",
    "y_predicted_grads=data_grads.mean(axis=1)\n",
    "#yeah i know i dont need to rename it, just easier for me this way to deal with RMSE concept\n",
    "\n",
    "rmse_grads = np.zeros(len(y_predicted_grads)) #RMSE of all gradiometers\n",
    "\n",
    "for i in range(len(y_predicted_grads)):\n",
    "    #print(i)\n",
    "    #print(y_actual[i, :])\n",
    "    #print(y_predicted[i])\n",
    "    y_predicted_vec_grads=np.ones(len(y_actual_grads[0]))*y_predicted_grads[i]\n",
    "    rmse_grads[i] = mean_squared_error(y_actual_grads[i, :], y_predicted_vec_grads, squared=False)\n",
    "\n",
    "\n",
    "print('Mean of magnetometers data: ', np.mean(rmse_mags)) #average RMSE\n",
    "print('Max of magnetometers data: ',max(rmse_mags)) #highest RMSE\n",
    "print('Min of magnetometers data: ',min(rmse_mags)) #lowest RMSE\n",
    "print('Mean of gradiometers data: ', np.mean(rmse_grads)) #average RMSE\n",
    "print('Max of gradiometers data: ',max(rmse_grads)) #highest RMSE\n",
    "print('Min of gradiometers data: ',min(rmse_grads)) #lowest RMSE\n",
    "\n",
    "\n",
    "t1_rmse = time.time()\n",
    "total_time_rmse = t1_rmse-t0_rmse\n",
    "\n",
    "print('Time to calculate std: ', total_time_std)\n",
    "print('Time to calculate rmse: ', total_time_rmse)\n",
    "\n",
    "#STD CALCULATION IS MUCH LESS COdE BUT TAKES LONGER THAN RMSE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DONT RUN. \n",
    "# Cos we decided to not pick the largest std, but look for channels outside of 1STD of all channels (next cell)\n",
    "# But this cell is kept in case we change the approach.\n",
    "\n",
    "# %% Pick channel with largest STD (RMSE)?\n",
    "# HOW DO WE DECIDE WHICH CHANNELS TO PICK? ANY PARTICULSR LIMIT?\n",
    "# If not - just display here channels with largest STD for user to decide\n",
    "largest_std_mags= np.where(std_mags == max(std_mags))\n",
    "largest_std_grads= np.where(std_grads == max(std_grads))\n",
    "\n",
    "mag_channel_largest_std=mags[largest_std_mags[0][0]]\n",
    "grad_channel_largest_std=grads[largest_std_grads[0][0]]\n",
    "print('Magnetometer with largest STD: ', mag_channel_largest_std[0])\n",
    "print('Gradiometer with largest STD: ', grad_channel_largest_std[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if channel data is within 1 std over all channels.\n",
    "# COMMENT: can use -3 to 3 (or other number) std istead of -1/+1 std, but this can adjusted later. \n",
    "# find our own best value. or make it user input? 1 std is too narrow, gives way too many bad channels.\n",
    "\n",
    "std_std_mags=np.std(std_mags)\n",
    "std_std_grads=np.std(std_grads)\n",
    "\n",
    "mean_std_mags=np.mean(std_mags)\n",
    "mean_std_grads=np.mean(std_grads)\n",
    "\n",
    "ch_large_std_mags= np.where(std_mags > mean_std_mags+std_std_mags) # | std_mags < mean_std_magn-std_std_mags)\n",
    "ch_large_std_grads= np.where(std_grads > mean_std_grads+std_std_grads) # | std_grads < mean_std_grad-std_std_grads)\n",
    "\n",
    "ch_small_std_mags= np.where(std_mags < mean_std_mags-std_std_mags)\n",
    "ch_small_std_grads= np.where(std_grads < mean_std_grads-std_std_grads)\n",
    "\n",
    "\n",
    "#print(ch_large_std_mags[0])\n",
    "\n",
    "magn_channel_big_std=np.array(mags)[ch_large_std_mags[0]]\n",
    "grad_channel_big_std=np.array(grads)[ch_large_std_grads[0]]\n",
    "\n",
    "magn_channel_small_std=np.array(mags)[ch_small_std_mags[0]]\n",
    "grad_channel_small_std=np.array(grads)[ch_small_std_grads[0]]\n",
    "\n",
    "print('Magnetometers with high STD: ', magn_channel_big_std)\n",
    "print('Gradiometers with high STD: ',grad_channel_big_std)\n",
    "\n",
    "print('Magnetometers with low STD: ', magn_channel_small_std)\n",
    "print('Gradiometers with low STD: ',grad_channel_small_std)\n",
    "\n",
    "\n",
    "#why is MEG0223 not detected as noisy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Now want to see for example 2 channels with high std: \n",
    "#chans = ['MEG2311', 'MEG1542']\n",
    "noisy_chans = [magn_channel_big_std[0][0], grad_channel_big_std[0][0]]\n",
    "chan_idxs = [raw_bandpass.ch_names.index(ch) for ch in noisy_chans]\n",
    "#original_raw_bandpass.plot(order=chan_idxs, start=12, duration=4)\n",
    "raw_bandpass.plot(order=chan_idxs, start=12, duration=4) #plot here only a part of channel.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 STD over all channels means: \n",
    "# Take mean over all stds.\n",
    "# And -1 STD over all stds from mean\n",
    "# And +1 std over all stds from mean\n",
    "# This range means \"within 1 std over all channels\"\n",
    "# Here visualise this idea. Middle line is the mean of stds:\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "#%matplotlib qt\n",
    "#%matplotlib inline\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(2)\n",
    "fig.suptitle('STDs')\n",
    "ax1.plot(list(range(1, len(std_mags)+1)), std_mags)\n",
    "ax1.plot(list(range(1, len(std_mags)+1)), [mean_std_mags]*len(std_mags))\n",
    "ax1.plot(list(range(1, len(std_mags)+1)), [mean_std_mags-std_std_mags]*len(std_mags))\n",
    "ax1.plot(list(range(1, len(std_mags)+1)), [mean_std_mags+std_std_mags]*len(std_mags))\n",
    "ax1.set(xlabel='Magnetometer', ylabel='STD')\n",
    "\n",
    "ax2.plot(list(range(1, len(std_grads)+1)), std_grads)\n",
    "ax2.plot(list(range(1, len(std_grads)+1)), [mean_std_grads]*len(std_grads))\n",
    "ax2.plot(list(range(1, len(std_grads)+1)), [mean_std_grads-std_std_grads]*len(std_grads))\n",
    "ax2.plot(list(range(1, len(std_grads)+1)), [mean_std_grads+std_std_grads]*len(std_grads))\n",
    "ax2.set(xlabel='Gradiometer', ylabel='STD')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "#BUT NO! THEY R STILL AT ^-9 AND ^-7!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DONT RUN.  \n",
    "# ADD CHANNELS TO BADS. Only if we want to later!\n",
    "\n",
    "original_bads = deepcopy(raw_bandpass.info['bads'])\n",
    "#raw_bandpass.info['bads'].append('EEG 050')               # add a single channel\n",
    "#raw_bandpass.info['bads'].extend(['EEG 051', 'EEG 052'])  # add a list of channels\n",
    "#bad_chan = raw_bandpass.info['bads'].pop(-1)  # remove the last entry in the list\n",
    "#raw_bandpass.info['bads'] = original_bads     # change the whole list at once\n",
    "\n",
    "#Add to bads only channels with big STD (both grads and mags):\n",
    "for m in magn_channel_big_std:\n",
    "\traw_bandpass.info['bads'].append(m[0])\n",
    "\n",
    "for g in grad_channel_big_std:\n",
    "\traw_bandpass.info['bads'].append(g[0])\n",
    "\n",
    "print(raw_bandpass.info['bads'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Next need to calculate also stds for each separate epoch. Because over the all time noisy cgannel can just even out and not be noticed.\n",
    "# \n",
    "# Extracting events and then epoching the data:\n",
    "# \n",
    "# \"STIM channels record voltages (usually short, rectangular DC pulses of fixed magnitudes sent from \n",
    "# the experiment-controlling computer) that are time-locked to experimental events, such as the \n",
    "# onset of a stimulus or a button-press response by the subject (those pulses are sometimes called \n",
    "# TTL pulses, event pulses, trigger signals, or just “triggers”). In other cases, these pulses may \n",
    "# not be strictly time-locked to an experimental event, but instead may occur in between trials \n",
    "# to indicate the type of stimulus (or experimental condition) that is about to occur on the \n",
    "# upcoming trial.\"\n",
    "\n",
    "#Look at the stimulus channel (can limit to only 3-6 sec here for example, or not):\n",
    "#raw_bandpass.copy().pick_types(meg=False, stim=True).plot(start=3, duration=6)\n",
    "raw_bandpass.copy().pick_types(meg=False, stim=True).plot()\n",
    "\n",
    "events = mne.find_events(raw_bandpass, stim_channel='STI101', min_duration=1.2)\n",
    "\n",
    "# WHAT IS OPTIMAL DURATION? GIVES DIFFERENT NUMBER OF EVENTS ACCORDING TO DURATION. \n",
    "# MAKE DURATION AS USER_PICKED VARIABLE\n",
    "# min_duration: The minimum duration of a change in the events channel required to consider it as an event (in seconds).\n",
    "\n",
    "# STI101 is stim data in this file. might be different name in another! \n",
    "# (it can be STI 014 in older systems for example). \n",
    "# There can as well be several sti channels, and we need the main one which summs all the others.\n",
    "# HERE WRITE THE CODE THAT WILL AUTOMATICALLY DETECT THE MAIN STI CHANNEL OR allow mne to find it itself:\n",
    "\n",
    "#\"If you don’t provide the name of a STIM channel, find_events will first look for MNE-Python \n",
    "# config variables for variables MNE_STIM_CHANNEL, MNE_STIM_CHANNEL_1, etc. If those are not \n",
    "# found, channels STI 014 and STI101 are tried, followed by the first channel with type “STIM” \n",
    "# present in raw.ch_names. If you regularly work with data from several different MEG systems \n",
    "# with different STIM channel names, setting the MNE_STIM_CHANNEL config variable may not be \n",
    "# very useful, but for researchers whose data is all from a single system it can be a time-saver \n",
    "# to configure that variable once and then forget about it.\"\n",
    "\n",
    "# findevents description:\n",
    "# https://mne.tools/stable/generated/mne.find_events.html#mne.find_events\n",
    "# https://mne.tools/stable/auto_tutorials/intro/20_events_from_raw.html\n",
    "\n",
    "\n",
    "#now look at events:\n",
    "print(events[:5])  # show the first 5\n",
    "\n",
    "#Plot events:\n",
    "fig = mne.viz.plot_events(events, sfreq=raw_bandpass.info['sfreq'],\n",
    "                          first_samp=raw_bandpass.first_samp) #, event_id=event_dict)\n",
    "#fig.subplots_adjust(right=0.7)  # make room for legend\n",
    "\n",
    "# \"The resulting events array is an ordinary 3-column NumPy array, with sample number in the first column \n",
    "# and integer event ID in the last column; the middle column is usually ignored. Rather than keeping \n",
    "# track of integer event IDs, we can provide an event dictionary that maps the integer IDs to experimental \n",
    "# conditions or events.\"\n",
    "\n",
    "\n",
    "#Plots events with the data:\n",
    "\n",
    "raw_bandpass.plot(events=events, start=5, duration=300, color='gray',\n",
    "         event_color={9: 'r', 19: 'g', 20: 'b', 21: 'm', 22: 'y'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DONT RUN - JUST USEFUL FOR THE FUTURE STUFF\n",
    "\n",
    "# Continue working with events - extra features:\n",
    "\n",
    "# How to detect events to then epoch data:\n",
    "#https://mne.tools/stable/auto_tutorials/intro/10_overview.html#sphx-glr-auto-tutorials-intro-10-overview-py\n",
    "\n",
    "\n",
    "#create even dictionary if needed:\n",
    "event_dict = {'auditory/left': 1, 'auditory/right': 2, 'visual/left': 3,\n",
    "              'visual/right': 4, 'smiley': 5, 'buttonpress': 32}\n",
    "\n",
    "#This here would allow to reject particular epochs in data. Values are copied from tutorial.\n",
    "#We would need to first epoch our own data, calculate std over different epochs and channels \n",
    "# and then decide which values to put here.\n",
    "\n",
    "reject_criteria = dict(mag=4000e-15,     # 4000 fT\n",
    "                       grad=4000e-13,    # 4000 fT/cm\n",
    "                       eeg=150e-6,       # 150 µV\n",
    "                       eog=250e-6)       # 250 µV\n",
    "\n",
    "\n",
    "#For some experiments (such as those intending to analyze resting-state activity) there may not \n",
    "# be any experimental events included in the raw recording. In such cases, an Events array of \n",
    "# equally-spaced events can be generated using mne.make_fixed_length_events():\n",
    "\n",
    "new_events = mne.make_fixed_length_events(raw_bandpass, start=5, stop=50, duration=2.)\n",
    "\n",
    "#By default, the events will all be given the integer Event ID of 1, but you can change that \n",
    "# with the id parameter. It is also possible to specify an overlap duration — i.e., if you ultimately\n",
    "#  want epochs that are 2.5 seconds long, but you want them to overlap by 0.5 seconds, you can specify \n",
    "# duration=2.5, overlap=0.5 in the call to make_fixed_length_events() (this will yield the same spacing \n",
    "# of events as duration=2, overlap=0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Epoching the data:\n",
    "\n",
    "epochs = mne.Epochs(raw_bandpass, events, tmin=-0.2, tmax=1, preload=True, baseline = None) #, event_id=event_dict, reject=reject_criteria)\n",
    "# tmin, tmax: float. Start and end time of the epochs in seconds, relative to the time-locked event. Defaults to -0.2 and 0.5, respectively.\n",
    "# MAKE THESE A USER_DEFINED_VARIABLE. Usually -1 and 3s used. this influences a lot the speed of further calculations.\n",
    "\n",
    "print(epochs)\n",
    "\n",
    "#Just for visual: look at the epochs and at the locations of the sensors:\n",
    "\n",
    "epochs.plot()\n",
    "#By default plots channels grouped by type: first grads, then mags.\n",
    "#black veryical lines separate ther epochs.\n",
    "\n",
    "epochs.plot_sensors(kind='3d', ch_type='all')\n",
    "#plots the position of each channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHECK NOT ONLY STD OF THE WHOLE CHANNEL BUT ALSO EPOCHS FOR CHANNELS:\n",
    "# 1.Loop over the epochs of each channel and check for every separate mag and grad and calculate std\n",
    "# 2.Check which epochs for which channel are over std of this epoch for all channels\n",
    "\n",
    "#Present epochs as data frame:\n",
    "df = epochs.to_data_frame(time_format=None, scalings=dict(mag=1, grad=1))\n",
    "#by default, channel measurement values are scaled so that EEG data are converted \n",
    "# to µV, magnetometer data are converted to fT, and gradiometer data are converted \n",
    "# to fT/cm. These scalings can be customized through the scalings parameter, or \n",
    "# suppressed by passing scalings=dict(eeg=1, mag=1, grad=1).\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 1) Loop over the epochs of each channel and check for every separate magn and grad and calculate std\n",
    "\n",
    "import pandas as pd\n",
    "eps=list(range(0,len(events))) #list of epoch numbers\n",
    "mags_names = [mag[0] for mag in mags]\n",
    "grads_names = [grad[0] for grad in grads]\n",
    "\n",
    "combined_names = {\"mags\": mags_names, \"grads\": grads_names}\n",
    "\n",
    "dict_mags = {}\n",
    "dict_grads = {}\n",
    "\n",
    "for ep in eps: #loop over each epoch\n",
    "    rows_for_ep = [row for row in df.iloc if row.epoch == ep] #take all rows of 1 epoch, all channels.\n",
    "\n",
    "    std_epoch = {\"mags\": [], \"grads\": []} #dictionary with stds\n",
    "\n",
    "    for key_of_list in combined_names: #loop over mags, then grads\n",
    "\n",
    "        for ch_name in combined_names[key_of_list]: #loop over channel names\n",
    "            \n",
    "            data_ch_epoch = [row_m[ch_name] for row_m in rows_for_ep]\n",
    "            #take the data \n",
    "\n",
    "            std_ch_ep = np.std(data_ch_epoch)\n",
    "\n",
    "            std_epoch[key_of_list].append(std_ch_ep)\n",
    "\n",
    "    dict_mags[ep] = std_epoch[\"mags\"]\n",
    "    dict_grads[ep] = std_epoch[\"grads\"]\n",
    "\n",
    "df_std_mags = pd.DataFrame(dict_mags, index=mags_names)\n",
    "df_std_grads = pd.DataFrame(dict_grads, index=grads_names)\n",
    "\n",
    "print('Mags std df: ')\n",
    "df_std_mags\n",
    "#print('Grads std df: ')\n",
    "#df_std_grads\n",
    "\n",
    "\n",
    "# might take really long (depending on the chosen length of epoch). \n",
    "# Try to make my RSME calculation into a functin and use insted of std."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1*)To check if calculations above were right:\n",
    "# Important checking step. Noticed: if give time for epoch -1 to 3s, might drop the whole 0 epoch, \n",
    "# then will give out false here. Dont know the reason for the issue.\n",
    "\n",
    "#How to find all indices of particular epoch in this dataframe\n",
    "epoch0_ind=df.index[df['epoch'] == 0].tolist()\n",
    "\n",
    "ch0111=df.iloc[epoch0_ind, 3+11] #all data of epoch 0 for MEG0111. \n",
    "#index of this channel in raw: 11. moved by 3 elements because data frame creates 3 additional columns\n",
    "print('data for MEG0111 of epoch 0: ', ch0111)\n",
    "ch0111_std=np.std(ch0111)\n",
    "print('Should be: ', ch0111_std)\n",
    "print('Calculated: ', df_std_mags.iloc[0,0])\n",
    "print(ch0111_std==df_std_mags.iloc[0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NEW! STD over Epochs. Do the same as precious, but use separate dfs for mags and grads: \n",
    "# part 1) separate dfs craetion\n",
    "\n",
    "picks_grad = mne.pick_types(raw_bandpass.info, meg='grad', eeg=False, eog=False, stim=False)\n",
    "picks_magn = mne.pick_types(raw_bandpass.info, meg='mag', eeg=False, eog=False, stim=False)\n",
    "\n",
    "#events = mne.find_events(raw_bandpass, stim_channel='STI101', min_duration=1.2)\n",
    "#n_events=len(events)\n",
    "\n",
    "epochs_mags = mne.Epochs(raw_bandpass, events, picks=picks_magn, tmin=-0.2, tmax=1, preload=True, baseline = None)\n",
    "epochs_grads = mne.Epochs(raw_bandpass, events, picks=picks_grad, tmin=-0.2, tmax=1, preload=True, baseline = None)\n",
    "\n",
    "#epochs = mne.Epochs(raw_bandpass, events, tmin=-0.2, tmax=1, preload=True, baseline = None) #, event_id=event_dict, reject=reject_criteria)\n",
    "\n",
    "\n",
    "#Present epochs as data frame - separately for mags and grads\n",
    "\n",
    "df_epochs_mags = epochs_mags.to_data_frame(time_format=None, scalings=dict(mag=1, grad=1))\n",
    "\n",
    "df_epochs_grads = epochs_grads.to_data_frame(time_format=None, scalings=dict(mag=1, grad=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 2) Part 2. Make function to loop over epochs and apply it to mags and grads\n",
    "\n",
    "import pandas as pd\n",
    "eps=list(range(0,len(events))) #list of epoch numbers\n",
    "\n",
    "mags_names = [mag[0] for mag in mags]\n",
    "grads_names = [grad[0] for grad in grads]\n",
    "\n",
    "def std_mg(mg_names, df_mg):\n",
    "    dict_mg = {}\n",
    "\n",
    "    for ep in eps: #loop over each epoch\n",
    "        rows_for_ep = [row for row in df_mg.iloc if row.epoch == ep] #take all rows of 1 epoch, all channels.\n",
    "        std_epoch = [] #list with stds\n",
    "\n",
    "        for ch_name in mg_names: #loop over channel names\n",
    "            data_ch_epoch = [row_mg[ch_name] for row_mg in rows_for_ep] #take the data for 1 epoch for 1 channel\n",
    "            std_ch_ep = np.std(data_ch_epoch)\n",
    "            std_epoch.append(std_ch_ep)\n",
    "\n",
    "        dict_mg[ep] = std_epoch\n",
    "\n",
    "    df_std_mg = pd.DataFrame(dict_mg, index=mg_names)\n",
    "\n",
    "    return(df_std_mg)\n",
    "   \n",
    "#Apply this function for mags and grads:\n",
    "df_std_mags_2=std_mg(df_mg=df_epochs_mags, mg_names=mags_names)\n",
    "df_std_grads_2=std_mg(df_mg=df_epochs_grads, mg_names=grads_names)\n",
    "\n",
    "#look at it:\n",
    "df_std_mags_2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2! To check if calculations above were right:\n",
    "# Here calculate by hand std over epoch 0 for channel MEG0111, taking data from df_epochs_mags\n",
    "\n",
    "# Important checking step. \n",
    "\n",
    "#How to find all indices of particular epoch in this dataframe\n",
    "epoch0_ind=df_epochs_mags.index[df_epochs_mags['epoch'] == 0].tolist()\n",
    "\n",
    "ch0111=df_epochs_mags.iloc[epoch0_ind, 0+3] #all data of epoch 0 for MEG0111. \n",
    "#index of this channel in raw: 0. moved by 3 elements because data frame creates 3 additional columns\n",
    "print('data for MEG0111 of epoch 0: ', ch0111)\n",
    "ch0111_std=np.std(ch0111)\n",
    "print('Should be: ', ch0111_std)\n",
    "print('Calculated: ', df_std_mags_2.iloc[0,0])\n",
    "print(ch0111_std==df_std_mags_2.iloc[0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3! BUT: apparently whole epoching the data points are calculated differently,\n",
    "# if mags and grads are separate or if they are together!\n",
    "# differnce is at about 8-10th digit after the coma and further. \n",
    "# Some scaling issue?\n",
    "# This cell show they are differnt:\n",
    "\n",
    "#How to find all indices of particular epoch in this dataframe\n",
    "epoch0_ind=df.index[df['epoch'] == 0].tolist()\n",
    "ch0111=df.iloc[epoch0_ind, 3+11] #all data of epoch 0 for MEG0111. \n",
    "#index of this channel in raw: 11. moved by 3 elements because data frame creates 3 additional columns\n",
    "\n",
    "epoch0_ind_mag=df_epochs_mags.index[df_epochs_mags['epoch'] == 0].tolist()\n",
    "ch0111_mag=df_epochs_mags.iloc[epoch0_ind, 3] #all data of epoch 0 for MEG0111. \n",
    "\n",
    "print('Values that are not equal between df (mags+grads togetehr) and df_epochs_mags (separate): ')\n",
    "for index, value in enumerate(ch0111):\n",
    "    if value != ch0111_mag[index]:\n",
    "        print(\"Not equal:\", index, \"\\n\", value, \"\\n\", ch0111_mag[index], \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) Check (which epochs for which channel) are over 1STD for (this epoch for all channels)\n",
    "\n",
    "std_lvl=1\n",
    "\n",
    " #Find what is 1 std over all channels per 1 epoch:\n",
    "std_std_mags_per_epoch=[]\n",
    "std_std_grads_per_epoch=[]\n",
    "mean_std_mags_per_epoch=[]\n",
    "mean_std_grads_per_epoch=[]\n",
    "\n",
    "for ep in eps: #goes over each epoch\n",
    "    std_std_mags_per_epoch.append(np.std(df_std_mags.iloc[:, ep])) #std of stds of all channels of every single epoch\n",
    "    std_std_grads_per_epoch.append(np.std(df_std_grads.iloc[:, ep]))\n",
    "\n",
    "    mean_std_mags_per_epoch.append(np.mean(df_std_mags.iloc[:, ep])) #mean of stds of all channels of every single epoch\n",
    "    mean_std_grads_per_epoch.append(np.mean(df_std_grads.iloc[:, ep]))\n",
    "\n",
    "\n",
    "df_ch_ep_large_std_mags=df_std_mags.copy()\n",
    "df_ch_ep_large_std_grads=df_std_grads.copy()\n",
    "\n",
    "df_ch_ep_small_std_mags=df_std_mags.copy()\n",
    "df_ch_ep_small_std_grads=df_std_grads.copy()\n",
    "\n",
    "#Now see which channles in epoch are over 1 std or under -1 std:\n",
    "for ep in eps: #goes over each epoch   \n",
    "    df_ch_ep_large_std_mags.iloc[:,ep] = df_ch_ep_large_std_mags.iloc[:,ep] > mean_std_mags_per_epoch[ep]+std_lvl*std_std_mags_per_epoch[ep] #magnetometers\n",
    "    df_ch_ep_large_std_grads.iloc[:,ep] = df_ch_ep_large_std_grads.iloc[:,ep] > mean_std_grads_per_epoch[ep]+std_lvl*std_std_grads_per_epoch[ep] #gradiometers\n",
    "\n",
    "    df_ch_ep_small_std_mags.iloc[:,ep] = df_ch_ep_small_std_mags.iloc[:,ep] < mean_std_mags_per_epoch[ep]-std_lvl*std_std_mags_per_epoch[ep] #magnetometers\n",
    "    df_ch_ep_small_std_grads.iloc[:,ep] = df_ch_ep_small_std_grads.iloc[:,ep] < mean_std_grads_per_epoch[ep]-std_lvl*std_std_grads_per_epoch[ep] #gradiometers\n",
    "\n",
    "\n",
    "#look at dataframe:\n",
    "print('Magnetometers: (which epoch in which channels) are over 1STD in (this epoch over all channels). True=over: ')\n",
    "df_ch_ep_large_std_mags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create csv file from the last data frame for the user:\n",
    "\n",
    "df_ch_ep_large_std_mags.to_csv('/Users/jenya/Local Storage/Job Uni Rieger lab/MEG QC code/large_std_mags.csv')\n",
    "df_ch_ep_large_std_grads.to_csv('/Users/jenya/Local Storage/Job Uni Rieger lab/MEG QC code/large_std_grads.csv')\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d401ab1bf6dd7bb97662b0feb1321a641d60d04842bfa92b47f7871360972b5d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('mne_new': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13 | packaged by conda-forge | (main, May 27 2022, 17:00:52) \n[Clang 13.0.1 ]"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
