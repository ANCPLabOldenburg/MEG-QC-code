{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This notebook is trying out different pipeline approaches\n",
    "\n",
    "# Cropped data is used here (5 minutes only), tried on whole data - takes forever.\n",
    "\n",
    "\n",
    "#Load data, make folders\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "import mne\n",
    "import pyprep as pp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#from Functions.main_meg_qc import initial_stuff\n",
    "from data_load_and_folders import load_meg_data\n",
    "duration=5 #in minutes\n",
    "#n_events, df_epochs_mags, df_epochs_grads, epochs_mags, epochs_grads, mags, grads, filtered_d, filtered_d_resamp, raw_cropped, raw=initial_stuff(duration)\n",
    "\n",
    "#data_file = '/Volumes/M2_DATA/MEG_QC_stuff/data/from openneuro/ds003483/sub-009/ses-1/meg/sub-009_ses-1_task-deduction_run-1_meg.fif'\n",
    "#data_file = '/Volumes/M2_DATA/MEG_QC_stuff/data/from openneuro/ds003352/sub-1/ses-01/meg/sub-1_ses-01_task-ColorSpirals_run-00_meg.fif'\n",
    "#data_file = '/Volumes/M2_DATA/MEG_QC_stuff/data/from openneuro/ds003352/sub-4/ses-02/meg/sub-4_ses-02_task-ColorSpirals_run-01_meg.fif'\n",
    "#data_file = '/Volumes/M2_DATA/MEG_QC_stuff/data/from openneuro/ds003392/sub-01/meg/sub-01_task-localizer_meg.fif'\n",
    "#data_file = '/Volumes/M2_DATA/MEG_QC_stuff/data/from openneuro/ds003645/sub-002/meg/sub-002_task-FacePerception_run-1_meg.fif'\n",
    "data_file = '/Volumes/M2_DATA/MEG_QC_stuff/data/from openneuro/ds003682/sub-001/ses-01/meg/sub-001_ses-01_task-AversiveLearningReplay_run-01_meg.fif'\n",
    "\n",
    "\n",
    "raw, channels = load_meg_data(data_file)\n",
    "\n",
    "#crop the data to calculate faster\n",
    "raw_cropped = raw.copy()\n",
    "#raw_cropped.crop(tmin=1100, tmax=None) \n",
    "\n",
    "raw_cropped\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Annotate bad peak to peak amplitudes: peaks and flats\n",
    "# USE TO MARK WHOLE CHANNELS AS BAD\n",
    "\n",
    "# https://mne.tools/stable/generated/mne.preprocessing.annotate_amplitude.html\n",
    "# copmpare this MNE function with what I wrote myself: Funnks - > Peaks_meg_qc -> neighbour_peak_amplitude\n",
    "\n",
    "#'Creates annotations BAD_peak or BAD_flat for spans of data where consecutive samples exceed the threshold in peak or fall below the threshold \n",
    "# in flat for more than min_duration' \n",
    "\n",
    "amplit_annot=mne.preprocessing.annotate_amplitude(raw_cropped, peak={'mag':4e-14, 'grad': 4e-14}, flat=3e-14, bad_percent=5, min_duration=0.002, verbose=True)\n",
    "\n",
    "#  !!! Automatically choose peak and flat values by averaging the data maybe?\n",
    "\n",
    "\n",
    "# Some input parameters:\n",
    "# * bad_percent - percent of tolerated bad segments in the channel. id some channel is over this percent - will be returned as \"bads\". \n",
    "#   While if its under, just the points will be returned as \"bad peak or \"bad flat\"\n",
    "#   However I dont see any info about which channel these points belong to! Which is totally stupid?\n",
    "# * picks can call channel types or separate channel names like: picks=['grad'] or picks=['MEG0111']\n",
    "# * alterbnatively u can specify peaks and/or flats values for types of channels like: peak={'mag':3.5e-11, 'grad': 4e-11} (but not the names of channels).\n",
    "# * min_duration is in minutes\n",
    "# * peaks and flats are in the same scale as the data, like: 1e-13\n",
    "\n",
    "# Differences with my function in Funks.Peaks_meg_gc.ipynb: \n",
    "# - no option to set distance between up and down peak to be concedered a pair. They calculate peak like: abs(a[i+1] - a[i]) ≥ peak (from docs).\n",
    "#   So we can probably adjust indexing of 'a' here to decide which peaks concider as an up+down pair.\n",
    "# - This function need raw obj as input. So not epochs and not just a piece of data -> need to adjust it for epochs. \n",
    "# - Can set here extra: flat, percent of bad, min duration and actual height of peaks and flats.\n",
    "\n",
    "# Now need to add these annotation obj to the raw:\n",
    "raw_cropped.set_annotations(raw_cropped.annotations + amplit_annot[0])  \n",
    "raw_cropped.info['bads'] = amplit_annot[1]\n",
    "# annotate_amplitude creates a tuple, not just annotations, like other functions from this series. \n",
    "# Second part of tuple is 'bads' (whole channel is bad, too many bad segments). \n",
    "# This whole tuple can't be added to annots in raw, need to slice the first part like: [0]\n",
    "\n",
    "\n",
    "#print('\\nAnnotations added to raw:', raw_cropped.annotations)\n",
    "#print('Channels added to bads in raw:', raw_cropped.info['bads'],\"\\n\")\n",
    "\n",
    "\n",
    "# ANNOTATIONS ARE SUMMED HERE. SO IF YOU WANT TO OVERWRITE THEM, RUN ALL CELLS ABOVE AGAIN OR JUST DELETE THE ANNOTATIONS like: \n",
    "# idx=[a for a in range(0,len(raw_cropped.annotations))] #all annotations chosen for removal\n",
    "# raw_cropped.annotations.delete(idx)\n",
    "# ONLY RERUNNING THIS ONE CELL WILL NOT REMOVE OLD ANNOTS FROM RAW. \n",
    "\n",
    "# raw_cropped.plot() #plot the data with annotations\n",
    "\n",
    "sid='009'\n",
    "# export annotation to dataframe:\n",
    "df_annot=raw_cropped.annotations.to_data_frame()\n",
    "df_annot.to_csv('../derivatives/sub-'+sid+'/megqc/csv files/ptp_amplitude_annots_all.csv')\n",
    "df_annot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since this function doesnt give channel names, need to loop over every channel and add its name into every annotation.\n",
    "# mne.Annotations obj doesnt allow changing, so will have to create a new object and write explicitly all info + channel name there.\n",
    "\n",
    "# USE TO MARK EPOCH AS BAD, EXTRACT TIME OF FLAT/PEAK + WHICH CHANNEL\n",
    "\n",
    "def get_amplitude_annots_per_channel(raw: mne.io.Raw, peak: float, flat: float, ch_type_names: list) -> tuple[pd.DataFrame, list]:\n",
    "    \"\"\"Function creates amplitude (peak-to-peak annotations for every channel separately\"\"\"\n",
    "    \n",
    "    amplit_annot_with_ch_names=mne.Annotations(onset=[], duration=[], description=[], orig_time=raw.annotations.orig_time) #initialize \n",
    "    bad_channels=[]\n",
    "\n",
    "    for channel in ch_type_names:\n",
    "        #get annotation object:\n",
    "        amplit_annot=mne.preprocessing.annotate_amplitude(raw, peak=peak, flat=flat , bad_percent=5, min_duration=0.002, picks=[channel], verbose=False)\n",
    "        \n",
    "        bad_channels.append(amplit_annot[1]) #Can later add these into annotation as well.\n",
    "\n",
    "        if len(amplit_annot[0])>0:\n",
    "\n",
    "            #create new annot obj and add there all data + channel name:\n",
    "            amplit_annot_with_ch_names.append(onset=amplit_annot[0][0]['onset'], duration=amplit_annot[0][0]['duration'], description=amplit_annot[0][0]['description'], ch_names=[[channel]])\n",
    "\n",
    "    df_ptp_amlitude_annot=amplit_annot_with_ch_names.to_data_frame()\n",
    "\n",
    "    return df_ptp_amlitude_annot, bad_channels, amplit_annot_with_ch_names\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # clear annotations:\n",
    "# idx=[a for a in range(0,len(raw_cropped.annotations))] #all annotations chosen for removal\n",
    "# raw_cropped.annotations.delete(idx)\n",
    "\n",
    "peak_m=4e-14\n",
    "peak_g=4e-14\n",
    "flat=3e-14\n",
    "bad_percent = 5\n",
    "min_duration = 0.002\n",
    "\n",
    "raw_cropped = raw.copy()\n",
    "raw_cropped.crop(tmin=1100, tmax=None) \n",
    "# annotate amplitude per channel:\n",
    "#df_ptp_amlitude_annot_mags, bad_channels, amplit_annot_with_ch_names_mags=get_amplitude_annots_per_channel(raw_cropped, peak_m, flat, ch_type_names=channels['mags'])\n",
    "#df_ptp_amlitude_annot_grads, bad_channels, amplit_annot_with_ch_names_grads=get_amplitude_annots_per_channel(raw_cropped, peak_g, flat, ch_type_names=channels['grads'])\n",
    "#amplit_annot_with_ch_names_grads=get_amplitude_annots_per_channel(raw_cropped, peak, flat, ch_type_names=grads)\n",
    "\n",
    "from Peaks_auto_meg_qc import get_amplitude_annots_per_channel\n",
    "df_ptp_amlitude_annot_mags, bad_channels_mags=get_amplitude_annots_per_channel(raw_cropped, peak_m, flat, channels['mags'],bad_percent, min_duration)\n",
    "df_ptp_amlitude_annot_mags.to_csv('/Users/jenya/Local Storage/Job Uni Rieger lab/MEG QC code/derivatives/sub-'+sid+'/megqc/csv files/ptp_amplitude_annots_mags.csv')\n",
    "\n",
    "df_ptp_amlitude_annot_mags, bad_channels_mags=get_amplitude_annots_per_channel(raw_cropped, peak_m, flat, channels['grads'],bad_percent, min_duration)\n",
    "df_ptp_amlitude_annot_mags.to_csv('/Users/jenya/Local Storage/Job Uni Rieger lab/MEG QC code/derivatives/sub-'+sid+'/megqc/csv files/ptp_amplitude_annots_grads.csv')\n",
    "\n",
    "df_ptp_amlitude_annot_mags\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Annotate breaks - doesnt work..\n",
    "\n",
    "break_annots = mne.preprocessing.annotate_break(\n",
    "    raw=raw_cropped,\n",
    "    min_break_duration=5,  # consider segments of at least 5 s duration\n",
    "    t_start_after_previous=2,  # start annotation 2 s after end of previous one\n",
    "    t_stop_before_next=2  # stop annotation 2 s before beginning of next one\n",
    ")\n",
    "\n",
    "\n",
    "raw_cropped.set_annotations(raw_cropped.annotations + break_annots)  # add to existing\n",
    "raw_cropped.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Annotate movement - like in tutorial 2 from:\n",
    "# https://mne.tools/stable/generated/mne.preprocessing.annotate_movement.html\n",
    "\n",
    "from mne.preprocessing import annotate_movement, compute_average_dev_head_t\n",
    "\n",
    "# Get cHPI time series and compute average\n",
    "chpi_locs = mne.chpi.extract_chpi_locs_ctf(raw)\n",
    "head_pos = mne.chpi.compute_head_pos(raw.info, chpi_locs)\n",
    "original_head_dev_t = mne.transforms.invert_transform(\n",
    "    raw.info['dev_head_t'])\n",
    "average_head_dev_t = mne.transforms.invert_transform(\n",
    "    compute_average_dev_head_t(raw, head_pos))\n",
    "fig = mne.viz.plot_head_positions(head_pos)\n",
    "for ax, val, val_ori in zip(fig.axes[::2], average_head_dev_t['trans'][:3, 3],\n",
    "                            original_head_dev_t['trans'][:3, 3]):\n",
    "    ax.axhline(1000 * val, color='r')\n",
    "    ax.axhline(1000 * val_ori, color='g')\n",
    "\n",
    "# The green horizontal lines represent the original head position, whereas the\n",
    "# red lines are the new head position averaged over all the time points.\n",
    "\n",
    "mean_distance_limit = 0.0015  # in meters\n",
    "annotation_movement, hpi_disp = annotate_movement(\n",
    "    raw, head_pos, mean_distance_limit=mean_distance_limit)\n",
    "raw.set_annotations(annotation_movement)\n",
    "raw.plot(n_channels=100, duration=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Since we got an error, try another tutorial: \n",
    "# (takes some minutes depends how big is raw_cropped: 2-40 min):\n",
    "# https://mne.tools/stable/auto_tutorials/preprocessing/59_head_positions.html#sphx-glr-auto-tutorials-preprocessing-59-head-positions-py\n",
    "\n",
    "# cHPI - continuous head position indicator (HPI) coil channels, data in teslas\n",
    "\n",
    "# 'We can use mne.chpi.get_chpi_info to retrieve the coil frequencies, the index of \n",
    "# the channel indicating when which coil was switched on, and the respective “event codes” \n",
    "# associated with each coil’s activity.'\n",
    "chpi_freqs, ch_idx, chpi_codes = mne.chpi.get_chpi_info(info=raw_cropped.info, on_missing='warn', verbose=None)\n",
    "# Output:\n",
    "# - The frequency used for each individual cHPI coil.\n",
    "# - The index of the STIM channel containing information about when which cHPI coils were switched on.\n",
    "# - The values coding for the “on” state of each individual cHPI coil.\n",
    "\n",
    "# The values coding for the “on” state of each individual cHPI coil.\n",
    "print(f'cHPI coil frequencies extracted from raw: {chpi_freqs} Hz')\n",
    "\n",
    "#We only got 5, not 9 HPI (see error in cell above)\n",
    "\n",
    "\n",
    "#extract the HPI coil amplitudes as a function of time:\n",
    "print('Extract the HPI coil amplitudes as a function of time:')\n",
    "chpi_amplitudes=mne.chpi.compute_chpi_amplitudes(raw_cropped)\n",
    "#chpi_amplitudes=mne.chpi.compute_chpi_amplitudes(raw_cropped, t_step_min=0.01, t_window='auto', ext_order=1, tmin=0, tmax=None, verbose=None)\n",
    "\n",
    "\n",
    "#compute time-varying HPI coil locations from these\n",
    "print('Compute time-varying HPI coil locations from these')\n",
    "#chpi_locs=mne.chpi.compute_chpi_locs(raw_cropped.info, chpi_amplitudes, t_step_max=1.0, too_close='raise', adjust_dig=False, verbose=None)\n",
    "chpi_locs=mne.chpi.compute_chpi_locs(raw_cropped.info, chpi_amplitudes)\n",
    "\n",
    "\n",
    "print('Compute head positions from the coil locations:')\n",
    "#compute head positions from the coil locations:\n",
    "head_pos = mne.chpi.compute_head_pos(raw_cropped.info, chpi_locs, verbose=True)\n",
    "print('head_positions computed:', head_pos)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualizing continuous head position: doesnt work\n",
    "\n",
    "mne.viz.plot_head_positions(head_pos, mode='traces')\n",
    "#mne.viz.plot_head_positions(head_pos, mode='field')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now again try to annotate movement: also error - It didnt calculate any positions!\n",
    "\n",
    "mean_distance_limit = 0.0015  # in meters\n",
    "annotation_movement, hpi_disp = annotate_movement(\n",
    "    raw_cropped, head_pos, mean_distance_limit=mean_distance_limit)\n",
    "raw_cropped.set_annotations(raw_cropped.annotations + annotation_movement)\n",
    "raw_cropped.plot(n_channels=100, duration=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://pyprep.readthedocs.io/en/latest/generated/pyprep.NoisyChannels.html#pyprep.NoisyChannels\n",
    "\n",
    "# This class implements all of the noisy channel detection methods used in the PREP pipeline, as described in:\n",
    "# Bigdely-Shamlo, N., Mullen, T., Kothe, C., Su, K. M., Robbins, K. A. (2015). The PREP pipeline: \n",
    "# standardized preprocessing for large-scale EEG analysis. Frontiers in Neuroinformatics, 9, 16.\n",
    "\n",
    "noisy = pp.NoisyChannels(raw) #first, add raw to class, then all the noisy channels finding performed on this new object.\n",
    "\n",
    "# Doesnt work. Only EEG is supported. Tried to change channel type in just to try in:\n",
    "# opt/anaconda3/envs/mne_new/lib/python3.9/site-packages/pyprep/find_noisy_channels.py\n",
    "# to self.raw_mne.pick_types(meg=True, verbose=True)\n",
    "# no luck, it gives traceback on this line. \n",
    "# (If u explicitely call raw.pick_types(meg=True, verbose=True) - everything works fine - see cell above).\n",
    "\n",
    "# Dont know where the issue is exactly, but in the end we ll need to rewrite this whole function \n",
    "# to work with MEG if we really need it.\n",
    "\n",
    "from time import perf_counter\n",
    "\n",
    "start_time = perf_counter()\n",
    "#noisy.find_bad_by_ransac(channel_wise=True)\n",
    "noisy.find_all_bads(ransac=True, channel_wise=False, max_chunk_size=None)\n",
    "print(\"--- %s seconds ---\" % (perf_counter() - start_time))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('mne_new')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13 | packaged by conda-forge | (main, May 27 2022, 17:00:52) \n[Clang 13.0.1 ]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d401ab1bf6dd7bb97662b0feb1321a641d60d04842bfa92b47f7871360972b5d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
