{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% TRY TO SAVE DERIVATIVE FROM BIDS DATASET HERE:\n",
    "from main_meg_qc import make_derivative_meg_qc\n",
    "config_file_name = 'settings.ini'\n",
    "raw = make_derivative_meg_qc(config_file_name)\n",
    "raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "import mne\n",
    "from mne.time_frequency import tfr_morlet, psd_multitaper, psd_welch\n",
    "import configparser\n",
    "import ancpbids\n",
    "import plotly\n",
    "import mpld3\n",
    "\n",
    "from main_meg_qc import make_derivative_meg_qc\n",
    "from initial_meg_qc import get_all_config_params, sanity_check, initial_processing\n",
    "from RMSE_meq_qc import RMSE_meg_qc\n",
    "from PSD_meg_qc import PSD_meg_qc\n",
    "from Peaks_manual_meg_qc import PP_manual_meg_qc\n",
    "from Peaks_auto_meg_qc import PP_auto_meg_qc\n",
    "from ECG_meg_qc import ECG_meg_qc\n",
    "from EOG_meg_qc import EOG_meg_qc\n",
    "from universal_html_report import keep_fig_derivs, make_joined_report\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from main_meg_qc import get_all_config_params, initial_processing\n",
    "all_qc_params=get_all_config_params('settings.ini')\n",
    "#print(all_qc_params)\n",
    "\n",
    "#data_file = '/Volumes/M2_DATA/MEG_QC_stuff/data/from openneuro/ds003483/sub-009/ses-1/meg/sub-009_ses-1_task-deduction_run-1_meg.fif' #GOOD ECG CHANNEL\n",
    "#data_file = '/Volumes/M2_DATA/MEG_QC_stuff/data/from lab/mikado/sub_HT05ND16/210811/mikado-1.fif' #NO ECG CHANNEL, GOOD RECONSTRUCT\n",
    "\n",
    "\n",
    "#data_file='/Volumes/M2_DATA/MEG_QC_stuff/data/from lab/forrest_gump_meg/en04ns31_vp15/190524/vp15_block1-1.fif'  #BAD ECG CHANNEL, 2 good eog.\n",
    "\n",
    "#data_file = '/Volumes/M2_DATA/MEG_QC_stuff/data/from openneuro/ds004229/sub-102/meg/sub-102_task-amnoise_meg.fif' #2EOG channels, both bad\n",
    "\n",
    "#data_file = '/Volumes/M2_DATA/MEG_QC_stuff/data/from openneuro/ds003703/sub-a68d5xp5/meg/sub-a68d5xp5_task-listeningToSpeech_run-01_meg.fif'\n",
    "#2EOG channels, both bad\n",
    "\n",
    "data_file = '/Volumes/M2_DATA/MEG_QC_stuff/data/from openneuro/ds004107/sub-mind002/ses-01/meg/sub-mind002_ses-01_task-auditory_meg.fif'\n",
    "#normal psd\n",
    "\n",
    "\n",
    "#data_file = '/Volumes/M2_DATA/MEG_QC_stuff/data/from openneuro/ds004107/sub-mind002/ses-01/meg/sub-mind002_ses-01_task-auditory_meg.fif'\n",
    "#EOG 061 bad (or rather unusual), EOG 062 good. Mne takes only the good channel and calculates events on base of it -  \n",
    "# my average and other plots are only on base of 1 goodchannel automatically\n",
    "\n",
    "#data_file = '/Volumes/M2_DATA/MEG_QC_stuff/data/from openneuro/ds003682/sub-003/ses-01/meg/sub-003_ses-01_task-AversiveLearningReplay_run-01_meg.fif'\n",
    "\n",
    "#dict_of_dfs_epoch, dict_epochs_mg, channels, raw_bandpass, raw_filtered_resampled, raw_cropped, raw, active_shielding_used = initial_processing(default_settings=all_qc_params['default'], filtering_settings=all_qc_params['Filtering'], epoching_params=all_qc_params['Epoching'], data_file=data_file)\n",
    "\n",
    "raw = mne.io.read_raw_fif(data_file, allow_maxshield=True)\n",
    "raw_cropped = raw.copy()\n",
    "tmin_my_plot=200\n",
    "tmax_my_plot=300\n",
    "duration_my_plot=tmax_my_plot-tmin_my_plot\n",
    "raw_cropped.crop(tmin=tmin_my_plot, tmax=tmax_my_plot)\n",
    "\n",
    "#raw_cropped.drop_channels(ECG_channel_name)\n",
    "\n",
    "raw_cropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_min=0.5\n",
    "freq_max=100\n",
    "n_fft = 2500\n",
    "n_per_seg = 2500\n",
    "\n",
    "psds, freqs = raw.compute_psd(method='welch', fmin=freq_min, fmax=freq_max, picks='mag', n_jobs=-1, n_fft=n_fft, n_per_seg=n_per_seg).get_data(return_freqs=True)\n",
    "\n",
    "from PSD_meg_qc import Plot_periodogram\n",
    "\n",
    "mag_ch_names = raw.copy().pick_types(meg='mag').ch_names if 'mag' in raw else None\n",
    "grad_ch_names = raw.copy().pick_types(meg='grad').ch_names if 'grad' in raw else None\n",
    "channels = {'mag': mag_ch_names, 'grad': grad_ch_names}\n",
    "\n",
    "der=Plot_periodogram('mag', freqs, psds, channels['mag'])\n",
    "der.content.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Average psd:\n",
    "\n",
    "avg_psd=np.mean(psds,axis=0)\n",
    "\n",
    "thresh=(max(avg_psd) - min(avg_psd)) / 20\n",
    "pos_peak_locs, pos_peak_magnitudes = mne.preprocessing.peak_finder(avg_psd, extrema=1, thresh=thresh, verbose=False) \n",
    "\n",
    "pos_peak_locs, pos_peak_magnitudes=pos_peak_locs[1:], pos_peak_magnitudes[1:]\n",
    "# remove the first one, because it is not actually a peak, but a start of psd curve.\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=freqs, y=avg_psd, name='Average PSD'))\n",
    "fig.add_trace(go.Scatter(x=freqs[pos_peak_locs], y=pos_peak_magnitudes, mode='markers', name='peaks'))\n",
    "fig.show()\n",
    "\n",
    "print(len(avg_psd))\n",
    "freqs\n",
    "\n",
    "print(pos_peak_magnitudes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2500: [5.08812970e-27 5.77794458e-27 5.19501531e-27 2.47311358e-27]\n",
    "# 1000: [4.59409698e-27 3.47110933e-27 1.03527341e-27]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import chirp, find_peaks, peak_widths\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x=avg_psd.copy()\n",
    "prominence=(max(avg_psd) - min(avg_psd)) / 10\n",
    "peaks, _ = find_peaks(x, prominence=prominence)\n",
    "\n",
    "results_full = peak_widths(x, peaks, rel_height=1)\n",
    "\n",
    "\n",
    "plt.plot(x)\n",
    "plt.plot(peaks, x[peaks], \"x\")\n",
    "\n",
    "plt.hlines(*results_full[1:], color=\"C3\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "prominence=(max(avg_psd) - min(avg_psd)) / 10\n",
    "peaks, _ = find_peaks(avg_psd, prominence=prominence)\n",
    "\n",
    "widths, width_heights, left_ips, right_ips = peak_widths(avg_psd, peaks, rel_height=1)\n",
    "\n",
    "#Plot signal, peaks and contour lines at which the widths where calculated\n",
    "from PSD_meg_qc import Power_of_band\n",
    "\n",
    "print('Central Freqs: ', freqs[peaks])\n",
    "print('Central Amplitudes: ', avg_psd[peaks])\n",
    "print('width_heights: ', width_heights)\n",
    "\n",
    "ips_pair=[]\n",
    "ips_l=[]\n",
    "ips_r=[]\n",
    "avg_psd_cut=avg_psd.copy()\n",
    "avg_psd_only_peaks=avg_psd.copy()\n",
    "avg_psd_only_peaks[:]=None\n",
    "avg_psd_only_peaks_baselined=avg_psd.copy()\n",
    "avg_psd_only_peaks_baselined[:]=0\n",
    "all_noisy_psds=[]\n",
    "\n",
    "for ip_n, _ in enumerate(left_ips):\n",
    "    ips_pair.append([freqs[int(left_ips[ip_n])], freqs[int(right_ips[ip_n]+1)]]) \n",
    "    #+1 here because Iwilluse these values as range,and range in pythonis usually \"up to the value but not including\", this should fix it to the right range\n",
    "    ips_l.append(freqs[int(left_ips[ip_n])])\n",
    "    ips_r.append(freqs[int(right_ips[ip_n]+1)])\n",
    "    avg_psd_cut[int(left_ips[ip_n]):int(right_ips[ip_n])+1]=None\n",
    "    avg_psd_only_peaks[int(left_ips[ip_n]):int(right_ips[ip_n])+1]=avg_psd[int(left_ips[ip_n]):int(right_ips[ip_n])+1].copy()\n",
    "    print([width_heights[ip_n]]*len(avg_psd_only_peaks[int(left_ips[ip_n]):int(right_ips[ip_n])+1]))\n",
    "    avg_psd_only_peaks_baselined[int(left_ips[ip_n]):int(right_ips[ip_n])+1]=avg_psd_only_peaks[int(left_ips[ip_n]):int(right_ips[ip_n])+1]-[width_heights[ip_n]]*len(avg_psd_only_peaks[int(left_ips[ip_n]):int(right_ips[ip_n])+1])\n",
    "\n",
    "\n",
    "avg_psd_only_peaks_baselined_new=np.array([avg_psd_only_peaks_baselined]) \n",
    "\n",
    "all_bandpower_per_ch_list=[]\n",
    "all_rel_bandpower_per_ch_list=[]\n",
    "for ip_n, _ in enumerate(left_ips):\n",
    "\n",
    "    print('HERE!')\n",
    "    print(avg_psd_only_peaks_baselined_new)\n",
    "    bandpower_per_ch_list, power_by_Nfreq_per_ch_list, rel_bandpower_per_ch_list = Power_of_band(freqs=freqs, f_low = freqs[int(left_ips[ip_n])], f_high= freqs[int(right_ips[ip_n]+1)], psds=avg_psd_only_peaks_baselined_new)\n",
    "\n",
    "    all_bandpower_per_ch_list.append(bandpower_per_ch_list)\n",
    "    all_rel_bandpower_per_ch_list.append(rel_bandpower_per_ch_list)\n",
    "\n",
    "\n",
    "print('Freq band for each peak:', ips_pair)\n",
    "print('BP', all_bandpower_per_ch_list)\n",
    "print('relative BP', all_rel_bandpower_per_ch_list)\n",
    "\n",
    "plt.plot(freqs,avg_psd)\n",
    "plt.plot(freqs[peaks], avg_psd[peaks], 'x')\n",
    "plt.hlines(y=width_heights, xmin=ips_l, xmax=ips_r, color=\"C3\")\n",
    "plt.show()\n",
    "\n",
    "plt.plot(freqs,avg_psd_cut)\n",
    "plt.plot(freqs[peaks], avg_psd_cut[peaks], \"x\")\n",
    "plt.hlines(y=width_heights, xmin=ips_l, xmax=ips_r, color=\"C3\")\n",
    "plt.show()\n",
    "\n",
    "plt.plot(freqs,avg_psd_only_peaks)\n",
    "plt.plot(freqs[peaks], avg_psd_only_peaks[peaks], \"x\")\n",
    "plt.hlines(y=width_heights, xmin=ips_l, xmax=ips_r, color=\"C3\")\n",
    "plt.show()\n",
    "\n",
    "plt.plot(freqs,avg_psd_only_peaks_baselined)\n",
    "plt.plot(freqs[peaks], avg_psd_only_peaks_baselined[peaks], \"x\")\n",
    "plt.show()\n",
    "\n",
    "#NOW need power of freq. for each band in baselined\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PSD_meg_qc import Power_of_band\n",
    "\n",
    "bandpower_per_ch_list, power_by_Nfreq_per_ch_list, rel_bandpower_per_ch_list = Power_of_band(freqs=freqs, f_low = 57.5, f_high= 62.5, psds=avg_psd_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit polynomial models up to degree 5\n",
    "model1 = np.poly1d(np.polyfit(freqs, avg_psd, 1))\n",
    "model2 = np.poly1d(np.polyfit(freqs, avg_psd, 2))\n",
    "model3 = np.poly1d(np.polyfit(freqs, avg_psd, 3))\n",
    "model4 = np.poly1d(np.polyfit(freqs, avg_psd, 4))\n",
    "model5 = np.poly1d(np.polyfit(freqs, avg_psd, 5))\n",
    "\n",
    "fig.add_trace(go.Scatter(x=freqs, y=model1(freqs), name='model1')) \n",
    "fig.add_trace(go.Scatter(x=freqs, y=model2(freqs), name='model2')) \n",
    "fig.add_trace(go.Scatter(x=freqs, y=model3(freqs), name='model3')) \n",
    "fig.add_trace(go.Scatter(x=freqs, y=model4(freqs), name='model4')) \n",
    "fig.add_trace(go.Scatter(x=freqs, y=model5(freqs), name='model5')) \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smooth(x,window_len=11,window='hanning'):\n",
    "    \"\"\"smooth the data using a window with requested size.\n",
    "    \n",
    "    This method is based on the convolution of a scaled window with the signal.\n",
    "    The signal is prepared by introducing reflected copies of the signal \n",
    "    (with the window size) in both ends so that transient parts are minimized\n",
    "    in the begining and end part of the output signal.\n",
    "    \n",
    "    input:\n",
    "        x: the input signal \n",
    "        window_len: the dimension of the smoothing window; should be an odd integer\n",
    "        window: the type of window from 'flat', 'hanning', 'hamming', 'bartlett', 'blackman'\n",
    "            flat window will produce a moving average smoothing.\n",
    "\n",
    "    output:\n",
    "        the smoothed signal\n",
    "        \n",
    "    example:\n",
    "\n",
    "    t=linspace(-2,2,0.1)\n",
    "    x=sin(t)+randn(len(t))*0.1\n",
    "    y=smooth(x)\n",
    "    \n",
    "    see also: \n",
    "    \n",
    "    numpy.hanning, numpy.hamming, numpy.bartlett, numpy.blackman, numpy.convolve\n",
    "    scipy.signal.lfilter\n",
    " \n",
    "    TODO: the window parameter could be the window itself if an array instead of a string\n",
    "    NOTE: length(output) != length(input), to correct this: return y[(window_len/2-1):-(window_len/2)] instead of just y.\n",
    "    \"\"\"\n",
    "\n",
    "    # if x.ndim != 1:\n",
    "    #     raise ValueError, \"smooth only accepts 1 dimension arrays.\"\n",
    "\n",
    "    # if x.size < window_len:\n",
    "    #     raise ValueError, \"Input vector needs to be bigger than window size.\"\n",
    "\n",
    "\n",
    "    # if window_len<3:\n",
    "    #     return x\n",
    "\n",
    "\n",
    "    # if not window in ['flat', 'hanning', 'hamming', 'bartlett', 'blackman']:\n",
    "    #     raise ValueError, \"Window is on of 'flat', 'hanning', 'hamming', 'bartlett', 'blackman'\"\n",
    "\n",
    "\n",
    "    s=np.r_[x[window_len-1:0:-1],x,x[-2:-window_len-1:-1]]\n",
    "    #print(len(s))\n",
    "    if window == 'flat': #moving average\n",
    "        w=np.ones(window_len,'d')\n",
    "    else:\n",
    "        w=eval('np.'+window+'(window_len)')\n",
    "\n",
    "    y=np.convolve(w/w.sum(),s,mode='valid')\n",
    "    return y\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_psd_smooth=smooth(avg_psd,window_len=11,window='hanning')\n",
    "fig.add_trace(go.Scatter(x=freqs, y=avg_psd_smooth, name='smooth')) \n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import pandas as pd\n",
    "\n",
    "# logging.basicConfig(datefmt='%H:%M:%S',\n",
    "#                     stream=sys.stdout, level=logging.DEBUG,\n",
    "#                     format='%(asctime)s %(message)s')\n",
    "\n",
    "# Distance away from the FBEWMA that data should be removed.\n",
    "DELTA = 0.1\n",
    "\n",
    "# clip data above this value:\n",
    "high_clip = 2.1\n",
    "\n",
    "# clip data below this value:\n",
    "LOW_CLIP = -2.1\n",
    "\n",
    "# random values above this trigger a spike:\n",
    "RAND_HIGH = 0.98\n",
    "\n",
    "# random values below this trigger a negative spike:\n",
    "RAND_LOW = 0.02\n",
    "\n",
    "# How many samples to run the FBEWMA over.\n",
    "SPAN = 10\n",
    "\n",
    "# spike amplitude\n",
    "SPIKE = 2\n",
    "\n",
    "\n",
    "def clip_data(unclipped, high_clip, low_clip):\n",
    "    ''' Clip unclipped between high_clip and low_clip. \n",
    "    unclipped contains a single column of unclipped data.'''\n",
    "    \n",
    "    # convert to np.array to access the np.where method\n",
    "    np_unclipped = np.array(unclipped)\n",
    "    # clip data above HIGH_CLIP or below LOW_CLIP\n",
    "    cond_high_clip = (np_unclipped > high_clip) | (np_unclipped < low_clip)\n",
    "    np_clipped = np.where(cond_high_clip, np.nan, np_unclipped)\n",
    "    return np_clipped.tolist()\n",
    "\n",
    "\n",
    "def create_sample_data():\n",
    "    ''' Create sine wave, amplitude +/-2 with random spikes. '''\n",
    "    x = np.linspace(0, 2*np.pi, 1000)\n",
    "    y = 2 * np.sin(x)\n",
    "    df = pd.DataFrame(list(zip(x,y)), columns=['x', 'y'])\n",
    "    df['rand'] = np.random.random_sample(len(x),)\n",
    "    # create random positive and negative spikes\n",
    "    cond_spike_high = (df['rand'] > RAND_HIGH)\n",
    "    df['spike_high'] = np.where(cond_spike_high, SPIKE, 0)\n",
    "    cond_spike_low = (df['rand'] < RAND_LOW)\n",
    "    df['spike_low'] = np.where(cond_spike_low, -SPIKE, 0)\n",
    "    df['y_spikey'] = df['y'] + df['spike_high'] + df['spike_low']\n",
    "    return df\n",
    "\n",
    "\n",
    "def ewma_fb(df_column, span):\n",
    "    ''' Apply forwards, backwards exponential weighted moving average (EWMA) to df_column. '''\n",
    "    # Forwards EWMA.\n",
    "    fwd = pd.Series.ewm(df_column, span=span).mean()\n",
    "    # Backwards EWMA.\n",
    "    bwd = pd.Series.ewm(df_column[::-1],span=10).mean()\n",
    "    # Add and take the mean of the forwards and backwards EWMA.\n",
    "    stacked_ewma = np.vstack(( fwd, bwd[::-1] ))\n",
    "    fb_ewma = np.mean(stacked_ewma, axis=0)\n",
    "    return fb_ewma\n",
    "    \n",
    "    \n",
    "def remove_outliers(spikey, fbewma, delta):\n",
    "    ''' Remove data from df_spikey that is > delta from fbewma. '''\n",
    "    np_spikey = np.array(spikey)\n",
    "    np_fbewma = np.array(fbewma)\n",
    "    cond_delta = (np.abs(np_spikey-np_fbewma) > delta)\n",
    "    np_remove_outliers = np.where(cond_delta, np.nan, np_spikey)\n",
    "    return np_remove_outliers\n",
    "\n",
    "    \n",
    "def main(avg_psd, freqs):\n",
    "    #df = create_sample_data()\n",
    "    df = pd.DataFrame(list(zip(freqs,avg_psd)), columns=['x', 'y'])\n",
    "    df['y_spikey']=avg_psd\n",
    "\n",
    "    df['y_clipped'] = clip_data(df['y_spikey'].tolist(), HIGH_CLIP, LOW_CLIP)\n",
    "    df['y_ewma_fb'] = ewma_fb(df['y_clipped'], SPAN)\n",
    "    df['y_remove_outliers'] = remove_outliers(df['y_clipped'].tolist(), df['y_ewma_fb'].tolist(), DELTA)\n",
    "    df['y_interpolated'] = df['y_remove_outliers'].interpolate()\n",
    "    \n",
    "    ax = df.plot(x='x', y='y_spikey', color='blue', alpha=0.5)\n",
    "    ax2 = df.plot(x='x', y='y_interpolated', color='black', ax=ax)\n",
    "\n",
    "    return df\n",
    "    \n",
    "df=main(avg_psd, freqs)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "logging.basicConfig(datefmt='%H:%M:%S',\n",
    "                    stream=sys.stdout, level=logging.DEBUG,\n",
    "                    format='%(asctime)s %(message)s')\n",
    "\n",
    "# Distance away from the FBEWMA that data should be removed.\n",
    "DELTA = 0.1\n",
    "\n",
    "# clip data above this value:\n",
    "HIGH_CLIP = 2.1\n",
    "\n",
    "# clip data below this value:\n",
    "LOW_CLIP = -2.1\n",
    "\n",
    "# random values above this trigger a spike:\n",
    "RAND_HIGH = 0.98\n",
    "\n",
    "# random values below this trigger a negative spike:\n",
    "RAND_LOW = 0.02\n",
    "\n",
    "# How many samples to run the FBEWMA over.\n",
    "SPAN = 10\n",
    "\n",
    "# spike amplitude\n",
    "SPIKE = 2\n",
    "\n",
    "\n",
    "def clip_data(unclipped, high_clip, low_clip):\n",
    "    ''' Clip unclipped between high_clip and low_clip. \n",
    "    unclipped contains a single column of unclipped data.'''\n",
    "    \n",
    "    # convert to np.array to access the np.where method\n",
    "    np_unclipped = np.array(unclipped)\n",
    "    # clip data above HIGH_CLIP or below LOW_CLIP\n",
    "    cond_high_clip = (np_unclipped > HIGH_CLIP) | (np_unclipped < LOW_CLIP)\n",
    "    np_clipped = np.where(cond_high_clip, np.nan, np_unclipped)\n",
    "    return np_clipped.tolist()\n",
    "\n",
    "\n",
    "def create_sample_data():\n",
    "    ''' Create sine wave, amplitude +/-2 with random spikes. '''\n",
    "    x = np.linspace(0, 2*np.pi, 1000)\n",
    "    y = 2 * np.sin(x)\n",
    "    df = pd.DataFrame(list(zip(x,y)), columns=['x', 'y'])\n",
    "    df['rand'] = np.random.random_sample(len(x),)\n",
    "    # create random positive and negative spikes\n",
    "    cond_spike_high = (df['rand'] > RAND_HIGH)\n",
    "    df['spike_high'] = np.where(cond_spike_high, SPIKE, 0)\n",
    "    cond_spike_low = (df['rand'] < RAND_LOW)\n",
    "    df['spike_low'] = np.where(cond_spike_low, -SPIKE, 0)\n",
    "    df['y_spikey'] = df['y'] + df['spike_high'] + df['spike_low']\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def ewma_fb(df_column, span):\n",
    "    ''' Apply forwards, backwards exponential weighted moving average (EWMA) to df_column. '''\n",
    "    # Forwards EWMA.\n",
    "    fwd = pd.Series.ewm(df_column, span=span).mean()\n",
    "    # Backwards EWMA.\n",
    "    bwd = pd.Series.ewm(df_column[::-1],span=10).mean()\n",
    "    # Add and take the mean of the forwards and backwards EWMA.\n",
    "    stacked_ewma = np.vstack(( fwd, bwd[::-1] ))\n",
    "    fb_ewma = np.mean(stacked_ewma, axis=0)\n",
    "    return fb_ewma\n",
    "    \n",
    "    \n",
    "def remove_outliers(spikey, fbewma, delta):\n",
    "    ''' Remove data from df_spikey that is > delta from fbewma. '''\n",
    "    np_spikey = np.array(spikey)\n",
    "    np_fbewma = np.array(fbewma)\n",
    "    cond_delta = (np.abs(np_spikey-np_fbewma) > delta)\n",
    "    np_remove_outliers = np.where(cond_delta, np.nan, np_spikey)\n",
    "    return np_remove_outliers\n",
    "\n",
    "    \n",
    "def main():\n",
    "    df = create_sample_data()\n",
    "\n",
    "    df['y_clipped'] = clip_data(df['y_spikey'].tolist(), HIGH_CLIP, LOW_CLIP)\n",
    "    df['y_ewma_fb'] = ewma_fb(df['y_clipped'], SPAN)\n",
    "    df['y_remove_outliers'] = remove_outliers(df['y_clipped'].tolist(), df['y_ewma_fb'].tolist(), DELTA)\n",
    "    df['y_interpolated'] = df['y_remove_outliers'].interpolate()\n",
    "    \n",
    "    ax = df.plot(x='x', y='y_spikey', color='blue', alpha=0.5)\n",
    "    ax2 = df.plot(x='x', y='y_interpolated', color='black', ax=ax)\n",
    "\n",
    "    return df\n",
    "    \n",
    "df= main()\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PSD_meg_qc import Power_of_band\n",
    "avg_psd_new=np.array([avg_psd])\n",
    "bandpower_per_ch_list, power_by_Nfreq_per_ch_list, rel_bandpower_per_ch_list = Power_of_band(freqs=freqs, f_low = 57.5, f_high= 62.5, psds=avg_psd_new)\n",
    "\n",
    "bandpower_per_ch_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot EOG channel\n",
    "\n",
    "raw.copy().pick_types(meg=False, stim=False,eog=True).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ECG_meg_qc import find_affected_channels\n",
    "\n",
    "mag_ch_names = raw.copy().pick_types(meg='mag').ch_names if 'mag' in raw else None\n",
    "grad_ch_names = raw.copy().pick_types(meg='grad').ch_names if 'grad' in raw else None\n",
    "channels = {'mag': mag_ch_names, 'grad': grad_ch_names}\n",
    "sfreq=raw.info['sfreq']\n",
    "m_or_g='mag'\n",
    "tmin=-0.2\n",
    "tmax=0.2\n",
    "#ecg_epochs = mne.preprocessing.create_ecg_epochs(raw, picks=channels[m_or_g], tmin=tmin, tmax=tmax)\n",
    "\n",
    "#ch_name='EOG 061'\n",
    "ch_name='EOG002'\n",
    "eog_epochs = mne.preprocessing.create_eog_epochs(raw, picks=channels[m_or_g], ch_name=ch_name, tmin=tmin, tmax=tmax)\n",
    "\n",
    "\n",
    "ecg_affected_channels, fig_affected, fig_not_affected, fig_avg=find_affected_channels(eog_epochs, channels, m_or_g, norm_lvl=1, ecg_or_eog='EOG', thresh_lvl_peakfinder=5, sfreq=sfreq, tmin=tmin, tmax=tmax, plotflag=True,  use_abs_of_all_data='flip')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ch_name='EOG003'\n",
    "eog_epochs = mne.preprocessing.create_eog_epochs(raw, picks=channels[m_or_g], ch_name=ch_name, tmin=tmin, tmax=tmax)\n",
    "\n",
    "\n",
    "ecg_affected_channels, fig_affected, fig_not_affected, fig_avg=find_affected_channels(eog_epochs, channels, m_or_g, norm_lvl=1, ecg_or_eog='EOG', thresh_lvl_peakfinder=5, sfreq=sfreq, tmin=tmin, tmax=tmax, plotflag=True,  use_abs_of_all_data='flip')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "eog_epochs = mne.preprocessing.create_eog_epochs(raw, picks=channels[m_or_g], tmin=tmin, tmax=tmax)\n",
    "\n",
    "\n",
    "ecg_affected_channels, fig_affected, fig_not_affected, fig_avg=find_affected_channels(eog_epochs, channels, m_or_g, norm_lvl=1, ecg_or_eog='EOG', thresh_lvl_peakfinder=5, sfreq=sfreq, tmin=tmin, tmax=tmax, plotflag=True,  use_abs_of_all_data='flip')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecg_affected_channels, fig_affected, fig_not_affected, fig_avg=find_affected_channels(ecg_epochs, channels, m_or_g, norm_lvl=1, ecg_or_eog='ecg', thresh_lvl_peakfinder=5, sfreq=sfreq, tmin=tmin, tmax=tmax, plotflag=True, use_abs_of_all_data='False')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecg_affected_channels, fig_affected, fig_not_affected, fig_avg=find_affected_channels(ecg_epochs, channels, m_or_g, norm_lvl=1, ecg_or_eog='ecg', thresh_lvl_peakfinder=5, sfreq=sfreq, tmin=tmin, tmax=tmax, plotflag=True, use_abs_of_all_data='flip')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = '/Volumes/M2_DATA/MEG_QC_stuff/data/from openneuro/ds003682/sub-001/ses-01/meg/sub-001_ses-01_task-AversiveLearningReplay_run-01_meg.fif'\n",
    "raw = mne.io.read_raw_fif(data_file)\n",
    "raw.info['chs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import numpy as np\n",
    "import mne\n",
    "y=np.array([1,4,5,0,0,0])\n",
    "peaks_l, peaks_m = mne.preprocessing.peak_finder(y)\n",
    "\n",
    "print(peaks_l)\n",
    "print(type(peaks_l[0]))\n",
    "print(len(peaks_l))\n",
    "\n",
    "print(np.array([87]))\n",
    "print(type(np.array([87])[0]))\n",
    "#print(len(np.array(87)))\n",
    "\n",
    "\n",
    "print(np.ndarray(87))\n",
    "print(len(np.ndarray(87)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Other useful ancp stuff:\n",
    "\n",
    "config = configparser.ConfigParser()\n",
    "config.read('settings.ini')\n",
    "\n",
    "default_direct = config['DEFAULT']['data_directory']\n",
    "dataset_path = ancpbids.utils.fetch_dataset(default_direct)\n",
    "\n",
    "from ancpbids import BIDSLayout\n",
    "layout = BIDSLayout(dataset_path)\n",
    "\n",
    "list_of_fifs = layout.get(suffix='meg', extension='.fif', return_type='filename')\n",
    "\n",
    "list_of_subs = layout.get_subjects()\n",
    "\n",
    "\n",
    "list_of_entities = layout.get_entities()\n",
    "print(list_of_entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TRY SEPARATE FUNCS HERE\n",
    "\n",
    "config = configparser.ConfigParser()\n",
    "config.read('settings.ini')\n",
    "data_file = '/Volumes/M2_DATA/MEG_QC_stuff/data/from openneuro/ds003483/sub-009/ses-1/meg/sub-009_ses-1_task-deduction_run-1_meg.fif'\n",
    "all_qc_params = get_all_config_params('settings.ini')\n",
    "dict_of_dfs_epoch, dict_epochs_mg, channels, raw_filtered, raw_filtered_resampled, raw_cropped, raw, active_shielding_used = initial_processing(default_settings=all_qc_params['default'], filtering_settings=all_qc_params['Filtering'], epoching_params=all_qc_params['Epoching'], data_file=data_file)\n",
    "\n",
    "m_or_g_chosen = ['mag']\n",
    "sid='009'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "\n",
    "#dfs_ptp_amlitude_annot, bad_channels, amplit_annot_with_ch_names = PP_auto_meg_qc(sid, config, channels, raw, m_or_g_chosen)\n",
    "\n",
    "#derivs, big_rmse_with_value_all_data, small_rmse_with_value_all_data = RMSE_meg_qc(all_qc_params['RMSE'], channels, dict_epochs_mg, dict_dict_of_dfs_epoch, raw, m_or_g_chosen)\n",
    "\n",
    "derivs = PP_manual_meg_qc(all_qc_params['PTP_manual'], channels, dict_epochs_mg, dict_of_dfs_epoch, raw, m_or_g_chosen)\n",
    "\n",
    "#out_with_name_and_format = PSD_meg_qc(sid, config, channels, raw, m_or_g_chosen)\n",
    "\n",
    "derivs = ECG_meg_qc(config, raw, m_or_g_chosen)\n",
    "\n",
    "#out_with_name_and_format = EOG_meg_qc(config, raw, m_or_g_chosen)\n",
    "\n",
    "#out_with_name_and_format, bad_channels = PP_auto_meg_qc(sid, config, channels, raw, m_or_g_chosen)\n",
    "\n",
    "print(\"--- Execution %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "\n",
    "for der in derivs:\n",
    "    if der.content_type == 'plotly':\n",
    "        der.content.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# out_with_name_and_format[0].convert_fig_to_html()\n",
    "from universal_plots import QC_derivative\n",
    "dr = QC_derivative('001', 'mean_EC_epoch', None, '')\n",
    "# dr_html = dr.convert_fig_to_html()\n",
    "# l=[\"a\"]\n",
    "\n",
    "# if dr_html is not None:\n",
    "\n",
    "#     l += dr_html\n",
    "    \n",
    "# print(l)\n",
    "\n",
    "sec = dr.get_section()\n",
    "print(sec)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(figs)\n",
    "all_fig_derivs = figs\n",
    "figures_report = {}\n",
    "for x in range(0, len(all_fig_derivs)):\n",
    "    if all_fig_derivs[x][3]=='plotly':\n",
    "        figures_report[\"f{0}\".format(x)] = plotly.io.to_html(all_fig_derivs[x][0])\n",
    "    elif all_fig_derivs[x][3]=='matplotlib':\n",
    "        figures_report[\"f{0}\".format(x)] = mpld3.fig_to_html(all_fig_derivs[x][0]);\n",
    "\n",
    "print(figures_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import mpld3\n",
    "\n",
    "html_fig=mpld3.fig_to_html(figs[0][0])\n",
    "print(html_fig)\n",
    "\n",
    "\n",
    "\n",
    "# file = open('matpl_fig.html', \"w\")\n",
    "# file.write(html_fig)\n",
    "# file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_string = '''\n",
    "<!doctype html>\n",
    "<html>\n",
    "    <head>\n",
    "        <meta charset=\"UTF-8\">\n",
    "        <title>MEG QC: Frequency spectrum Report</title>\n",
    "        <style>body{ margin:0 100;}</style>\n",
    "    </head>\n",
    "    \n",
    "    <body style=\"font-family: Arial\">\n",
    "        <center>\n",
    "        <h1>MEG data quality analysis report</h1>\n",
    "        <br></br>\n",
    "        <!-- *** Section 1 *** --->\n",
    "        <h2>Frequency spectrum per channel</h2>\n",
    "        ''' + html_fig + '''\n",
    "        <p>graph description...</p>\n",
    "        </center>\n",
    "    \n",
    "    </body>\n",
    "</html>'''\n",
    "\n",
    "with open('report_trial.html', 'w', encoding = 'utf8') as f:\n",
    "    f.write(html_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#config = configparser.ConfigParser()\n",
    "#config.read('settings.ini')\n",
    "\n",
    "#data_file = '/Volumes/M2_DATA/MEG_QC_stuff/data/from openneuro/ds000117/sub-01/ses-meg/meg/sub-01_ses-meg_task-facerecognition_run-01_meg.fif'\n",
    "# file does not start with a file id tag\n",
    "\n",
    "#data_file = '/Volumes/M2_DATA/MEG_QC_stuff/data/from openneuro/ds003392/sub-01/meg/sub-01_task-localizer_meg.fif'\n",
    "# SSS frilter. need to allow maxshiled.\n",
    "\n",
    "#data_file ='/Volumes/M2_DATA/MEG_QC_stuff/data/from openneuro/ds003694/sub-01/meg/sub-01_task-MEM_run-01_meg.fif'\n",
    "#raw = mne.io.read_raw_fif(data_file, on_split_missing='ignore')\n",
    "\n",
    "\n",
    "#dict_of_dfs_epoch, dict_epochs_mg, channels, raw_bandpass, raw_filtered_resampled, raw_cropped, raw = initial_processing(config, data_file)\n",
    "\n",
    "#data_file ='/Volumes/M2_DATA/MEG_QC_stuff/data/from openneuro/ds003922/sub-Mp150285/ses-01/meg/sub-Mp150285_ses-01_acq-crosstalk_meg.fif'\n",
    "#Could not find measurement data: how many in this set, which subjects?\n",
    "\n",
    "\n",
    "data_file ='/Volumes/M2_DATA/MEG_QC_stuff/data/from openneuro/ds004229/sub-102/meg/sub-102_task-amnoise_meg.fif'\n",
    "#SSS filter\n",
    "raw = mne.io.read_raw_fif(data_file, allow_maxshield=True)\n",
    "\n",
    "\n",
    "#data_dir ='/Volumes/M2_DATA/MEG_QC_stuff/data/from openneuro/not fitting no fif/ds000246/sub-0001/meg/sub-0001_task-AEF_run-01_meg.ds'\n",
    "#raw = mne.io.read_raw_ctf(data_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import configparser\n",
    "from ancpbids import BIDSLayout\n",
    "\n",
    "config = configparser.ConfigParser()\n",
    "config.read('settings.ini')\n",
    "\n",
    "default_section = config['DEFAULT']\n",
    "\n",
    "m_or_g_chosen = default_section['do_for'] \n",
    "m_or_g_chosen = m_or_g_chosen.replace(\" \", \"\")\n",
    "m_or_g_chosen = m_or_g_chosen.split(\",\")\n",
    "#m_or_g_chosen = select_m_or_g(default_section)\n",
    "\n",
    "dataset_path = default_section['data_directory']\n",
    "\n",
    "layout = BIDSLayout(dataset_path)\n",
    "schema = layout.schema\n",
    "\n",
    "#create derivative folder first!\n",
    "derivative = layout.dataset.create_derivative(name=\"Meg_QC\")\n",
    "derivative.dataset_description.GeneratedBy.Name = \"MEG QC Pipeline\"\n",
    "\n",
    "list_of_subs = layout.get_subjects()\n",
    "#print(list_of_subs)\n",
    "for sub in list_of_subs:\n",
    "    list_of_fifs_per_sub = layout.get(suffix='meg', extension='.fif', sub=sub)\n",
    "    for_entities={}\n",
    "    for file in list_of_fifs_per_sub:\n",
    "        k=file['entities'][1]['key']\n",
    "        v=file['entities'][1]['value']\n",
    "        for_entities[k]=v\n",
    "    print(for_entities)\n",
    "\n",
    "#print(list_of_fifs_per_sub)\n",
    "# for sid in [list_of_subs[0]]: #RUN OVER JUST 1 SUBJ\n",
    "# #for sid in list_of_subs: \n",
    "\n",
    "#     subject_folder = derivative.create_folder(type_=schema.Subject, name='sub-'+sid)\n",
    "\n",
    "#     list_of_fifs = layout.get(suffix='meg', extension='.fif', return_type='filename', subj=sid)\n",
    "#     #Devide here fifs by task, ses , run\n",
    "\n",
    "#     for data_file in [list_of_fifs[0]]: #RUN OVER JUST 1 FIF because is not divided by tasks yet..\n",
    "#         print(type(data_file))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('mne_new')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d401ab1bf6dd7bb97662b0feb1321a641d60d04842bfa92b47f7871360972b5d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
