{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% TRY TO SAVE DERIVATIVE FROM BIDS DATASET HERE:\n",
    "from main_meg_qc import make_derivative_meg_qc\n",
    "config_file_name = 'settings.ini'\n",
    "raw = make_derivative_meg_qc(config_file_name)\n",
    "raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "import mne\n",
    "from mne.time_frequency import tfr_morlet, psd_multitaper, psd_welch\n",
    "import configparser\n",
    "import ancpbids\n",
    "import plotly\n",
    "import mpld3\n",
    "\n",
    "from main_meg_qc import make_derivative_meg_qc\n",
    "from initial_meg_qc import get_all_config_params, sanity_check, initial_processing\n",
    "from RMSE_meq_qc import RMSE_meg_qc\n",
    "from PSD_meg_qc import PSD_meg_qc\n",
    "from Peaks_manual_meg_qc import PP_manual_meg_qc\n",
    "from Peaks_auto_meg_qc import PP_auto_meg_qc\n",
    "from ECG_meg_qc import ECG_meg_qc\n",
    "from EOG_meg_qc import EOG_meg_qc\n",
    "from universal_html_report import keep_fig_derivs, make_joined_report\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from main_meg_qc import get_all_config_params, initial_processing\n",
    "all_qc_params=get_all_config_params('settings.ini')\n",
    "#print(all_qc_params)\n",
    "\n",
    "#data_file = '/Volumes/M2_DATA/MEG_QC_stuff/data/from openneuro/ds003483/sub-009/ses-1/meg/sub-009_ses-1_task-deduction_run-1_meg.fif' #GOOD ECG CHANNEL\n",
    "#data_file = '/Volumes/M2_DATA/MEG_QC_stuff/data/from lab/mikado/sub_HT05ND16/210811/mikado-1.fif' #NO ECG CHANNEL, GOOD RECONSTRUCT\n",
    "\n",
    "\n",
    "#data_file='/Volumes/M2_DATA/MEG_QC_stuff/data/from lab/forrest_gump_meg/en04ns31_vp15/190524/vp15_block1-1.fif'  #BAD ECG CHANNEL, 2 good eog.\n",
    "\n",
    "#data_file = '/Volumes/M2_DATA/MEG_QC_stuff/data/from openneuro/ds004229/sub-102/meg/sub-102_task-amnoise_meg.fif' #2EOG channels, both bad\n",
    "\n",
    "#data_file = '/Volumes/M2_DATA/MEG_QC_stuff/data/from openneuro/ds003703/sub-a68d5xp5/meg/sub-a68d5xp5_task-listeningToSpeech_run-01_meg.fif'\n",
    "#2EOG channels, both bad\n",
    "\n",
    "data_file = '/Volumes/M2_DATA/MEG_QC_stuff/data/from openneuro/ds004107/sub-mind002/ses-01/meg/sub-mind002_ses-01_task-auditory_meg.fif'\n",
    "#normal psd\n",
    "\n",
    "\n",
    "#data_file = '/Volumes/M2_DATA/MEG_QC_stuff/data/from openneuro/ds004107/sub-mind002/ses-01/meg/sub-mind002_ses-01_task-auditory_meg.fif'\n",
    "#EOG 061 bad (or rather unusual), EOG 062 good. Mne takes only the good channel and calculates events on base of it -  \n",
    "# my average and other plots are only on base of 1 goodchannel automatically\n",
    "\n",
    "#data_file = '/Volumes/M2_DATA/MEG_QC_stuff/data/from openneuro/ds003682/sub-003/ses-01/meg/sub-003_ses-01_task-AversiveLearningReplay_run-01_meg.fif'\n",
    "\n",
    "#dict_of_dfs_epoch, dict_epochs_mg, channels, raw_bandpass, raw_filtered_resampled, raw_cropped, raw, active_shielding_used = initial_processing(default_settings=all_qc_params['default'], filtering_settings=all_qc_params['Filtering'], epoching_params=all_qc_params['Epoching'], data_file=data_file)\n",
    "\n",
    "raw = mne.io.read_raw_fif(data_file, allow_maxshield=True)\n",
    "raw_cropped = raw.copy()\n",
    "tmin_my_plot=200\n",
    "tmax_my_plot=300\n",
    "duration_my_plot=tmax_my_plot-tmin_my_plot\n",
    "raw_cropped.crop(tmin=tmin_my_plot, tmax=tmax_my_plot)\n",
    "\n",
    "#raw_cropped.drop_channels(ECG_channel_name)\n",
    "\n",
    "raw_cropped\n",
    "raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_min=0.5\n",
    "freq_max=100\n",
    "n_fft = 2500\n",
    "n_per_seg = 2500\n",
    "\n",
    "psds, freqs = raw.compute_psd(method='welch', fmin=freq_min, fmax=freq_max, picks='mag', n_jobs=-1, n_fft=n_fft, n_per_seg=n_per_seg).get_data(return_freqs=True)\n",
    "\n",
    "from PSD_meg_qc import Plot_periodogram\n",
    "\n",
    "mag_ch_names = raw.copy().pick_types(meg='mag').ch_names if 'mag' in raw else None\n",
    "grad_ch_names = raw.copy().pick_types(meg='grad').ch_names if 'grad' in raw else None\n",
    "channels = {'mag': mag_ch_names, 'grad': grad_ch_names}\n",
    "\n",
    "der=Plot_periodogram('mag', freqs, psds, channels['mag'])\n",
    "der.content.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Average psd:\n",
    "\n",
    "avg_psd=np.mean(psds,axis=0)\n",
    "\n",
    "thresh=(max(avg_psd) - min(avg_psd)) / 20\n",
    "pos_peak_locs, pos_peak_magnitudes = mne.preprocessing.peak_finder(avg_psd, extrema=1, thresh=thresh, verbose=False) \n",
    "\n",
    "pos_peak_locs, pos_peak_magnitudes=pos_peak_locs[1:], pos_peak_magnitudes[1:]\n",
    "# remove the first one, because it is not actually a peak, but a start of psd curve.\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=freqs, y=avg_psd, name='Average PSD'))\n",
    "fig.add_trace(go.Scatter(x=freqs[pos_peak_locs], y=pos_peak_magnitudes, mode='markers', name='peaks'))\n",
    "fig.show()\n",
    "\n",
    "print(len(avg_psd))\n",
    "freqs\n",
    "\n",
    "print(pos_peak_magnitudes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2500: [5.08812970e-27 5.77794458e-27 5.19501531e-27 2.47311358e-27]\n",
    "# 1000: [4.59409698e-27 3.47110933e-27 1.03527341e-27]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import chirp, find_peaks, peak_widths\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x=avg_psd.copy()\n",
    "prominence=(max(avg_psd) - min(avg_psd)) / 20\n",
    "peaks, _ = find_peaks(x, prominence=prominence)\n",
    "\n",
    "results_full = peak_widths(x, peaks, rel_height=1)\n",
    "\n",
    "\n",
    "plt.plot(x)\n",
    "plt.plot(peaks, x[peaks], \"x\")\n",
    "\n",
    "plt.hlines(*results_full[1:], color=\"C3\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "prominence=(max(avg_psd) - min(avg_psd)) / 20\n",
    "peaks, _ = find_peaks(avg_psd, prominence=prominence)\n",
    "\n",
    "widths, width_heights, left_ips, right_ips = peak_widths(avg_psd, peaks, rel_height=1)\n",
    "\n",
    "#Plot signal, peaks and contour lines at which the widths where calculated\n",
    "from PSD_meg_qc import Power_of_band\n",
    "from universal_plots import plot_pie_chart_freq\n",
    "from scipy.integrate import simps\n",
    "\n",
    "print('Central Freqs: ', freqs[peaks])\n",
    "print('Central Amplitudes: ', avg_psd[peaks])\n",
    "print('width_heights: ', width_heights)\n",
    "\n",
    "#ips_pair=[]\n",
    "ips_l=[]\n",
    "ips_r=[]\n",
    "avg_psd_only_signal=avg_psd.copy()\n",
    "avg_psd_only_peaks=avg_psd.copy()\n",
    "avg_psd_only_peaks[:]=None\n",
    "avg_psd_only_peaks_baselined=avg_psd.copy()\n",
    "avg_psd_only_peaks_baselined[:]=0\n",
    "\n",
    "noisy_freq_bands_idx=[]\n",
    "for ip_n, _ in enumerate(peaks):\n",
    "    #+1 here because I  will use these values as range,and range in pythonis usually \"up to the value but not including\", this should fix it to the right rang\n",
    "    noisy_freq_bands_idx.append([fr for fr in np.arange((round(left_ips[ip_n])), round(right_ips[ip_n])+1)])\n",
    "\n",
    "\n",
    "print(noisy_freq_bands_idx)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Looping over all bands\n",
    "print('BEFORE', width_heights)\n",
    "print('BEFORE', noisy_freq_bands_idx)\n",
    "\n",
    "def split_blended_freqs(noisy_freq_bands_idx, width_heights, freqs):\n",
    "    band = 0\n",
    "    while band < len(noisy_freq_bands_idx):\n",
    "\n",
    "        # Checking if the last element of every band is contained in the current band\n",
    "        last = 0\n",
    "        while last < len(noisy_freq_bands_idx):\n",
    "\n",
    "            if (noisy_freq_bands_idx[last] != noisy_freq_bands_idx[band]) and (noisy_freq_bands_idx[last][-1] in noisy_freq_bands_idx[band]):\n",
    "                \n",
    "                print('split freq', noisy_freq_bands_idx[last][-1])\n",
    "                split_index = noisy_freq_bands_idx[band].index(noisy_freq_bands_idx[last][-1])\n",
    "\n",
    "                split_band_left = noisy_freq_bands_idx[band][:split_index]\n",
    "                split_band_right = noisy_freq_bands_idx[band][split_index:]\n",
    "\n",
    "                noisy_freq_bands_idx[last] = split_band_left\n",
    "                noisy_freq_bands_idx[band] = split_band_right\n",
    "\n",
    "                min_width_heights = min(width_heights[last],width_heights[band])\n",
    "                width_heights[band] = min_width_heights\n",
    "                width_heights[last] = min_width_heights\n",
    "\n",
    "                band = 0\n",
    "                last = 0\n",
    "\n",
    "            last += 1\n",
    "        band += 1\n",
    "\n",
    "\n",
    "\n",
    "    # # Getting the matching indexes in fregs for the bands in noisy_freq_bands\n",
    "    # for band in noisy_freq_bands:\n",
    "    #     band_ind=[]\n",
    "    #     for freq in band:\n",
    "    #         band_ind.append(freqs.tolist().index(freq))\n",
    "    #     noisy_freq_bands_ind.append(band_ind)\n",
    "\n",
    "\n",
    "    return noisy_freq_bands_idx, width_heights\n",
    "\n",
    "noisy_freq_bands_idx_split, width_heights_split = split_blended_freqs(noisy_freq_bands_idx, width_heights, freqs)\n",
    "\n",
    "print('AFTER', width_heights_split)\n",
    "print('AFTER', noisy_freq_bands_idx_split)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ips_l, ips_r = [], []\n",
    "for fr_n, fr_b in enumerate(noisy_freq_bands_idx_split):\n",
    "    ips_l.append(freqs[fr_b][0])\n",
    "    ips_r.append(freqs[fr_b][-1])\n",
    "    \n",
    "    avg_psd_only_signal[fr_b]=None #keep only main psd, remove noise bands, just for visual\n",
    "    avg_psd_only_peaks[fr_b]=avg_psd[fr_b].copy() #keep only noise bands, remove psd, again for visual\n",
    "    avg_psd_only_peaks_baselined[fr_b]=avg_psd[fr_b].copy()-[width_heights[fr_n]]*len(avg_psd_only_peaks[fr_b])\n",
    "    #keep only noise bands and baseline them to 0 (remove the signal which is under the noise line)\n",
    "\n",
    "\n",
    "\n",
    "freq_res = freqs[1] - freqs[0]\n",
    "total_power = simps(avg_psd, dx=freq_res) # power of all signal\n",
    "print('Total power: ', total_power)\n",
    "\n",
    "all_bp_noise=[]\n",
    "all_bp_relative=[]\n",
    "bp_noise_relative_to_signal=[]\n",
    "\n",
    "\n",
    "avg_psd_only_peaks_baselined_new=np.array([avg_psd_only_peaks_baselined]) \n",
    "for fr_n, fr_b in enumerate(noisy_freq_bands_idx_split):\n",
    "\n",
    "    #print('band',  freqs[fr_b][0], freqs[fr_b][-1])\n",
    "    bp_noise, _, bp_relative = Power_of_band(freqs=freqs, f_low = freqs[fr_b][0], f_high= freqs[fr_b][-1], psds=avg_psd_only_peaks_baselined_new)\n",
    "\n",
    "    all_bp_noise+=bp_noise\n",
    "    all_bp_relative+=bp_relative\n",
    "\n",
    "    #Calculate how much of the total power of the average signal goes into each of the noise freqs:\n",
    "    bp_noise_relative_to_signal.append(bp_noise / total_power) # relative power: % of this band in the total bands power for this channel:\n",
    "\n",
    "bp_noise_relative_to_signal=[r[0] for r in bp_noise_relative_to_signal]\n",
    "\n",
    "#print('Freq band for each peak:', ips_pair)\n",
    "print('BP', all_bp_noise)\n",
    "print('relative BP', all_bp_relative)\n",
    "print('Amount of noisy freq in total signal', bp_noise_relative_to_signal)\n",
    "\n",
    "helper_plots= True\n",
    "if helper_plots is True:\n",
    "    plt.plot(freqs,avg_psd)\n",
    "    plt.plot(freqs[peaks], avg_psd[peaks], 'x')\n",
    "    plt.hlines(y=width_heights, xmin=ips_l, xmax=ips_r, color=\"C3\")\n",
    "    plt.show()\n",
    "\n",
    "    plt.plot(freqs,avg_psd_only_signal)\n",
    "    plt.plot(freqs[peaks], avg_psd_only_signal[peaks], \"x\")\n",
    "    plt.hlines(y=width_heights, xmin=ips_l, xmax=ips_r, color=\"C3\")\n",
    "    plt.show()\n",
    "\n",
    "    plt.plot(freqs,avg_psd_only_peaks)\n",
    "    plt.plot(freqs[peaks], avg_psd_only_peaks[peaks], \"x\")\n",
    "    plt.hlines(y=width_heights, xmin=ips_l, xmax=ips_r, color=\"C3\")\n",
    "    plt.show()\n",
    "\n",
    "    plt.plot(freqs,avg_psd_only_peaks_baselined)\n",
    "    plt.plot(freqs[peaks], avg_psd_only_peaks_baselined[peaks], \"x\")\n",
    "    plt.show()\n",
    "\n",
    "#NOW need power of freq. for each band in baselined\n",
    "\n",
    "bands_names=[str(fr)+' Hz noise' for fr in freqs[peaks]]+['Main signal']\n",
    "Snr=bp_noise_relative_to_signal+[1-sum(bp_noise_relative_to_signal)]\n",
    "psd_pie_derivative = plot_pie_chart_freq(mean_relative_freq=Snr, tit='Signal and Noise', bands_names=bands_names)\n",
    "psd_pie_derivative.content.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noisy_freq_bands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=[13, 14, 15, 16, 17, 18] \n",
    "b=[7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21]\n",
    "\n",
    "all(item in b for item in a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "[range(13,19)] in [range(7, 22)]\n",
    "\n",
    "[l for l in range(13,19)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit polynomial models up to degree 5\n",
    "model1 = np.poly1d(np.polyfit(freqs, avg_psd, 1))\n",
    "model2 = np.poly1d(np.polyfit(freqs, avg_psd, 2))\n",
    "model3 = np.poly1d(np.polyfit(freqs, avg_psd, 3))\n",
    "model4 = np.poly1d(np.polyfit(freqs, avg_psd, 4))\n",
    "model5 = np.poly1d(np.polyfit(freqs, avg_psd, 5))\n",
    "\n",
    "fig.add_trace(go.Scatter(x=freqs, y=model1(freqs), name='model1')) \n",
    "fig.add_trace(go.Scatter(x=freqs, y=model2(freqs), name='model2')) \n",
    "fig.add_trace(go.Scatter(x=freqs, y=model3(freqs), name='model3')) \n",
    "fig.add_trace(go.Scatter(x=freqs, y=model4(freqs), name='model4')) \n",
    "fig.add_trace(go.Scatter(x=freqs, y=model5(freqs), name='model5')) \n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot EOG channel\n",
    "\n",
    "raw.copy().pick_types(meg=False, stim=False,eog=True).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ECG_meg_qc import find_affected_channels\n",
    "\n",
    "mag_ch_names = raw.copy().pick_types(meg='mag').ch_names if 'mag' in raw else None\n",
    "grad_ch_names = raw.copy().pick_types(meg='grad').ch_names if 'grad' in raw else None\n",
    "channels = {'mag': mag_ch_names, 'grad': grad_ch_names}\n",
    "sfreq=raw.info['sfreq']\n",
    "m_or_g='mag'\n",
    "tmin=-0.2\n",
    "tmax=0.2\n",
    "#ecg_epochs = mne.preprocessing.create_ecg_epochs(raw, picks=channels[m_or_g], tmin=tmin, tmax=tmax)\n",
    "\n",
    "#ch_name='EOG 061'\n",
    "ch_name='EOG002'\n",
    "eog_epochs = mne.preprocessing.create_eog_epochs(raw, picks=channels[m_or_g], ch_name=ch_name, tmin=tmin, tmax=tmax)\n",
    "\n",
    "\n",
    "ecg_affected_channels, fig_affected, fig_not_affected, fig_avg=find_affected_channels(eog_epochs, channels, m_or_g, norm_lvl=1, ecg_or_eog='EOG', thresh_lvl_peakfinder=5, sfreq=sfreq, tmin=tmin, tmax=tmax, plotflag=True,  use_abs_of_all_data='flip')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ch_name='EOG003'\n",
    "eog_epochs = mne.preprocessing.create_eog_epochs(raw, picks=channels[m_or_g], ch_name=ch_name, tmin=tmin, tmax=tmax)\n",
    "\n",
    "\n",
    "ecg_affected_channels, fig_affected, fig_not_affected, fig_avg=find_affected_channels(eog_epochs, channels, m_or_g, norm_lvl=1, ecg_or_eog='EOG', thresh_lvl_peakfinder=5, sfreq=sfreq, tmin=tmin, tmax=tmax, plotflag=True,  use_abs_of_all_data='flip')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "eog_epochs = mne.preprocessing.create_eog_epochs(raw, picks=channels[m_or_g], tmin=tmin, tmax=tmax)\n",
    "\n",
    "\n",
    "ecg_affected_channels, fig_affected, fig_not_affected, fig_avg=find_affected_channels(eog_epochs, channels, m_or_g, norm_lvl=1, ecg_or_eog='EOG', thresh_lvl_peakfinder=5, sfreq=sfreq, tmin=tmin, tmax=tmax, plotflag=True,  use_abs_of_all_data='flip')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecg_affected_channels, fig_affected, fig_not_affected, fig_avg=find_affected_channels(ecg_epochs, channels, m_or_g, norm_lvl=1, ecg_or_eog='ecg', thresh_lvl_peakfinder=5, sfreq=sfreq, tmin=tmin, tmax=tmax, plotflag=True, use_abs_of_all_data='False')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecg_affected_channels, fig_affected, fig_not_affected, fig_avg=find_affected_channels(ecg_epochs, channels, m_or_g, norm_lvl=1, ecg_or_eog='ecg', thresh_lvl_peakfinder=5, sfreq=sfreq, tmin=tmin, tmax=tmax, plotflag=True, use_abs_of_all_data='flip')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = '/Volumes/M2_DATA/MEG_QC_stuff/data/from openneuro/ds003682/sub-001/ses-01/meg/sub-001_ses-01_task-AversiveLearningReplay_run-01_meg.fif'\n",
    "raw = mne.io.read_raw_fif(data_file)\n",
    "raw.info['chs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import numpy as np\n",
    "import mne\n",
    "y=np.array([1,4,5,0,0,0])\n",
    "peaks_l, peaks_m = mne.preprocessing.peak_finder(y)\n",
    "\n",
    "print(peaks_l)\n",
    "print(type(peaks_l[0]))\n",
    "print(len(peaks_l))\n",
    "\n",
    "print(np.array([87]))\n",
    "print(type(np.array([87])[0]))\n",
    "#print(len(np.array(87)))\n",
    "\n",
    "\n",
    "print(np.ndarray(87))\n",
    "print(len(np.ndarray(87)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Other useful ancp stuff:\n",
    "\n",
    "config = configparser.ConfigParser()\n",
    "config.read('settings.ini')\n",
    "\n",
    "default_direct = config['DEFAULT']['data_directory']\n",
    "dataset_path = ancpbids.utils.fetch_dataset(default_direct)\n",
    "\n",
    "from ancpbids import BIDSLayout\n",
    "layout = BIDSLayout(dataset_path)\n",
    "\n",
    "list_of_fifs = layout.get(suffix='meg', extension='.fif', return_type='filename')\n",
    "\n",
    "list_of_subs = layout.get_subjects()\n",
    "\n",
    "\n",
    "list_of_entities = layout.get_entities()\n",
    "print(list_of_entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TRY SEPARATE FUNCS HERE\n",
    "\n",
    "config = configparser.ConfigParser()\n",
    "config.read('settings.ini')\n",
    "data_file = '/Volumes/M2_DATA/MEG_QC_stuff/data/from openneuro/ds003483/sub-009/ses-1/meg/sub-009_ses-1_task-deduction_run-1_meg.fif'\n",
    "all_qc_params = get_all_config_params('settings.ini')\n",
    "dict_of_dfs_epoch, dict_epochs_mg, channels, raw_filtered, raw_filtered_resampled, raw_cropped, raw, active_shielding_used = initial_processing(default_settings=all_qc_params['default'], filtering_settings=all_qc_params['Filtering'], epoching_params=all_qc_params['Epoching'], data_file=data_file)\n",
    "\n",
    "m_or_g_chosen = ['mag']\n",
    "sid='009'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "\n",
    "#dfs_ptp_amlitude_annot, bad_channels, amplit_annot_with_ch_names = PP_auto_meg_qc(sid, config, channels, raw, m_or_g_chosen)\n",
    "\n",
    "#derivs, big_rmse_with_value_all_data, small_rmse_with_value_all_data = RMSE_meg_qc(all_qc_params['RMSE'], channels, dict_epochs_mg, dict_dict_of_dfs_epoch, raw, m_or_g_chosen)\n",
    "\n",
    "derivs = PP_manual_meg_qc(all_qc_params['PTP_manual'], channels, dict_epochs_mg, dict_of_dfs_epoch, raw, m_or_g_chosen)\n",
    "\n",
    "#out_with_name_and_format = PSD_meg_qc(sid, config, channels, raw, m_or_g_chosen)\n",
    "\n",
    "derivs = ECG_meg_qc(config, raw, m_or_g_chosen)\n",
    "\n",
    "#out_with_name_and_format = EOG_meg_qc(config, raw, m_or_g_chosen)\n",
    "\n",
    "#out_with_name_and_format, bad_channels = PP_auto_meg_qc(sid, config, channels, raw, m_or_g_chosen)\n",
    "\n",
    "print(\"--- Execution %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "\n",
    "for der in derivs:\n",
    "    if der.content_type == 'plotly':\n",
    "        der.content.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# out_with_name_and_format[0].convert_fig_to_html()\n",
    "from universal_plots import QC_derivative\n",
    "dr = QC_derivative('001', 'mean_EC_epoch', None, '')\n",
    "# dr_html = dr.convert_fig_to_html()\n",
    "# l=[\"a\"]\n",
    "\n",
    "# if dr_html is not None:\n",
    "\n",
    "#     l += dr_html\n",
    "    \n",
    "# print(l)\n",
    "\n",
    "sec = dr.get_section()\n",
    "print(sec)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(figs)\n",
    "all_fig_derivs = figs\n",
    "figures_report = {}\n",
    "for x in range(0, len(all_fig_derivs)):\n",
    "    if all_fig_derivs[x][3]=='plotly':\n",
    "        figures_report[\"f{0}\".format(x)] = plotly.io.to_html(all_fig_derivs[x][0])\n",
    "    elif all_fig_derivs[x][3]=='matplotlib':\n",
    "        figures_report[\"f{0}\".format(x)] = mpld3.fig_to_html(all_fig_derivs[x][0]);\n",
    "\n",
    "print(figures_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import mpld3\n",
    "\n",
    "html_fig=mpld3.fig_to_html(figs[0][0])\n",
    "print(html_fig)\n",
    "\n",
    "\n",
    "\n",
    "# file = open('matpl_fig.html', \"w\")\n",
    "# file.write(html_fig)\n",
    "# file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_string = '''\n",
    "<!doctype html>\n",
    "<html>\n",
    "    <head>\n",
    "        <meta charset=\"UTF-8\">\n",
    "        <title>MEG QC: Frequency spectrum Report</title>\n",
    "        <style>body{ margin:0 100;}</style>\n",
    "    </head>\n",
    "    \n",
    "    <body style=\"font-family: Arial\">\n",
    "        <center>\n",
    "        <h1>MEG data quality analysis report</h1>\n",
    "        <br></br>\n",
    "        <!-- *** Section 1 *** --->\n",
    "        <h2>Frequency spectrum per channel</h2>\n",
    "        ''' + html_fig + '''\n",
    "        <p>graph description...</p>\n",
    "        </center>\n",
    "    \n",
    "    </body>\n",
    "</html>'''\n",
    "\n",
    "with open('report_trial.html', 'w', encoding = 'utf8') as f:\n",
    "    f.write(html_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#config = configparser.ConfigParser()\n",
    "#config.read('settings.ini')\n",
    "\n",
    "#data_file = '/Volumes/M2_DATA/MEG_QC_stuff/data/from openneuro/ds000117/sub-01/ses-meg/meg/sub-01_ses-meg_task-facerecognition_run-01_meg.fif'\n",
    "# file does not start with a file id tag\n",
    "\n",
    "#data_file = '/Volumes/M2_DATA/MEG_QC_stuff/data/from openneuro/ds003392/sub-01/meg/sub-01_task-localizer_meg.fif'\n",
    "# SSS frilter. need to allow maxshiled.\n",
    "\n",
    "#data_file ='/Volumes/M2_DATA/MEG_QC_stuff/data/from openneuro/ds003694/sub-01/meg/sub-01_task-MEM_run-01_meg.fif'\n",
    "#raw = mne.io.read_raw_fif(data_file, on_split_missing='ignore')\n",
    "\n",
    "\n",
    "#dict_of_dfs_epoch, dict_epochs_mg, channels, raw_bandpass, raw_filtered_resampled, raw_cropped, raw = initial_processing(config, data_file)\n",
    "\n",
    "#data_file ='/Volumes/M2_DATA/MEG_QC_stuff/data/from openneuro/ds003922/sub-Mp150285/ses-01/meg/sub-Mp150285_ses-01_acq-crosstalk_meg.fif'\n",
    "#Could not find measurement data: how many in this set, which subjects?\n",
    "\n",
    "\n",
    "data_file ='/Volumes/M2_DATA/MEG_QC_stuff/data/from openneuro/ds004229/sub-102/meg/sub-102_task-amnoise_meg.fif'\n",
    "#SSS filter\n",
    "raw = mne.io.read_raw_fif(data_file, allow_maxshield=True)\n",
    "\n",
    "\n",
    "#data_dir ='/Volumes/M2_DATA/MEG_QC_stuff/data/from openneuro/not fitting no fif/ds000246/sub-0001/meg/sub-0001_task-AEF_run-01_meg.ds'\n",
    "#raw = mne.io.read_raw_ctf(data_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import configparser\n",
    "from ancpbids import BIDSLayout\n",
    "\n",
    "config = configparser.ConfigParser()\n",
    "config.read('settings.ini')\n",
    "\n",
    "default_section = config['DEFAULT']\n",
    "\n",
    "m_or_g_chosen = default_section['do_for'] \n",
    "m_or_g_chosen = m_or_g_chosen.replace(\" \", \"\")\n",
    "m_or_g_chosen = m_or_g_chosen.split(\",\")\n",
    "#m_or_g_chosen = select_m_or_g(default_section)\n",
    "\n",
    "dataset_path = default_section['data_directory']\n",
    "\n",
    "layout = BIDSLayout(dataset_path)\n",
    "schema = layout.schema\n",
    "\n",
    "#create derivative folder first!\n",
    "derivative = layout.dataset.create_derivative(name=\"Meg_QC\")\n",
    "derivative.dataset_description.GeneratedBy.Name = \"MEG QC Pipeline\"\n",
    "\n",
    "list_of_subs = layout.get_subjects()\n",
    "#print(list_of_subs)\n",
    "for sub in list_of_subs:\n",
    "    list_of_fifs_per_sub = layout.get(suffix='meg', extension='.fif', sub=sub)\n",
    "    for_entities={}\n",
    "    for file in list_of_fifs_per_sub:\n",
    "        k=file['entities'][1]['key']\n",
    "        v=file['entities'][1]['value']\n",
    "        for_entities[k]=v\n",
    "    print(for_entities)\n",
    "\n",
    "#print(list_of_fifs_per_sub)\n",
    "# for sid in [list_of_subs[0]]: #RUN OVER JUST 1 SUBJ\n",
    "# #for sid in list_of_subs: \n",
    "\n",
    "#     subject_folder = derivative.create_folder(type_=schema.Subject, name='sub-'+sid)\n",
    "\n",
    "#     list_of_fifs = layout.get(suffix='meg', extension='.fif', return_type='filename', subj=sid)\n",
    "#     #Devide here fifs by task, ses , run\n",
    "\n",
    "#     for data_file in [list_of_fifs[0]]: #RUN OVER JUST 1 FIF because is not divided by tasks yet..\n",
    "#         print(type(data_file))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('mne_new')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d401ab1bf6dd7bb97662b0feb1321a641d60d04842bfa92b47f7871360972b5d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
