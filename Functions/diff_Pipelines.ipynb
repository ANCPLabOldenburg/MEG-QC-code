{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This notebook is trying out different pipeline approaches\n",
    "\n",
    "# Cropped data is used here (5 minutes only), tried on whole data - takes forever.\n",
    "\n",
    "\n",
    "#Load data, make folders\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "import mne\n",
    "import pyprep as pp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening raw data file /Volumes/M2_DATA/MEG_QC_stuff/data/from openneuro/ds003483/sub-009/ses-1/meg/sub-009_ses-1_task-deduction_run-1_meg.fif...\n",
      "    Range : 60000 ... 1255999 =     60.000 ...  1255.999 secs\n",
      "Ready.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"table table-hover table-striped table-sm table-responsive small\">\n",
       "    <tr>\n",
       "        <th>Measurement date</th>\n",
       "        \n",
       "        <td>February 21, 2019  11:11:50 GMT</td>\n",
       "        \n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Experimenter</th>\n",
       "        \n",
       "        <td>Common account for MEG work (meg)</td>\n",
       "        \n",
       "    </tr>\n",
       "        <th>Participant</th>\n",
       "        \n",
       "            \n",
       "        \n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Digitized points</th>\n",
       "        \n",
       "        <td>0 points</td>\n",
       "        \n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Good channels</th>\n",
       "        <td>204 Gradiometers, 102 Magnetometers, 1 EOG, 1 ECG, 3 Stimulus, 9 CHPI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Bad channels</th>\n",
       "        <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>EOG channels</th>\n",
       "        <td>EOG061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>ECG channels</th>\n",
       "        <td>ECG062</td>\n",
       "    \n",
       "    <tr>\n",
       "        <th>Sampling frequency</th>\n",
       "        <td>1000.00 Hz</td>\n",
       "    </tr>\n",
       "    \n",
       "    \n",
       "    <tr>\n",
       "        <th>Highpass</th>\n",
       "        <td>0.10 Hz</td>\n",
       "    </tr>\n",
       "    \n",
       "    \n",
       "    <tr>\n",
       "        <th>Lowpass</th>\n",
       "        <td>330.00 Hz</td>\n",
       "    </tr>\n",
       "    \n",
       "    \n",
       "    \n",
       "    <tr>\n",
       "        <th>Filenames</th>\n",
       "        <td>sub-009_ses-1_task-deduction_run-1_meg.fif</td>\n",
       "    </tr>\n",
       "    \n",
       "    <tr>\n",
       "        <th>Duration</th>\n",
       "        <td>00:01:35 (HH:MM:SS)</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Raw | sub-009_ses-1_task-deduction_run-1_meg.fif, 320 x 96000 (96.0 s), ~5.3 MB, data not loaded>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#from Functions.main_meg_qc import initial_stuff\n",
    "from data_load_and_folders import load_meg_data\n",
    "duration=5 #in minutes\n",
    "#n_events, df_epochs_mags, df_epochs_grads, epochs_mags, epochs_grads, mags, grads, filtered_d, filtered_d_resamp, raw_cropped, raw=initial_stuff(duration)\n",
    "\n",
    "data_file = '/Volumes/M2_DATA/MEG_QC_stuff/data/from openneuro/ds003483/sub-009/ses-1/meg/sub-009_ses-1_task-deduction_run-1_meg.fif'\n",
    "raw, channels = load_meg_data(data_file)\n",
    "\n",
    "#crop the data to calculate faster\n",
    "raw_cropped = raw.copy()\n",
    "raw_cropped.crop(tmin=1100, tmax=None) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding segments below or above PTP threshold.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>onset</th>\n",
       "      <th>duration</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-02-21 11:31:10.619717</td>\n",
       "      <td>0.002</td>\n",
       "      <td>BAD_flat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-02-21 11:31:10.623717</td>\n",
       "      <td>0.025</td>\n",
       "      <td>BAD_flat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-02-21 11:31:10.649717</td>\n",
       "      <td>0.027</td>\n",
       "      <td>BAD_flat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-02-21 11:31:10.678717</td>\n",
       "      <td>0.002</td>\n",
       "      <td>BAD_flat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-02-21 11:31:10.681717</td>\n",
       "      <td>0.030</td>\n",
       "      <td>BAD_flat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3647</th>\n",
       "      <td>2019-02-21 11:32:46.536717</td>\n",
       "      <td>0.028</td>\n",
       "      <td>BAD_flat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3648</th>\n",
       "      <td>2019-02-21 11:32:46.567717</td>\n",
       "      <td>0.008</td>\n",
       "      <td>BAD_flat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3649</th>\n",
       "      <td>2019-02-21 11:32:46.576717</td>\n",
       "      <td>0.024</td>\n",
       "      <td>BAD_flat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3650</th>\n",
       "      <td>2019-02-21 11:32:46.601717</td>\n",
       "      <td>0.002</td>\n",
       "      <td>BAD_flat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3651</th>\n",
       "      <td>2019-02-21 11:32:46.604717</td>\n",
       "      <td>0.012</td>\n",
       "      <td>BAD_flat</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3652 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          onset  duration description\n",
       "0    2019-02-21 11:31:10.619717     0.002    BAD_flat\n",
       "1    2019-02-21 11:31:10.623717     0.025    BAD_flat\n",
       "2    2019-02-21 11:31:10.649717     0.027    BAD_flat\n",
       "3    2019-02-21 11:31:10.678717     0.002    BAD_flat\n",
       "4    2019-02-21 11:31:10.681717     0.030    BAD_flat\n",
       "...                         ...       ...         ...\n",
       "3647 2019-02-21 11:32:46.536717     0.028    BAD_flat\n",
       "3648 2019-02-21 11:32:46.567717     0.008    BAD_flat\n",
       "3649 2019-02-21 11:32:46.576717     0.024    BAD_flat\n",
       "3650 2019-02-21 11:32:46.601717     0.002    BAD_flat\n",
       "3651 2019-02-21 11:32:46.604717     0.012    BAD_flat\n",
       "\n",
       "[3652 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Annotate bad peak to peak amplitudes: peaks and flats\n",
    "# USE TO MARK WHOLE CHANNELS AS BAD\n",
    "\n",
    "# https://mne.tools/stable/generated/mne.preprocessing.annotate_amplitude.html\n",
    "# copmpare this MNE function with what I wrote myself: Funnks - > Peaks_meg_qc -> neighbour_peak_amplitude\n",
    "\n",
    "#'Creates annotations BAD_peak or BAD_flat for spans of data where consecutive samples exceed the threshold in peak or fall below the threshold \n",
    "# in flat for more than min_duration' \n",
    "\n",
    "amplit_annot=mne.preprocessing.annotate_amplitude(raw_cropped, peak={'mag':4e-14, 'grad': 4e-14}, flat=3e-14, bad_percent=5, min_duration=0.002, verbose=True)\n",
    "\n",
    "#  !!! Automatically choose peak and flat values by averaging the data maybe?\n",
    "\n",
    "\n",
    "# Some input parameters:\n",
    "# * bad_percent - percent of tolerated bad segments in the channel. id some channel is over this percent - will be returned as \"bads\". \n",
    "#   While if its under, just the points will be returned as \"bad peak or \"bad flat\"\n",
    "#   However I dont see any info about which channel these points belong to! Which is totally stupid?\n",
    "# * picks can call channel types or separate channel names like: picks=['grad'] or picks=['MEG0111']\n",
    "# * alterbnatively u can specify peaks and/or flats values for types of channels like: peak={'mag':3.5e-11, 'grad': 4e-11} (but not the names of channels).\n",
    "# * min_duration is in minutes\n",
    "# * peaks and flats are in the same scale as the data, like: 1e-13\n",
    "\n",
    "# Differences with my function in Funks.Peaks_meg_gc.ipynb: \n",
    "# - no option to set distance between up and down peak to be concedered a pair. They calculate peak like: abs(a[i+1] - a[i]) ≥ peak (from docs).\n",
    "#   So we can probably adjust indexing of 'a' here to decide which peaks concider as an up+down pair.\n",
    "# - This function need raw obj as input. So not epochs and not just a piece of data -> need to adjust it for epochs. \n",
    "# - Can set here extra: flat, percent of bad, min duration and actual height of peaks and flats.\n",
    "\n",
    "# Now need to add these annotation obj to the raw:\n",
    "raw_cropped.set_annotations(raw_cropped.annotations + amplit_annot[0])  \n",
    "raw_cropped.info['bads'] = amplit_annot[1]\n",
    "# annotate_amplitude creates a tuple, not just annotations, like other functions from this series. \n",
    "# Second part of tuple is 'bads' (whole channel is bad, too many bad segments). \n",
    "# This whole tuple can't be added to annots in raw, need to slice the first part like: [0]\n",
    "\n",
    "\n",
    "#print('\\nAnnotations added to raw:', raw_cropped.annotations)\n",
    "#print('Channels added to bads in raw:', raw_cropped.info['bads'],\"\\n\")\n",
    "\n",
    "\n",
    "# ANNOTATIONS ARE SUMMED HERE. SO IF YOU WANT TO OVERWRITE THEM, RUN ALL CELLS ABOVE AGAIN OR JUST DELETE THE ANNOTATIONS like: \n",
    "# idx=[a for a in range(0,len(raw_cropped.annotations))] #all annotations chosen for removal\n",
    "# raw_cropped.annotations.delete(idx)\n",
    "# ONLY RERUNNING THIS ONE CELL WILL NOT REMOVE OLD ANNOTS FROM RAW. \n",
    "\n",
    "# raw_cropped.plot() #plot the data with annotations\n",
    "\n",
    "sid='009'\n",
    "# export annotation to dataframe:\n",
    "df_annot=raw_cropped.annotations.to_data_frame()\n",
    "df_annot.to_csv('../derivatives/sub-'+sid+'/megqc/csv files/ptp_amplitude_annots_all.csv')\n",
    "df_annot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since this function doesnt give channel names, need to loop over every channel and add its name into every annotation.\n",
    "# mne.Annotations obj doesnt allow changing, so will have to create a new object and write explicitly all info + channel name there.\n",
    "\n",
    "# USE TO MARK EPOCH AS BAD, EXTRACT TIME OF FLAT/PEAK + WHICH CHANNEL\n",
    "\n",
    "def get_amplitude_annots_per_channel(raw: mne.io.Raw, peak: float, flat: float, ch_type_names: list) -> tuple[pd.DataFrame, list]:\n",
    "    \"\"\"Function creates amplitude (peak-to-peak annotations for every channel separately\"\"\"\n",
    "    \n",
    "    amplit_annot_with_ch_names=mne.Annotations(onset=[], duration=[], description=[], orig_time=raw.annotations.orig_time) #initialize \n",
    "    bad_channels=[]\n",
    "\n",
    "    for channel in ch_type_names:\n",
    "        #get annotation object:\n",
    "        amplit_annot=mne.preprocessing.annotate_amplitude(raw, peak=peak, flat=flat , bad_percent=5, min_duration=0.002, picks=[channel], verbose=False)\n",
    "        \n",
    "        bad_channels.append(amplit_annot[1]) #Can later add these into annotation as well.\n",
    "\n",
    "        if len(amplit_annot[0])>0:\n",
    "\n",
    "            #create new annot obj and add there all data + channel name:\n",
    "            amplit_annot_with_ch_names.append(onset=amplit_annot[0][0]['onset'], duration=amplit_annot[0][0]['duration'], description=amplit_annot[0][0]['description'], ch_names=[[channel]])\n",
    "\n",
    "    df_ptp_amlitude_annot=amplit_annot_with_ch_names.to_data_frame()\n",
    "\n",
    "    return df_ptp_amlitude_annot, bad_channels, amplit_annot_with_ch_names\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>onset</th>\n",
       "      <th>duration</th>\n",
       "      <th>description</th>\n",
       "      <th>ch_names</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-02-21 11:31:10.815717</td>\n",
       "      <td>0.002</td>\n",
       "      <td>BAD_flat</td>\n",
       "      <td>(MEG2533,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-02-21 11:31:11.102717</td>\n",
       "      <td>0.002</td>\n",
       "      <td>BAD_flat</td>\n",
       "      <td>(MEG0542,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-02-21 11:31:11.123717</td>\n",
       "      <td>0.002</td>\n",
       "      <td>BAD_flat</td>\n",
       "      <td>(MEG1042,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-02-21 11:31:11.134717</td>\n",
       "      <td>0.002</td>\n",
       "      <td>BAD_flat</td>\n",
       "      <td>(MEG2332,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-02-21 11:31:11.155717</td>\n",
       "      <td>0.002</td>\n",
       "      <td>BAD_flat</td>\n",
       "      <td>(MEG1713,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>2019-02-21 11:32:25.835717</td>\n",
       "      <td>0.002</td>\n",
       "      <td>BAD_flat</td>\n",
       "      <td>(MEG0423,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>2019-02-21 11:32:28.571717</td>\n",
       "      <td>0.002</td>\n",
       "      <td>BAD_flat</td>\n",
       "      <td>(MEG1023,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>2019-02-21 11:32:28.876717</td>\n",
       "      <td>0.002</td>\n",
       "      <td>BAD_flat</td>\n",
       "      <td>(MEG2022,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>2019-02-21 11:32:30.472717</td>\n",
       "      <td>0.002</td>\n",
       "      <td>BAD_flat</td>\n",
       "      <td>(MEG0943,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>2019-02-21 11:32:36.620717</td>\n",
       "      <td>0.002</td>\n",
       "      <td>BAD_flat</td>\n",
       "      <td>(MEG0642,)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>199 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         onset  duration description    ch_names\n",
       "0   2019-02-21 11:31:10.815717     0.002    BAD_flat  (MEG2533,)\n",
       "1   2019-02-21 11:31:11.102717     0.002    BAD_flat  (MEG0542,)\n",
       "2   2019-02-21 11:31:11.123717     0.002    BAD_flat  (MEG1042,)\n",
       "3   2019-02-21 11:31:11.134717     0.002    BAD_flat  (MEG2332,)\n",
       "4   2019-02-21 11:31:11.155717     0.002    BAD_flat  (MEG1713,)\n",
       "..                         ...       ...         ...         ...\n",
       "194 2019-02-21 11:32:25.835717     0.002    BAD_flat  (MEG0423,)\n",
       "195 2019-02-21 11:32:28.571717     0.002    BAD_flat  (MEG1023,)\n",
       "196 2019-02-21 11:32:28.876717     0.002    BAD_flat  (MEG2022,)\n",
       "197 2019-02-21 11:32:30.472717     0.002    BAD_flat  (MEG0943,)\n",
       "198 2019-02-21 11:32:36.620717     0.002    BAD_flat  (MEG0642,)\n",
       "\n",
       "[199 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # clear annotations:\n",
    "# idx=[a for a in range(0,len(raw_cropped.annotations))] #all annotations chosen for removal\n",
    "# raw_cropped.annotations.delete(idx)\n",
    "\n",
    "peak_m=4e-14\n",
    "peak_g=4e-14\n",
    "flat=3e-14\n",
    "bad_percent = 5\n",
    "min_duration = 0.002\n",
    "\n",
    "raw_cropped = raw.copy()\n",
    "raw_cropped.crop(tmin=1100, tmax=None) \n",
    "# annotate amplitude per channel:\n",
    "#df_ptp_amlitude_annot_mags, bad_channels, amplit_annot_with_ch_names_mags=get_amplitude_annots_per_channel(raw_cropped, peak_m, flat, ch_type_names=channels['mags'])\n",
    "#df_ptp_amlitude_annot_grads, bad_channels, amplit_annot_with_ch_names_grads=get_amplitude_annots_per_channel(raw_cropped, peak_g, flat, ch_type_names=channels['grads'])\n",
    "#amplit_annot_with_ch_names_grads=get_amplitude_annots_per_channel(raw_cropped, peak, flat, ch_type_names=grads)\n",
    "\n",
    "from Peaks_auto_meg_qc import get_amplitude_annots_per_channel\n",
    "df_ptp_amlitude_annot_mags, bad_channels_mags=get_amplitude_annots_per_channel(raw_cropped, peak_m, flat, channels['mags'],bad_percent, min_duration)\n",
    "df_ptp_amlitude_annot_mags.to_csv('/Users/jenya/Local Storage/Job Uni Rieger lab/MEG QC code/derivatives/sub-'+sid+'/megqc/csv files/ptp_amplitude_annots_mags.csv')\n",
    "\n",
    "df_ptp_amlitude_annot_mags, bad_channels_mags=get_amplitude_annots_per_channel(raw_cropped, peak_m, flat, channels['grads'],bad_percent, min_duration)\n",
    "df_ptp_amlitude_annot_mags.to_csv('/Users/jenya/Local Storage/Job Uni Rieger lab/MEG QC code/derivatives/sub-'+sid+'/megqc/csv files/ptp_amplitude_annots_grads.csv')\n",
    "\n",
    "df_ptp_amlitude_annot_mags\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Annotate breaks - doesnt work..\n",
    "\n",
    "break_annots = mne.preprocessing.annotate_break(\n",
    "    raw=raw_cropped,\n",
    "    min_break_duration=5,  # consider segments of at least 5 s duration\n",
    "    t_start_after_previous=2,  # start annotation 2 s after end of previous one\n",
    "    t_stop_before_next=2  # stop annotation 2 s before beginning of next one\n",
    ")\n",
    "\n",
    "\n",
    "raw_cropped.set_annotations(raw_cropped.annotations + break_annots)  # add to existing\n",
    "raw_cropped.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Annotate movement - like in tutorial 2 from:\n",
    "# https://mne.tools/stable/generated/mne.preprocessing.annotate_movement.html\n",
    "\n",
    "from mne.preprocessing import annotate_movement, compute_average_dev_head_t\n",
    "\n",
    "# Get cHPI time series and compute average\n",
    "chpi_locs = mne.chpi.extract_chpi_locs_ctf(raw_cropped)\n",
    "head_pos = mne.chpi.compute_head_pos(raw_cropped.info, chpi_locs)\n",
    "original_head_dev_t = mne.transforms.invert_transform(\n",
    "    raw_cropped.info['dev_head_t'])\n",
    "average_head_dev_t = mne.transforms.invert_transform(\n",
    "    compute_average_dev_head_t(raw_cropped, head_pos))\n",
    "fig = mne.viz.plot_head_positions(head_pos)\n",
    "for ax, val, val_ori in zip(fig.axes[::2], average_head_dev_t['trans'][:3, 3],\n",
    "                            original_head_dev_t['trans'][:3, 3]):\n",
    "    ax.axhline(1000 * val, color='r')\n",
    "    ax.axhline(1000 * val_ori, color='g')\n",
    "\n",
    "# The green horizontal lines represent the original head position, whereas the\n",
    "# red lines are the new head position averaged over all the time points.\n",
    "\n",
    "mean_distance_limit = 0.0015  # in meters\n",
    "annotation_movement, hpi_disp = annotate_movement(\n",
    "    raw_cropped, head_pos, mean_distance_limit=mean_distance_limit)\n",
    "raw_cropped.set_annotations(annotation_movement)\n",
    "raw_cropped.plot(n_channels=100, duration=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Since we got an error, try another tutorial: \n",
    "# (takes some minutes depends how big is raw_cropped: 2-40 min):\n",
    "# https://mne.tools/stable/auto_tutorials/preprocessing/59_head_positions.html#sphx-glr-auto-tutorials-preprocessing-59-head-positions-py\n",
    "\n",
    "# cHPI - continuous head position indicator (HPI) coil channels, data in teslas\n",
    "\n",
    "# 'We can use mne.chpi.get_chpi_info to retrieve the coil frequencies, the index of \n",
    "# the channel indicating when which coil was switched on, and the respective “event codes” \n",
    "# associated with each coil’s activity.'\n",
    "chpi_freqs, ch_idx, chpi_codes = mne.chpi.get_chpi_info(info=raw_cropped.info, on_missing='warn', verbose=None)\n",
    "# Output:\n",
    "# - The frequency used for each individual cHPI coil.\n",
    "# - The index of the STIM channel containing information about when which cHPI coils were switched on.\n",
    "# - The values coding for the “on” state of each individual cHPI coil.\n",
    "\n",
    "# The values coding for the “on” state of each individual cHPI coil.\n",
    "print(f'cHPI coil frequencies extracted from raw: {chpi_freqs} Hz')\n",
    "\n",
    "#We only got 5, not 9 HPI (see error in cell above)\n",
    "\n",
    "\n",
    "#extract the HPI coil amplitudes as a function of time:\n",
    "print('Extract the HPI coil amplitudes as a function of time:')\n",
    "chpi_amplitudes=mne.chpi.compute_chpi_amplitudes(raw_cropped)\n",
    "#chpi_amplitudes=mne.chpi.compute_chpi_amplitudes(raw_cropped, t_step_min=0.01, t_window='auto', ext_order=1, tmin=0, tmax=None, verbose=None)\n",
    "\n",
    "\n",
    "#compute time-varying HPI coil locations from these\n",
    "print('Compute time-varying HPI coil locations from these')\n",
    "#chpi_locs=mne.chpi.compute_chpi_locs(raw_cropped.info, chpi_amplitudes, t_step_max=1.0, too_close='raise', adjust_dig=False, verbose=None)\n",
    "chpi_locs=mne.chpi.compute_chpi_locs(raw_cropped.info, chpi_amplitudes)\n",
    "\n",
    "\n",
    "print('Compute head positions from the coil locations:')\n",
    "#compute head positions from the coil locations:\n",
    "head_pos = mne.chpi.compute_head_pos(raw_cropped.info, chpi_locs, verbose=True)\n",
    "print('head_positions computed:', head_pos)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualizing continuous head position: doesnt work\n",
    "\n",
    "mne.viz.plot_head_positions(head_pos, mode='traces')\n",
    "#mne.viz.plot_head_positions(head_pos, mode='field')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now again try to annotate movement: also error - It didnt calculate any positions!\n",
    "\n",
    "mean_distance_limit = 0.0015  # in meters\n",
    "annotation_movement, hpi_disp = annotate_movement(\n",
    "    raw_cropped, head_pos, mean_distance_limit=mean_distance_limit)\n",
    "raw_cropped.set_annotations(raw_cropped.annotations + annotation_movement)\n",
    "raw_cropped.plot(n_channels=100, duration=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://pyprep.readthedocs.io/en/latest/generated/pyprep.NoisyChannels.html#pyprep.NoisyChannels\n",
    "\n",
    "# This class implements all of the noisy channel detection methods used in the PREP pipeline, as described in:\n",
    "# Bigdely-Shamlo, N., Mullen, T., Kothe, C., Su, K. M., Robbins, K. A. (2015). The PREP pipeline: \n",
    "# standardized preprocessing for large-scale EEG analysis. Frontiers in Neuroinformatics, 9, 16.\n",
    "\n",
    "noisy = pp.NoisyChannels(raw) #first, add raw to class, then all the noisy channels finding performed on this new object.\n",
    "\n",
    "# Doesnt work. Only EEG is supported. Tried to change channel type in just to try in:\n",
    "# opt/anaconda3/envs/mne_new/lib/python3.9/site-packages/pyprep/find_noisy_channels.py\n",
    "# to self.raw_mne.pick_types(meg=True, verbose=True)\n",
    "# no luck, it gives traceback on this line. \n",
    "# (If u explicitely call raw.pick_types(meg=True, verbose=True) - everything works fine - see cell above).\n",
    "\n",
    "# Dont know where the issue is exactly, but in the end we ll need to rewrite this whole function \n",
    "# to work with MEG if we really need it.\n",
    "\n",
    "from time import perf_counter\n",
    "\n",
    "start_time = perf_counter()\n",
    "#noisy.find_bad_by_ransac(channel_wise=True)\n",
    "noisy.find_all_bads(ransac=True, channel_wise=False, max_chunk_size=None)\n",
    "print(\"--- %s seconds ---\" % (perf_counter() - start_time))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('mne_new')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d401ab1bf6dd7bb97662b0feb1321a641d60d04842bfa92b47f7871360972b5d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
