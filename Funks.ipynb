{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "#import matplotlib\n",
    "#matplotlib.use('MACOSX')\n",
    "#for some reason if I run these 2 lines - it doesnt plot at all any more.\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import mne\n",
    "import matplotlib.pyplot as plt\n",
    "from copy import deepcopy\n",
    "from mne.time_frequency import tfr_morlet, psd_multitaper, psd_welch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_meg_data(raw_file=None):\n",
    "    #Load data AND SEPARATE MAGS AND GRADS. How do we want to input the path file here?\n",
    "\n",
    "    #raw_file = os.path.join('Katharinas_Data','sub_HT05ND16', '210811', 'mikado-1.fif')                               \n",
    "    raw = mne.io.read_raw_fif(raw_file)\n",
    "\n",
    "    #Separate mags and grads:\n",
    "    mags = [(chs['ch_name'], i) for i, chs in enumerate(raw.info['chs']) if str(chs['unit']).endswith('UNIT_T)')]\n",
    "    grads = [(chs['ch_name'], i) for i, chs in enumerate(raw.info['chs']) if str(chs['unit']).endswith('UNIT_T_M)')]\n",
    "\n",
    "    return(raw, mags, grads)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening raw data file Katharinas_Data/sub_HT05ND16/210811/mikado-1.fif...\n",
      "    Read a total of 8 projection items:\n",
      "        magn8_iasoff_68deg.fif : PCA-v1 (1 x 306)  idle\n",
      "        magn8_iasoff_68deg.fif : PCA-v2 (1 x 306)  idle\n",
      "        magn8_iasoff_68deg.fif : PCA-v3 (1 x 306)  idle\n",
      "        magn8_iasoff_68deg.fif : PCA-v4 (1 x 306)  idle\n",
      "        magn8_iasoff_68deg.fif : PCA-v5 (1 x 306)  idle\n",
      "        magn8_iasoff_68deg.fif : PCA-v6 (1 x 306)  idle\n",
      "        magn8_iasoff_68deg.fif : PCA-v7 (1 x 306)  idle\n",
      "        magn8_iasoff_68deg.fif : PCA-v8 (1 x 306)  idle\n",
      "    Range : 1809000 ... 3375999 =   1809.000 ...  3375.999 secs\n",
      "Ready.\n",
      "Opening raw data file /Users/jenya/Local Storage/Job Uni Rieger lab/MEG QC code/Katharinas_Data/sub_HT05ND16/210811/mikado-2.fif...\n",
      "    Read a total of 8 projection items:\n",
      "        magn8_iasoff_68deg.fif : PCA-v1 (1 x 306)  idle\n",
      "        magn8_iasoff_68deg.fif : PCA-v2 (1 x 306)  idle\n",
      "        magn8_iasoff_68deg.fif : PCA-v3 (1 x 306)  idle\n",
      "        magn8_iasoff_68deg.fif : PCA-v4 (1 x 306)  idle\n",
      "        magn8_iasoff_68deg.fif : PCA-v5 (1 x 306)  idle\n",
      "        magn8_iasoff_68deg.fif : PCA-v6 (1 x 306)  idle\n",
      "        magn8_iasoff_68deg.fif : PCA-v7 (1 x 306)  idle\n",
      "        magn8_iasoff_68deg.fif : PCA-v8 (1 x 306)  idle\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/h2/khhmb4p510vg63hbv0qkftt80000gs/T/ipykernel_90828/3339949254.py:5: RuntimeWarning: This filename (Katharinas_Data/sub_HT05ND16/210811/mikado-1.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw_fif(raw_file)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Range : 3376000 ... 4942999 =   3376.000 ...  4942.999 secs\n",
      "Ready.\n",
      "Opening raw data file /Users/jenya/Local Storage/Job Uni Rieger lab/MEG QC code/Katharinas_Data/sub_HT05ND16/210811/mikado-3.fif...\n",
      "    Read a total of 8 projection items:\n",
      "        magn8_iasoff_68deg.fif : PCA-v1 (1 x 306)  idle\n",
      "        magn8_iasoff_68deg.fif : PCA-v2 (1 x 306)  idle\n",
      "        magn8_iasoff_68deg.fif : PCA-v3 (1 x 306)  idle\n",
      "        magn8_iasoff_68deg.fif : PCA-v4 (1 x 306)  idle\n",
      "        magn8_iasoff_68deg.fif : PCA-v5 (1 x 306)  idle\n",
      "        magn8_iasoff_68deg.fif : PCA-v6 (1 x 306)  idle\n",
      "        magn8_iasoff_68deg.fif : PCA-v7 (1 x 306)  idle\n",
      "        magn8_iasoff_68deg.fif : PCA-v8 (1 x 306)  idle\n",
      "    Range : 4943000 ... 5198999 =   4943.000 ...  5198.999 secs\n",
      "Ready.\n"
     ]
    }
   ],
   "source": [
    "# run load:\n",
    "raw_file = os.path.join('Katharinas_Data','sub_HT05ND16', '210811', 'mikado-1.fif')  \n",
    "raw, mags, grads=load_meg_data(raw_file=raw_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_folders_meg(sid='1'):\n",
    "#Create folders (if they dont exist yet)\n",
    "\n",
    "#sid is subject Id, must be a string.\n",
    "#Folders are created in BIDS-compliant directory order: \n",
    "#Working directory - Subject - derivtaives - megQC - csvs and figures\n",
    "\n",
    "    #This is the list of folders and subfolders to be created. Loop checks if directory already exists, if not - create.\n",
    "    #Make sure to add subfolders on the list here AFTER the parent folder.\n",
    "\n",
    "    #DO WE NEED TO CREATE IT ACTUALLY NOT IN CURRENT DIRECTORY, BUT GO ONE STEP UP FROM CURRENT DIRECTORY AND THEN CREAT DERIVATIVES?\n",
    "\n",
    "    path_list = [f'./derivatives', \n",
    "    f'./derivatives/sub-{sid}',\n",
    "    f'./derivatives/sub-{sid}/megqc',\n",
    "    f'./derivatives/sub-{sid}/megqc/csv files',\n",
    "    f'./derivatives/sub-{sid}/megqc/figures']\n",
    "\n",
    "    print(path_list)\n",
    "\n",
    "    for path in path_list:\n",
    "        if os.path.isdir(path)==False: #if directory doesnt exist yet - create\n",
    "            os.mkdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['./derivatives', './derivatives/sub-1', './derivatives/sub-1/megqc', './derivatives/sub-1/megqc/csv files', './derivatives/sub-1/megqc/figures']\n"
     ]
    }
   ],
   "source": [
    "make_folders_meg(sid='1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "\n",
       "<table class=\"table table-hover table-striped table-sm table-responsive small\">\n",
       "    <tr>\n",
       "        <th>Measurement date</th>\n",
       "        <td>August 11, 2021  12:05:17 GMT</td>\n",
       "        \n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Experimenter</th>\n",
       "        <td>Meg User (meg)</td>\n",
       "        \n",
       "    </tr>\n",
       "        <th>Participant</th>\n",
       "        \n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Digitized points</th>\n",
       "        <td>356 points</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Good channels</th>\n",
       "        <td>11 IAS, 102 Magnetometers, 204 Gradiometers, 1 Stimulus, 1 SYST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Bad channels</th>\n",
       "        <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>EOG channels</th>\n",
       "        <td>Not available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>ECG channels</th>\n",
       "        <td>Not available</td>\n",
       "    <tr>\n",
       "        <th>Sampling frequency</th>\n",
       "        <td>1000.00 Hz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Highpass</th>\n",
       "        <td>0.10 Hz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Lowpass</th>\n",
       "        <td>330.00 Hz</td>\n",
       "    </tr>\n",
       "        <tr>\n",
       "            <th>Projections</th>\n",
       "            <td>magn8_iasoff_68deg.fif : PCA-v1: off<br/>magn8_iasoff_68deg.fif : PCA-v2: off<br/>magn8_iasoff_68deg.fif : PCA-v3: off<br/>magn8_iasoff_68deg.fif : PCA-v4: off<br/>magn8_iasoff_68deg.fif : PCA-v5: off<br/>magn8_iasoff_68deg.fif : PCA-v6: off<br/>magn8_iasoff_68deg.fif : PCA-v7: off<br/>magn8_iasoff_68deg.fif : PCA-v8: off</td>\n",
       "        </tr>\n",
       "\n",
       "    <tr>\n",
       "        <th>Filenames</th>\n",
       "        <td>mikado-1.fif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Duration</th>\n",
       "        <td>00:05:00 (HH:MM:SS)</td>\n",
       "    </tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<Raw | mikado-1.fif, 319 x 300001 (300.0 s), ~6.6 MB, data not loaded>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#crop the data to calculate faster\n",
    "\n",
    "raw_cropped = raw.copy()\n",
    "raw_cropped.crop(0, 300) #(first 5 min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filter the data and downsampling. see comments!\n",
    "\n",
    "def filter_and_resample_data(data=None,l_freq=None, h_freq=None, method='iir'):\n",
    "    # Filtering the data. Recommended: 1-100Hz bandpass or 0.5-100 Hz - better for frequency spectrum\n",
    "    # https://mne.tools/stable/generated/mne.io.Raw.html#mne.io.Raw.filter\n",
    "\n",
    "    # method='iir' - I m using here the Butterworth filter similar to filtfilt in matlab, like we  \n",
    "    # did in the course with eeg data. such filter creates no time shift, since it filters forward and backward.\n",
    "    # But we might use a different filter as well. I dont know if this one is the best possible option.\n",
    "\n",
    "    #Data has to be loaded into mememory before filetering:\n",
    "    data.load_data(verbose=True)\n",
    "    raw_bandpass = data.copy()\n",
    "    raw_bandpass.filter(l_freq=l_freq, h_freq=h_freq, picks='meg', method=method, iir_params=None)\n",
    "\n",
    "    #And resample:\n",
    "    #LOOK AT THE WARNING HERE https://mne.tools/stable/generated/mne.io.Raw.html?highlight=resample#mne.io.Raw.resample\n",
    "    #It s not recommended to epoch resampled data as it can mess up the triggers.\n",
    "    #We can either downsample after epoching - if needed. https://mne.tools/stable/generated/mne.Epochs.html#mne.Epochs.resample\n",
    "    #And here downsample the continuous data - and use it further only in continuouys form, no epoching. This is why 2 options returned.\n",
    "\n",
    "    raw_bandpass_resamp=raw_bandpass.copy()\n",
    "    raw_bandpass_resamp.resample(sfreq=h_freq*5)\n",
    "    #frequency to resample is 5 times higher than the maximum chosen frequency of the function\n",
    "\n",
    "    return(raw_bandpass, raw_bandpass_resamp)\n",
    "\n",
    "    #JOCHEM SAID: Try turning off the aliasing filter in downsampling. Not sure how?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading 0 ... 300000  =      0.000 ...   300.000 secs...\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.5 - 1e+02 Hz\n",
      "\n",
      "IIR filter parameters\n",
      "---------------------\n",
      "Butterworth bandpass zero-phase (two-pass forward and reverse) non-causal filter:\n",
      "- Filter order 16 (effective, after forward-backward)\n",
      "- Cutoffs at 0.50, 100.00 Hz: -6.02, -6.02 dB\n",
      "\n",
      "Trigger channel has a non-zero initial value of 18 (consider using initial_event=True to detect this event)\n",
      "301 events found\n",
      "Event IDs: [    9    19    21    23    27    31 16393 16402 16403 16405 16411 32741\n",
      " 32746 32749 32750 32759]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/h2/khhmb4p510vg63hbv0qkftt80000gs/T/ipykernel_90828/1734743608.py:23: RuntimeWarning: Trigger channel contains negative values, using absolute value. If data were acquired on a Neuromag system with STI016 active, consider using uint_cast=True to work around an acquisition bug\n",
      "  raw_bandpass_resamp.resample(sfreq=h_freq*5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trigger channel has a non-zero initial value of 18 (consider using initial_event=True to detect this event)\n",
      "253 events found\n",
      "Event IDs: [    9    19    20    21    22    23    27    31 16393 16402 16403 16405\n",
      " 16411 32741 32746 32749 32750 32759]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/h2/khhmb4p510vg63hbv0qkftt80000gs/T/ipykernel_90828/1734743608.py:23: RuntimeWarning: Trigger channel contains negative values, using absolute value. If data were acquired on a Neuromag system with STI016 active, consider using uint_cast=True to work around an acquisition bug\n",
      "  raw_bandpass_resamp.resample(sfreq=h_freq*5)\n"
     ]
    }
   ],
   "source": [
    "#apply filtering\n",
    "\n",
    "filtered_d, filtered_d_resamp=filter_and_resample_data(data=raw_cropped,l_freq=0.5, h_freq=100, method='iir')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Epoch_meg(data=None, stim_channel='STI101', event_dur=1.2, epoch_tmin=-0.2, epoch_tmax=1):\n",
    "#Gives epoched data i2 separatet data frames: mags and grads\n",
    "\n",
    "\n",
    "       picks_grad = mne.pick_types(data.info, meg='grad', eeg=False, eog=False, stim=False)\n",
    "       picks_magn = mne.pick_types(data.info, meg='mag', eeg=False, eog=False, stim=False)\n",
    "\n",
    "       events = mne.find_events(data, stim_channel=stim_channel, min_duration=event_dur)\n",
    "       n_events=len(events)\n",
    "\n",
    "       epochs_mags = mne.Epochs(data, events, picks=picks_magn, tmin=epoch_tmin, tmax=epoch_tmax, preload=True, baseline = None)\n",
    "       epochs_grads = mne.Epochs(data, events, picks=picks_grad, tmin=epoch_tmin, tmax=epoch_tmax, preload=True, baseline = None)\n",
    "\n",
    "       #Present epochs as data frame - separately for mags and grads\n",
    "       df_epochs_mags = epochs_mags.to_data_frame(time_format=None, scalings=dict(mag=1, grad=1))\n",
    "       df_epochs_grads = epochs_grads.to_data_frame(time_format=None, scalings=dict(mag=1, grad=1))\n",
    "\n",
    "       return(n_events, df_epochs_mags, df_epochs_grads, epochs_mags, epochs_grads)\n",
    "       #Returns: \n",
    "       # number of events(=number of epochs), \n",
    "       # data frame containing data for all epochs: mags and grads separately\n",
    "       # epochs as mne data structure (not used anywhere, we may use it for something in the future)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trigger channel has a non-zero initial value of 18 (consider using initial_event=True to detect this event)\n",
      "8 events found\n",
      "Event IDs: [ 9 19 20 21 22]\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "8 matching events found\n",
      "No baseline correction applied\n",
      "Created an SSP operator (subspace dimension = 8)\n",
      "8 projection items activated\n",
      "Loading data for 8 events and 1201 original time points ...\n",
      "0 bad epochs dropped\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "8 matching events found\n",
      "No baseline correction applied\n",
      "8 projection items activated\n",
      "Loading data for 8 events and 1201 original time points ...\n",
      "0 bad epochs dropped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/h2/khhmb4p510vg63hbv0qkftt80000gs/T/ipykernel_90828/2534005067.py:8: RuntimeWarning: Trigger channel contains negative values, using absolute value. If data were acquired on a Neuromag system with STI016 active, consider using uint_cast=True to work around an acquisition bug\n",
      "  events = mne.find_events(data, stim_channel=stim_channel, min_duration=event_dur)\n"
     ]
    }
   ],
   "source": [
    "#Apply epoching: USE NON RESAMPLED DATA. Or should we resample after epoching? Since sampling freq is 1kHz and resampling is 500Hz, it s not that much of a win...\n",
    "\n",
    "n_events, df_epochs_mags, df_epochs_grads, epochs_mags, epochs_grads=Epoch_meg(data=filtered_d, stim_channel='STI101', event_dur=1.2, epoch_tmin=-0.2, epoch_tmax=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% RMSE - general function to use in other functions\n",
    "#STD CALCULATION IS MUCH LESS COdE BUT TAKES LONGER THAN RMSE\n",
    "\n",
    "def RMSE(data_mags=None, data_grads=None):\n",
    "\n",
    "    # https://stackoverflow.com/questions/17197492/is-there-a-library-function-for-root-mean-square-error-rmse-in-python\n",
    "\n",
    "    from sklearn.metrics import mean_squared_error\n",
    "\n",
    "    #Magnitometers:\n",
    "    y_actual_mags=data_mags #refrence to data_mags\n",
    "    y_predicted_mags=data_mags.mean(axis=1)\n",
    "\n",
    "    rmse_mags = np.zeros(len(y_predicted_mags)) #RMSE of all magnetometers\n",
    "\n",
    "    for i in range(len(y_predicted_mags)):\n",
    "        y_predicted_vec_mags=np.ones(len(y_actual_mags[0]))*y_predicted_mags[i]\n",
    "        rmse_mags[i] = mean_squared_error(y_actual_mags[i, :], y_predicted_vec_mags, squared=False)\n",
    "\n",
    "\n",
    "    #Gradiometers:\n",
    "    y_actual_grads=data_grads #refrence to data_grads\n",
    "    y_predicted_grads=data_grads.mean(axis=1)\n",
    "\n",
    "    rmse_grads = np.zeros(len(y_predicted_grads)) #RMSE of all gradiometers\n",
    "\n",
    "    for i in range(len(y_predicted_grads)):\n",
    "        y_predicted_vec_grads=np.ones(len(y_actual_grads[0]))*y_predicted_grads[i]\n",
    "        rmse_grads[i] = mean_squared_error(y_actual_grads[i, :], y_predicted_vec_grads, squared=False)\n",
    "\n",
    "    return(rmse_mags, rmse_grads)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Root mean squared error calculation (or STD - same result) over all data:\n",
    "\n",
    "def RMSE_meg_all(data=None, mags=mags, grads=grads, std_lvl=1, plotflag=True, sid='1'): #, min_duration_event=1, epoch_tmin=-0.2, epoch_tmax=1):\n",
    "    #give path to directory and then it should auto find the data file when bids compliant.\n",
    "    ##maybe distinguish between negative and positive std_lvl\n",
    "\n",
    "    #plotflag - plot or no plot\n",
    "    #sid - subject Id. Has to be a string , like '1'\n",
    "    #mags, grads - channels like [name, index]\n",
    "  \n",
    "\n",
    "    # Separate data for mags and grads in 2 arrays.\n",
    "    selected_mags = [item[1] for item in mags]\n",
    "    selected_grads = [item[1] for item in grads]\n",
    "    data_mags, times = data[selected_mags, :]  \n",
    "    data_grads, times = data[selected_grads, :]  \n",
    "\n",
    "    # %% Calculate STD or RMSE of each channel\n",
    "\n",
    "    #Calculate RMSE for each channel (separated mags and grads) - for the entire time duration:\n",
    "    std_mags, std_grads = RMSE(data_mags=data_mags, data_grads=data_grads)\n",
    "\n",
    "    #STD (if wanna use insted of RMSE. it will exactly replace the RMSE function above):\n",
    "    #std_mags=np.std(data_mags, axis=1) #calculate std of all magnetometers (along second dimantion)\n",
    "    #std_grads=np.std(data_grads, axis=1) #calculate std of all gradiometers (along second dimantion)\n",
    "\n",
    "\n",
    "    # Check if channel data is within 1 std over all channels.\n",
    "    # COMMENT: can use -3 to 3 (or other number) std istead of -1/+1 std, but this can adjusted later. \n",
    "    # 1 std is too narrow, gives way too many bad channels.\n",
    "\n",
    "    std_std_mags=np.std(std_mags)\n",
    "    std_std_grads=np.std(std_grads)\n",
    "\n",
    "    mean_std_mags=np.mean(std_mags)\n",
    "    mean_std_grads=np.mean(std_grads)\n",
    "\n",
    "    ch_ind_large_std_mags= np.where(std_mags > mean_std_mags+std_lvl*std_std_mags) #find magn channels with largest std\n",
    "    ch_ind_large_std_grads= np.where(std_grads > mean_std_grads+std_lvl*std_std_grads) \n",
    "    ch_ind_small_std_mags= np.where(std_mags < mean_std_mags-std_lvl*std_std_mags) #find magn channels with smallest std\n",
    "    ch_ind_small_std_grads= np.where(std_grads < mean_std_grads-std_lvl*std_std_grads)\n",
    "\n",
    "    magn_channel_big_std=np.array(mags)[ch_ind_large_std_mags] #find the name of the magn with largest std \n",
    "    grad_channel_big_std=np.array(grads)[ch_ind_large_std_grads]\n",
    "    magn_channel_small_std=np.array(mags)[ch_ind_small_std_mags]\n",
    "    grad_channel_small_std=np.array(grads)[ch_ind_small_std_grads]\n",
    "\n",
    "\n",
    "    #This function simply makes a list of tuples. Each tuple is: name of channel, std value.\n",
    "    #Each tuple represents channel with too big or too small std, calculated over whole data.\n",
    "\n",
    "    def Channels_with_nonnormal_stds(ch_ind, all_stds_m_or_g, channels_big_std_names):\n",
    "        channel_big_std_vals=all_stds_m_or_g[ch_ind]\n",
    "        nonnormal_std_with_value=[]\n",
    "        for id, val in enumerate (ch_ind[0]):\n",
    "            new_tuple=(channels_big_std_names[id][0],  channel_big_std_vals[id])\n",
    "            nonnormal_std_with_value.append(new_tuple)\n",
    "        return(nonnormal_std_with_value)\n",
    "\n",
    "    #Apply function above:\n",
    "    m_big_std_with_value=Channels_with_nonnormal_stds(ch_ind_large_std_mags, std_mags, magn_channel_big_std)\n",
    "    g_big_std_with_value=Channels_with_nonnormal_stds(ch_ind_large_std_grads, std_grads, grad_channel_big_std)\n",
    "    m_small_std_with_value=Channels_with_nonnormal_stds(ch_ind_small_std_mags, std_mags, magn_channel_small_std)\n",
    "    g_small_std_with_value=Channels_with_nonnormal_stds(ch_ind_small_std_grads, std_grads, grad_channel_small_std)\n",
    "\n",
    "\n",
    "    #OLd STD figure:\n",
    "    if plotflag==True:\n",
    "        \n",
    "        from matplotlib import pyplot as plt\n",
    "\n",
    "        fig, (ax1, ax2) = plt.subplots(2)\n",
    "        fig.suptitle('STDs')\n",
    "        ax1.plot(list(range(1, len(std_mags)+1)), std_mags, marker='o', linestyle = 'None')\n",
    "        ax1.plot(list(range(1, len(std_mags)+1)), [mean_std_mags]*len(std_mags))\n",
    "        ax1.plot(list(range(1, len(std_mags)+1)), [mean_std_mags-std_lvl*std_std_mags]*len(std_mags))\n",
    "        ax1.plot(list(range(1, len(std_mags)+1)), [mean_std_mags+std_lvl*std_std_mags]*len(std_mags))\n",
    "        ax1.set(xlabel='Magnetometer', ylabel='STD')\n",
    "\n",
    "        ax2.plot(list(range(1, len(std_grads)+1)), std_grads, marker='o', linestyle = 'None')\n",
    "        ax2.plot(list(range(1, len(std_grads)+1)), [mean_std_grads]*len(std_grads))\n",
    "        ax2.plot(list(range(1, len(std_grads)+1)), [mean_std_grads-std_lvl*std_std_grads]*len(std_grads))\n",
    "        ax2.plot(list(range(1, len(std_grads)+1)), [mean_std_grads+std_lvl*std_std_grads]*len(std_grads))\n",
    "        ax2.set(xlabel='Gradiometer', ylabel='STD')\n",
    "\n",
    "        plt.savefig('./derivatives/sub-'+sid+'/megqc/figures/RMSE_all_channels.png')\n",
    "\n",
    "        \n",
    "\n",
    "    #Return the channel names with STD over the set STD level and under the set negative STD level.\n",
    "    return(m_big_std_with_value, g_big_std_with_value, m_small_std_with_value, g_small_std_with_value, std_mags, std_grads)\n",
    "\n",
    "\n",
    "    #CAN ADD OPTIONAL PLOTTING OF SOME CHANNELS WITH HIGH/LOW STD. DO WE NEED THAT?\n",
    "    #WHAT DO WE WANT TO GIVE AS OUTPUT HERE? NEED PLOTS, NEED LIST OF CHANNELS?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Magnetometers with high std:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('MEG0621', 4.965338372879145e-13),\n",
       " ('MEG1021', 4.852992071039414e-13),\n",
       " ('MEG1031', 5.004345361972638e-13),\n",
       " ('MEG1041', 4.939759752048587e-13),\n",
       " ('MEG1421', 5.678604995893133e-13),\n",
       " ('MEG1431', 5.476084157649638e-13),\n",
       " ('MEG1741', 5.282172136198286e-13),\n",
       " ('MEG2121', 5.018134686600477e-13),\n",
       " ('MEG2131', 5.860882537731944e-13),\n",
       " ('MEG2141', 5.460444751629966e-13),\n",
       " ('MEG2331', 5.002680469283238e-13),\n",
       " ('MEG2531', 5.683082618711569e-13),\n",
       " ('MEG2541', 5.925124304516582e-13),\n",
       " ('MEG2621', 5.364787072987134e-13),\n",
       " ('MEG2631', 5.466366791474147e-13)]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Try: USING RESAMPLED DATA HERE\n",
    "\n",
    "m_big_std_with_value, g_big_std_with_value, m_small_std_with_value, g_small_std_with_value, std_mags, std_grads=RMSE_meg_all(data=filtered_d_resamp, \n",
    "    mags=mags, grads=grads, std_lvl=1, plotflag=True, sid='1')\n",
    "\n",
    "print('Magnetometers with high std:')\n",
    "m_big_std_with_value\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def boxplot_std_hovering(std_data=std_mags, tit=None, channel_names=None, sid='1'):\n",
    "\n",
    "    #Boxplot with hovering annotations: https://stackoverflow.com/questions/7908636/how-to-add-hovering-annotations-in-matplotlib\n",
    "        \n",
    "    from matplotlib import pyplot as plt\n",
    "\n",
    "    ch_only_name_mag=[m[0] for m in channel_names] #names of channels for annotating the plot\n",
    "    #std_mags_df = pd.DataFrame(std_mags, index = ch_only_name_mag) #put all stds into a data frame with channels name as index\n",
    "\n",
    "    #Boxplot with seaborn:\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    #import seaborn as sns\n",
    "    #bp=sns.boxplot(data=std_data, orient='h') # DONT USE SEABORN, COS IT DOWSNT WANNA HOVER-ANNOTATE IT, ONLY PYPLOTLIB WORKS FINE\n",
    "\n",
    "    bp=plt.boxplot(std_data, vert=False)\n",
    "    sc = plt.scatter(std_data, np.ones(len(std_data)), color=\".25\") \n",
    "\n",
    "        #Workaround: Doest wanna annotate the swarmplot. So make swarmplot first, then take its coordinates (cis scatter needs aboth x and y) \n",
    "        # and make scatterplot with these coordinates (it can be annotated)\n",
    "        #sw=sns.swarmplot(data=std_mags, color=\".25\", ax=ax, alpha=0) #Makes data dots. Alpha sets swarmplot dots to invisible.\n",
    "        #offs=ax.collections[0].get_offsets() #get x and y coordinates\n",
    "        #ycoords=[coord[0] for coord in offs]\n",
    "        #xcoords=[coord[1] for coord in offs]\n",
    "        #sc = plt.scatter(xcoords,ycoords, color=\".25\") #use swarmplot coordinates to create scatter\n",
    "        #BUT IT CHANGES THE ORDER OF STDS, THATS WHY EVERYTHING S MESSED UP! Restore the order or just keep stuff as it is now\n",
    "\n",
    "    plt.xlabel(\"Standard deviation\")\n",
    "\n",
    "    #Set generic annotation:\n",
    "    annot = ax.annotate(\"\", xy=(0,0), xytext=(5,20),textcoords=\"offset points\",\n",
    "                        bbox=dict(boxstyle=\"round\", fc=\"w\"),\n",
    "                        arrowprops=dict(arrowstyle=\"->\"))\n",
    "    #xytext - how far from the dot the text is, bbox - box with name inside, arrowprops - to draw arrow\n",
    "\n",
    "    annot.set_visible(False) #hide annotations first\n",
    "\n",
    "\n",
    "    def update_annot(ind):\n",
    "\n",
    "        pos = sc.get_offsets()[ind[\"ind\"][0]]\n",
    "        annot.xy = pos #resets the xy values from annot above\n",
    "\n",
    "        #text = \"{}, {}\".format(\" \".join(list(map(str,ind[\"ind\"]))), \n",
    "        #                       \" \".join([ch_only_name_mag[n] for n in ind[\"ind\"]]))\n",
    "        #shows both index and name of channel\n",
    "\n",
    "        text = \"{}\".format(\" \".join([ch_only_name_mag[n] for n in ind[\"ind\"]]))\n",
    "        annot.set_text(text) #resets the text from annot above\n",
    "        \n",
    "\n",
    "    def hover(event):\n",
    "        vis = annot.get_visible()\n",
    "        if event.inaxes == ax:\n",
    "            cont, ind = sc.contains(event)\n",
    "            if cont:\n",
    "                update_annot(ind)\n",
    "                annot.set_visible(True)  #make annotation visible when hovering\n",
    "                fig.canvas.draw_idle()\n",
    "            else:\n",
    "                if vis:\n",
    "                    annot.set_visible(False)\n",
    "                    fig.canvas.draw_idle()\n",
    "\n",
    "    fig.canvas.mpl_connect(\"motion_notify_event\", hover)\n",
    "\n",
    "    ax.set_title(tit)\n",
    "\n",
    "    #Saving interactive figure:..\n",
    "    import pickle\n",
    "    fig_name='Stds_all_data_'+tit+'.fig.pickle'\n",
    "    fig_path='./derivatives/sub-'+sid+'/megqc/figures/'+fig_name\n",
    "    f_handle=open(fig_path, 'wb') # This is for Python 3 - py2 may need `file` instead of `open`, 'wb' means 'write binary' \n",
    "    pickle.dump(fig,f_handle) #save\n",
    "    f_handle.close() #close the binary file\n",
    "    \n",
    "    #plt.close('all') #close the figures\n",
    "\n",
    "    return(fig_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "\n",
    "tit='Magnetometers'\n",
    "fig_path_mags=boxplot_std_hovering(std_data=std_mags, tit=tit, channel_names=mags, sid='1')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reopen saved interactive figure:\n",
    "import pickle\n",
    "\n",
    "figx = pickle.load(open(fig_path_mags, 'rb'))\n",
    "figx.show() # Show the figure, edit it, etc.!\n",
    "\n",
    "#%matplotlib inline\n",
    "\n",
    "#REOPENS AS FIGURE, NOT PICTURE, good. BUT DOESNT DO THE HOVERING, HM..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./derivatives/sub-1/megqc/figures/Stds_all_data_Gradiometers.fig.pickle'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boxplot_std_hovering(std_data=std_grads, tit='Gradiometers', channel_names=grads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STD over epochs - REWRITTEN. Now use 2 separate data frames for mags and grads in calculations:\n",
    "\n",
    "def RMSE_meg_epoch(mags=mags, grads=grads, std_lvl=1, n_events=n_events, df_epochs_mags=df_epochs_mags, df_epochs_grads=df_epochs_grads, sid='1'):\n",
    "\n",
    "#def RMSE_meg_epoch(data=None, std_lvl=1, stim_channel='STI101',  min_duration_event=1.2, epoch_tmin=-0.2, epoch_tmax=1):\n",
    "    #stim_channel name is users input. but we can also let mne find it itself if 'None' is set? mne seems to have such function.\n",
    "\n",
    "    # 1) Loop over the epochs of each channel and check for every separate magn and grad and calculate std\n",
    "    import pandas as pd\n",
    "    eps=list(range(0,n_events)) #list of epoch numbers\n",
    "   \n",
    "    mags_names = [mag[0] for mag in mags]\n",
    "    grads_names = [grad[0] for grad in grads]\n",
    "\n",
    "    #Create a function which will loop over mags or grads and calculate std:\n",
    "    def std_mg(mg_names, df_mg):\n",
    "        dict_mg = {}\n",
    "\n",
    "        for ep in eps: #loop over each epoch\n",
    "            rows_for_ep = [row for row in df_mg.iloc if row.epoch == ep] #take all rows of 1 epoch, all channels.\n",
    "            std_epoch = [] #list with stds\n",
    "\n",
    "            for ch_name in mg_names: #loop over channel names\n",
    "                data_ch_epoch = [row_mg[ch_name] for row_mg in rows_for_ep] #take the data for 1 epoch for 1 channel\n",
    "                std_ch_ep = np.std(data_ch_epoch)\n",
    "                std_epoch.append(std_ch_ep)\n",
    "\n",
    "            dict_mg[ep] = std_epoch\n",
    "\n",
    "        df_std_mg = pd.DataFrame(dict_mg, index=mg_names)\n",
    "\n",
    "        return(df_std_mg)\n",
    "\n",
    "    #Apply this function for mags and grads:\n",
    "    df_std_mags=std_mg(df_mg=df_epochs_mags, mg_names=mags_names)\n",
    "    df_std_grads=std_mg(df_mg=df_epochs_grads, mg_names=grads_names)\n",
    "\n",
    "    # 2) Check (which epochs for which channel) are over 1STD (or 2, 3, ets STDs) for (this epoch for all channels)\n",
    "\n",
    "    #Find what is 1 std over all channels per 1 epoch:\n",
    "    std_std_mags_per_epoch=[]\n",
    "    std_std_grads_per_epoch=[]\n",
    "    mean_std_mags_per_epoch=[]\n",
    "    mean_std_grads_per_epoch=[]\n",
    "\n",
    "    for ep in eps: #goes over each epoch\n",
    "        std_std_mags_per_epoch.append(np.std(df_std_mags.iloc[:, ep])) #std of stds of all channels of every single epoch\n",
    "        std_std_grads_per_epoch.append(np.std(df_std_grads.iloc[:, ep]))\n",
    "\n",
    "        mean_std_mags_per_epoch.append(np.mean(df_std_mags.iloc[:, ep])) #mean of stds of all channels of every single epoch\n",
    "        mean_std_grads_per_epoch.append(np.mean(df_std_grads.iloc[:, ep]))\n",
    "\n",
    "\n",
    "    df_ch_ep_large_std_mags=df_std_mags.copy()\n",
    "    df_ch_ep_large_std_grads=df_std_grads.copy()\n",
    "\n",
    "    df_ch_ep_small_std_mags=df_std_mags.copy()\n",
    "    df_ch_ep_small_std_grads=df_std_grads.copy()\n",
    "\n",
    "    #Now see which channles in epoch are over 1 std or under -1 std:\n",
    "    for ep in eps: #goes over each epoch   \n",
    "        df_ch_ep_large_std_mags.iloc[:,ep] = df_ch_ep_large_std_mags.iloc[:,ep] > mean_std_mags_per_epoch[ep]+std_lvl*std_std_mags_per_epoch[ep] #magnetometers\n",
    "        df_ch_ep_large_std_grads.iloc[:,ep] = df_ch_ep_large_std_grads.iloc[:,ep] > mean_std_grads_per_epoch[ep]+std_lvl*std_std_grads_per_epoch[ep] #gradiometers\n",
    "\n",
    "        df_ch_ep_small_std_mags.iloc[:,ep] = df_ch_ep_small_std_mags.iloc[:,ep] < mean_std_mags_per_epoch[ep]-std_lvl*std_std_mags_per_epoch[ep] #magnetometers\n",
    "        df_ch_ep_small_std_grads.iloc[:,ep] = df_ch_ep_small_std_grads.iloc[:,ep] < mean_std_grads_per_epoch[ep]-std_lvl*std_std_grads_per_epoch[ep] #gradiometers\n",
    "\n",
    "\n",
    "    # Create csv files  for the user:\n",
    "\n",
    "    df_std_mags.to_csv('./derivatives/sub-'+sid+'/megqc/csv files/std_mags_per_epoch.csv')\n",
    "    \n",
    "    df_std_grads.to_csv('./derivatives/sub-'+sid+'/megqc/csv files/std_grads_per_epoch.csv')\n",
    "\n",
    "    df_ch_ep_large_std_mags.to_csv('./derivatives/sub-'+sid+'/megqc/csv files/Large_std_mags_per_epoch.csv')\n",
    "\n",
    "    df_ch_ep_large_std_grads.to_csv('./derivatives/sub-'+sid+'/megqc/csv files/Large_std_grads_per_epoch.csv')\n",
    "\n",
    "    df_ch_ep_small_std_mags.to_csv('./derivatives/sub-'+sid+'/megqc/csv files/Small_std_mags_per_epoch.csv')\n",
    "\n",
    "    df_ch_ep_small_std_grads.to_csv('./derivatives/sub-'+sid+'/megqc/csv files/Small_std_grads_per_epoch.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#try (will output csv files):\n",
    "# USING NON RESAMPLED DATA\n",
    "\n",
    "RMSE_meg_epoch(mags=mags, grads=grads, std_lvl=1, sid='1') #stim_channel='STI101', std_lvl=1, min_duration_event=1.2, epoch_tmin=-0.2, epoch_tmax=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting function for periodogram:\n",
    "\n",
    "def Plot_periodogram(m_or_g, freqs_mat, psds, sid):\n",
    "\n",
    "    from matplotlib import pyplot as plt\n",
    "\n",
    "    if m_or_g=='m':\n",
    "        naming='magnetomoters'\n",
    "    elif m_or_g=='g':\n",
    "        naming='gradiometers'\n",
    "    else:\n",
    "        print(\"input 'm' or 'g'\")\n",
    "        return\n",
    "\n",
    "    fig=plt.figure()\n",
    "    plt.plot(freqs_mat.T, np.sqrt(psds.T))\n",
    "    plt.yscale='log'\n",
    "    plt.xlabel('Frequency (Hz)')\n",
    "    plt.ylabel('Power spectral density (T / Hz)')  #check the units!\n",
    "    plt.title(\"Welch's periodogram for all \"+naming)\n",
    "    plt.savefig('./derivatives/sub-'+sid+'/megqc/figures/PSD_over_all_data_'+naming+'.png')\n",
    "    #plt.show()\n",
    "\n",
    "    #Save interactive figure:\n",
    "    import pickle\n",
    "    fig_name='PSD_over_all_data_interactive'+naming+'.fig.pickle'\n",
    "    fig_path='./derivatives/sub-'+sid+'/megqc/figures/'+fig_name\n",
    "    f_handle=open(fig_path, 'wb') # This is for Python 3 - py2 may need `file` instead of `open`\n",
    "    pickle.dump(fig,f_handle) \n",
    "    f_handle.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate frequency spectrum:\n",
    "#UPD: as discussed with Jochem, only calculate over whole time, no over concatenated epochs. For concatenated version see Funks_old notebook.\n",
    "\n",
    "def Freq_Spectrum_meg(data=None, plotflag=True, sid='1', freq_min=1, freq_max=200, n_fft=1000, n_per_seg=1000, freq_tmin=None, freq_tmax=None):\n",
    "\n",
    "    picks_grad = mne.pick_types(data.info, meg='grad', eeg=False, eog=False, stim=False)\n",
    "    picks_magn = mne.pick_types(data.info, meg='mag', eeg=False, eog=False, stim=False)\n",
    "\n",
    "    psds_mags, freqs_mags = psd_welch(data, fmin=freq_min, fmax=freq_max, n_jobs=-1, picks=picks_magn, n_fft=n_fft, n_per_seg=n_per_seg, tmin=freq_tmin, tmax=freq_tmax)\n",
    "    psds_grads, freqs_grads = psd_welch(data, fmin=freq_min, fmax=freq_max, n_jobs=-1, picks=picks_grad, n_fft=n_fft, n_per_seg=n_per_seg, tmin=freq_tmin, tmax=freq_tmax)\n",
    "    #CALCULATES NOW OVER ALL TIME. SET TIME HERE IF WANT IT FASTER OR PARTICULAR PERIOD. RESULT CAN LOOK VERY DIFFERNT.\n",
    "\n",
    "    # n_per_seg - Length of each Welch segment (windowed with a Hamming window). Defaults to None, which sets n_per_seg equal to n_fft.\n",
    "    # n_fft - The length of FFT used, must be >= n_per_seg (default: 256). The segments will be zero-padded if n_fft > n_per_seg. If n_per_seg \n",
    "    # is None, n_fft must be <= number of time points in the data.\n",
    "    # These influence the bandwidth.\n",
    "\n",
    "    #Plot the result over all time:\n",
    "\n",
    "    freqs_mat_mags=np.tile(freqs_mags, [np.shape(psds_mags)[0],1])\n",
    "    freqs_mat_grads=np.tile(freqs_grads, [np.shape(psds_grads)[0],1])\n",
    "\n",
    "    if plotflag==True:\n",
    "        \n",
    "        Plot_periodogram('m', freqs_mat_mags, psds_mags, sid) #Magnetometers:\n",
    "        Plot_periodogram('g', freqs_mat_grads, psds_grads, sid) #Gradiometers:\n",
    "\n",
    "        #Freq spectrum peaks we see (visible on shorter interval, ALMOST NONE SEEN when Welch is done over all time):\n",
    "        #50, 100, 150 - powerline EU\n",
    "        #6 noise of shielding chambers \n",
    "        #44 meg noise\n",
    "        #17 - was it the train station near by?\n",
    "        #10 Secret :)\n",
    "        #1hz - highpass filter.\n",
    "        #flat spectrum is white noise process. Has same energy in every frequency (starts around 50Hz or even below)\n",
    "\n",
    "        #Need to find frequencies.. and filter out? \n",
    "        #Powerline\n",
    "        #Eye moves \n",
    "        #Blinks\n",
    "        #Cardio: try to autocreate it. Maybe it s small enough to not care?\n",
    "        #Muscle movements \n",
    "\n",
    "    return(freqs_mags, freqs_grads, psds_mags, psds_grads, fig_path_m, fig_path_g) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Effective window size : 2.000 (s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done   3 out of   8 | elapsed:    0.4s remaining:    0.6s\n",
      "[Parallel(n_jobs=8)]: Done   5 out of   8 | elapsed:    0.6s remaining:    0.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Effective window size : 2.000 (s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done   8 out of   8 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done   3 out of   8 | elapsed:    0.4s remaining:    0.7s\n",
      "[Parallel(n_jobs=8)]: Done   5 out of   8 | elapsed:    0.6s remaining:    0.3s\n",
      "[Parallel(n_jobs=8)]: Done   8 out of   8 | elapsed:    0.8s finished\n"
     ]
    }
   ],
   "source": [
    "#try: OVER RESAMPLED WHOLE DATA\n",
    "\n",
    "#%matplotlib inline\n",
    "%matplotlib qt\n",
    "\n",
    "freqs_mags, freqs_grads, psds_mags, psds_grads, fig_path_m, fig_path_g = Freq_Spectrum_meg(data=filtered_d_resamp, plotflag=True, sid='1', freq_min=0.5, freq_max=100, \n",
    "    n_fft=1000, n_per_seg=1000, freq_tmin=None, freq_tmax=None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reopen saved interactive figure:\n",
    "import pickle\n",
    "\n",
    "%matplotlib qt\n",
    "\n",
    "fig_psd_m = pickle.load(open(fig_path_m, 'rb'))\n",
    "fig_psd_m.show() # Show the figure, edit it, etc.!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def Power_of_freq_meg(mags=mags, grads=grads, freqs_mags=freqs_mags, freqs_grads=freqs_grads, psds_mags=psds_mags, psds_grads=psds_grads, mean_power_per_band=True, plotflag=True, sid='1'):\n",
    "\n",
    "    # Power of frequencies calculation for all mags + grads channels separately, \n",
    "    # saving power + power/freq value in data frames.\n",
    "\n",
    "    from scipy.integrate import simps\n",
    "    import pandas as pd\n",
    "\n",
    "    # adopted from: https://raphaelvallat.com/bandpower.html\n",
    "    \n",
    "    # Calculate the band power:\n",
    "    wave_bands=[[0.5, 4], [4, 8], [8, 12], [12, 30], [30, 100]]\n",
    "    #delta (0.5–4 Hz), theta (4–8 Hz), alpha (8–12 Hz), beta (12–30 Hz), and gamma (30–100 Hz) bands\n",
    "\n",
    "    mags_names = [mag[0] for mag in mags]\n",
    "    grads_names = [grad[0] for grad in grads]\n",
    "\n",
    "    dict_mags_power = {}\n",
    "    dict_grads_power = {}\n",
    "\n",
    "    dict_mags_power_freq = {}\n",
    "    dict_grads_power_freq = {}\n",
    "\n",
    "    dict_mags_rel_power = {}\n",
    "    dict_grads_rel_power = {}\n",
    "\n",
    "    for w in enumerate(wave_bands): #loop over bands\n",
    "\n",
    "        low, high = w[1] # Define band lower and upper limits\n",
    "        power_per_band = {\"mags\": [], \"grads\": []}\n",
    "        power_by_Nfreq_per_band = {\"mags\": [], \"grads\": []}\n",
    "        rel_power_per_band = {\"mags\": [], \"grads\": []}\n",
    "\n",
    "    #loop over mags, then grads\n",
    "\n",
    "        idx_delta_m = np.logical_and(freqs_mags >= low, freqs_mags <= high)\n",
    "        for m in enumerate(psds_mags): \n",
    "        #loop over mags channels. psd_ch_m is psd of partigular channel\n",
    "\n",
    "            #ch_name_m=mags_names[m[0]]\n",
    "            psd_ch_m=np.array(m[1])\n",
    "\n",
    "            #Area under the curve:\n",
    "            # Frequency resolution\n",
    "            freq_res = freqs_mags[1] - freqs_mags[0]  # = 1 / 4 = 0.25\n",
    "\n",
    "            # Compute the absolute power by approximating the area under the curve\n",
    "            band_power_m = simps(psd_ch_m[idx_delta_m], dx=freq_res)\n",
    "\n",
    "            #devide the power by the  number of frequencies in the band\n",
    "            power_compare_m=band_power_m/sum(idx_delta_m) \n",
    "\n",
    "            #calculate the relative power: % of this band in the total bands power for this channel:\n",
    "            total_power_m = simps(psd_ch_m, dx=freq_res)\n",
    "            band_rel_power_m = band_power_m / total_power_m\n",
    "\n",
    "            power_per_band['mags'].append(band_power_m)\n",
    "            rel_power_per_band['mags'].append(band_rel_power_m)\n",
    "            power_by_Nfreq_per_band['mags'].append(power_compare_m)\n",
    "\n",
    "        #print('mags done')\n",
    "\n",
    "        idx_delta_g = np.logical_and(freqs_grads >= low, freqs_grads <= high)\n",
    "        for g in enumerate(psds_grads): \n",
    "        #loop over grads channels and their names\n",
    "\n",
    "            #ch_name_g=grads_names[g[0]]\n",
    "            psd_ch_g=np.array(g[1])\n",
    "\n",
    "            #Area under the curve:\n",
    "            # Frequency resolution\n",
    "            freq_res = freqs_grads[1] - freqs_grads[0]  \n",
    "\n",
    "            # Compute the absolute power by approximating the area under the curve\n",
    "            band_power_g = simps(psd_ch_g[idx_delta_g], dx=freq_res)\n",
    "\n",
    "            #devide the power by the  number of frequencies in the band\n",
    "            power_compare_g=band_power_g/sum(idx_delta_g) \n",
    "\n",
    "            #calculate the relative power: % of this band in the total bands power for this channel:\n",
    "            total_power_g = simps(psd_ch_g, dx=freq_res)\n",
    "            band_rel_power_g = band_power_g / total_power_g\n",
    "\n",
    "            power_per_band['grads'].append(band_power_g)\n",
    "            rel_power_per_band['grads'].append(band_rel_power_g)\n",
    "            power_by_Nfreq_per_band['grads'].append(power_compare_g)\n",
    "\n",
    "\n",
    "            \n",
    "        dict_mags_power[w[0]] = power_per_band[\"mags\"]\n",
    "        dict_grads_power[w[0]] = power_per_band[\"grads\"]\n",
    "\n",
    "        dict_mags_power_freq[w[0]] = power_by_Nfreq_per_band[\"mags\"]\n",
    "        dict_grads_power_freq[w[0]] = power_by_Nfreq_per_band[\"grads\"]\n",
    "\n",
    "        dict_mags_rel_power[w[0]] = rel_power_per_band[\"mags\"]\n",
    "        dict_grads_rel_power[w[0]] = rel_power_per_band[\"grads\"]\n",
    "\n",
    "\n",
    "    # Save power and delta_compare to data frame:\n",
    "    df_power_mags = pd.DataFrame(dict_mags_power, index=mags_names)\n",
    "    df_power_grads = pd.DataFrame(dict_grads_power, index=grads_names)\n",
    "\n",
    "    df_power_freq_mags = pd.DataFrame(dict_mags_power_freq, index=mags_names)\n",
    "    df_power_freq_grads = pd.DataFrame(dict_grads_power_freq, index=grads_names)\n",
    "\n",
    "    df_rel_power_mags = pd.DataFrame(dict_mags_rel_power, index=mags_names)\n",
    "    df_rel_power_grads = pd.DataFrame(dict_grads_rel_power, index=grads_names)\n",
    "\n",
    "    # Rename columns and extract to csv:\n",
    "\n",
    "    renamed_df_power_mags = df_power_mags.rename(columns={0: \"delta (0.5-4 Hz)\", 1: \"theta (4-8 Hz)\", 2: \"alpha (8-12 Hz)\", 3: \"beta (12-30 Hz)\", 4: \"gamma (30-100 Hz)\"})\n",
    "    renamed_df_power_grads = df_power_grads.rename(columns={0: \"delta (0.5-4 Hz)\", 1: \"theta (4-8 Hz)\", 2: \"alpha (8-12 Hz)\", 3: \"beta (12-30 Hz)\", 4: \"gamma (30-100 Hz)\"})\n",
    "\n",
    "    renamed_df_power_freq_mags = df_power_freq_mags.rename(columns={0: \"delta (0.5-4 Hz)\", 1: \"theta (4-8 Hz)\", 2: \"alpha (8-12 Hz)\", 3: \"beta (12-30 Hz)\", 4: \"gamma (30-100 Hz)\"})\n",
    "    renamed_df_power_freq_grads = df_power_freq_grads.rename(columns={0: \"delta (0.5-4 Hz)\", 1: \"theta (4-8 Hz)\", 2: \"alpha (8-12 Hz)\", 3: \"beta (12-30 Hz)\", 4: \"gamma (30-100 Hz)\"})\n",
    "\n",
    "    renamed_df_rel_power_mags = df_rel_power_mags.rename(columns={0: \"delta (0.5-4 Hz)\", 1: \"theta (4-8 Hz)\", 2: \"alpha (8-12 Hz)\", 3: \"beta (12-30 Hz)\", 4: \"gamma (30-100 Hz)\"})\n",
    "    renamed_df_rel_power_grads = df_rel_power_grads.rename(columns={0: \"delta (0.5-4 Hz)\", 1: \"theta (4-8 Hz)\", 2: \"alpha (8-12 Hz)\", 3: \"beta (12-30 Hz)\", 4: \"gamma (30-100 Hz)\"})\n",
    "\n",
    "    # Create csv file  for the user:\n",
    "    renamed_df_power_mags.to_csv('./derivatives/sub-'+sid+'/megqc/csv files/abs_power_mags.csv')\n",
    "    renamed_df_power_grads.to_csv('./derivatives/sub-'+sid+'/megqc/csv files/abs_power_grads.csv')\n",
    "    renamed_df_power_freq_mags.to_csv('./derivatives/sub-'+sid+'/megqc/csv files/power_by_Nfreq_mags.csv')\n",
    "    renamed_df_power_freq_grads.to_csv('./derivatives/sub-'+sid+'/megqc/csv files/power_by_Nfreq_grads.csv')\n",
    "    renamed_df_rel_power_mags.to_csv('./derivatives/sub-'+sid+'/megqc/csv files/relative_power_mags.csv')\n",
    "    renamed_df_rel_power_grads.to_csv('./derivatives/sub-'+sid+'/megqc/csv files/relative_power_grads.csv')\n",
    "\n",
    "    if mean_power_per_band==True: #if user wants to see average power per band over all channels - calculate and plot here:\n",
    "\n",
    "        #Calculate power per band over all mags and all grads\n",
    "\n",
    "        import statistics \n",
    "\n",
    "        power_dfs=[df_power_mags, df_rel_power_mags, df_power_grads, df_rel_power_grads, df_power_freq_mags, df_power_freq_grads]\n",
    "        #keep them in this order!  important for this cell calculations\n",
    "\n",
    "        bands_names=['delta', 'theta', 'alpha', 'beta', 'gamma']\n",
    "        band_title=['Magnetometers. Average absolute power per band:', 'Magnetometers. Average relative power per band:',\n",
    "        'Gradiometers. Average absolute power per band:', 'Gradiometers. Average relative power per band:', \n",
    "        'Magnetometers. Average power/freq per band:', 'Gradiometers. Average power/freq per band:']\n",
    "\n",
    "        mean_abs_m=[]\n",
    "        mean_abs_g=[]\n",
    "        mean_relative_m=[]\n",
    "        mean_relative_g=[]\n",
    "        mean_power_nfreq_m=[]\n",
    "        mean_power_nfreq_g=[]\n",
    "\n",
    "        for d in enumerate(power_dfs):\n",
    "            print(band_title[d[0]])\n",
    "\n",
    "            for w in enumerate(bands_names): #loop over bands\n",
    "                mean_power_per_band = statistics.mean(d[1].loc[:,w[0]])\n",
    "                \n",
    "                if d[0]==0: #df_power_mags:\n",
    "                    mean_abs_m.append(mean_power_per_band) \n",
    "                elif d[0]==1: #df_rel_power_mags:\n",
    "                    mean_relative_m.append(mean_power_per_band) \n",
    "                elif d[0]==2: #df_power_grads:\n",
    "                    mean_abs_g.append(mean_power_per_band)\n",
    "                elif d[0]==3: #df_rel_power_grads:\n",
    "                    mean_relative_g.append(mean_power_per_band) \n",
    "                elif d[0]==4: #df_power_freq_mags:\n",
    "                    mean_power_nfreq_m.append(mean_power_per_band)\n",
    "                elif d[0]==5: #df_power_freq_grads:\n",
    "                    mean_power_nfreq_g.append(mean_power_per_band)\n",
    "                print(w[1], mean_power_per_band)\n",
    "\n",
    "\n",
    "        if plotflag==True: #If user sets plotting to true -> show and save Visual: band power over all mags and grads as a pie chart:\n",
    "\n",
    "            #The mean relative percentages dont sum up into 100%, so added the 'unknown' part.\n",
    "\n",
    "            bands_names_un_m=['delta', 'theta', 'alpha', 'beta', 'gamma']\n",
    "            bands_names_un_g=['delta', 'theta', 'alpha', 'beta', 'gamma']\n",
    "\n",
    "            mean_relative_m_un=[v * 100 for v in mean_relative_m]  #in percentage\n",
    "            power_unknown_m=100-(sum(mean_relative_m))*100\n",
    "            if power_unknown_m>0:\n",
    "                mean_relative_m_un.append(power_unknown_m)\n",
    "                bands_names_un_m=['delta', 'theta', 'alpha', 'beta', 'gamma', 'unknown']\n",
    "\n",
    "            mean_relative_g_un=[v * 100 for v in mean_relative_g] #in percentage\n",
    "            power_unknown_g=100-(sum(mean_relative_g))*100\n",
    "            if power_unknown_g>0:\n",
    "                mean_relative_g_un.append(power_unknown_g)\n",
    "                bands_names_un_g=['delta', 'theta', 'alpha', 'beta', 'gamma', 'unknown']\n",
    "\n",
    "            fig1, axs = plt.subplots(1,2)\n",
    "            fig1.suptitle('Relative power of each band')\n",
    "            axs[0].pie(mean_relative_m_un, labels=bands_names_un_m, autopct='%1.1f%%') #autopct for percentage values\n",
    "            axs[0].axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n",
    "            axs[0].set_title('Magnetometers')\n",
    "            axs[1].pie(mean_relative_g_un, labels=bands_names_un_g, autopct='%1.1f%%')\n",
    "            axs[1].axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n",
    "            axs[1].set_title('Gradiometers')\n",
    "            plt.savefig('./derivatives/sub-'+sid+'/megqc/figures/Relative_power_per_band_over_all_channels.png')\n",
    "            plt.show()\n",
    "\n",
    "    return(psd_ch_m)\n",
    "    #Note on the pie chart: it calculates average relative power of each band. Powers might average so, that their sum is over 100% (101,102..). \n",
    "    #This is why in pie chart the relative values dont correspond exactly to the relative values which are printed. \n",
    "    # (pie recalculates everything so it s 100% in sum).\n",
    "    #also - there might be the \"unknown\" frequency and might not. This is why the if statements above.\n",
    "    #DO WE NEED THE PIE CHART IF IT WORK THIS WAY? MIGHT BE CONFUSING? OR SHOULD WE SKIP CALCULATING AVERAGE POWERS AT ALL?\n",
    "   \n",
    "   \n",
    "    # DECIDE WHAT TO OUTPUT HERE!\n",
    "    #ask Jochem about reference values for relative power values!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Magnetometers. Average absolute power per band:\n",
      "delta 6.434569286715877e-26\n",
      "theta 2.608824050924633e-26\n",
      "alpha 1.716783383579402e-26\n",
      "beta 5.703166640471932e-26\n",
      "gamma 1.1935286854758124e-26\n",
      "Magnetometers. Average relative power per band:\n",
      "delta 0.37137966623753815\n",
      "theta 0.1513686955941812\n",
      "alpha 0.10215063662315998\n",
      "beta 0.321277998976726\n",
      "gamma 0.06767791043212261\n",
      "Gradiometers. Average absolute power per band:\n",
      "delta 8.19644924752349e-24\n",
      "theta 3.213813114557092e-24\n",
      "alpha 3.6045476494656196e-24\n",
      "beta 5.7889819360100895e-24\n",
      "gamma 8.530424481172285e-24\n",
      "Gradiometers. Average relative power per band:\n",
      "delta 0.28101461005110046\n",
      "theta 0.11290237156433974\n",
      "alpha 0.11530130164049675\n",
      "beta 0.19488272175591329\n",
      "gamma 0.29641080116517227\n",
      "Magnetometers. Average power/freq per band:\n",
      "delta 8.043211608394847e-27\n",
      "theta 2.8986933899162588e-27\n",
      "alpha 1.907537092866002e-27\n",
      "beta 1.5413963893167384e-27\n",
      "gamma 8.464742450183067e-29\n",
      "Gradiometers. Average power/freq per band:\n",
      "delta 1.0245561559404362e-24\n",
      "theta 3.570903460618991e-25\n",
      "alpha 4.0050529438506884e-25\n",
      "beta 1.5645897124351593e-25\n",
      "gamma 6.04994644054772e-26\n"
     ]
    }
   ],
   "source": [
    "#try:\n",
    "\n",
    "psd_ch_m=Power_of_freq_meg(mags=mags, grads=grads, freqs_mags=freqs_mags, freqs_grads=freqs_grads, psds_mags=psds_mags, psds_grads=psds_grads, mean_power_per_band=True, plotflag=True, sid='1')\n",
    "#will output dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.831608981386599e-27"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What we did above:\n",
    "# Take 1 band, delta or so and calculate area under the curve. \n",
    "\n",
    "# Do now: take one band and calculate std\n",
    "# Devide area under curve by num of freq. Should be same as std for this band.\n",
    "\n",
    "new_val=np.std(psd_ch_m)\n",
    "new_val\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d401ab1bf6dd7bb97662b0feb1321a641d60d04842bfa92b47f7871360972b5d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('mne_new')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
